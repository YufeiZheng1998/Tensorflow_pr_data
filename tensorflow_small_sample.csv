pr_id,pr_title,pr_body,requester,pr_commenters,pr_comments,original_reviewers,active_reviewers,assignees,changed_files_content,commits_messages,commits_comments,created_at
58320,Declare strides when ACL objects init and activation in ACL depthwise,"The following fixes are in PR:

(1) Since when we are configuring ACL objects we know exactly what is expected formats for weights so we should set strides at that point and not leave it to ACL to estimate based on weights dimensions,

(2) If depthwise convolution comes with post op that converts to ACL’s activation layer operation we were not executing that activation function because the convolution was not configured with it.",milpuz01,['milpuz01'],['cc: @penpornk '],['penpornk'],['penpornk'],['gbaned'],"b'diff --git a/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh b/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh\nindex 4977870515231..ae26ae0ad9c8f 100644\n--- a/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh\n+++ b/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh\n@@ -24,14 +24,4 @@ ARM_SKIP_TESTS=""-//tensorflow/lite/... \\\n -//tensorflow/python/kernel_tests/nn_ops:conv_ops_test \\\n -//tensorflow/python/kernel_tests/nn_ops:conv2d_backprop_filter_grad_test \\\n -//tensorflow/python/kernel_tests/nn_ops:atrous_conv2d_test \\\n--//tensorflow/python/training:server_lib_test \\\n--//tensorflow/python/kernel_tests/linalg:linalg_grad_test_gpu \\\n--//tensorflow/python/kernel_tests/linalg:linalg_grad_test_cpu \\\n--//tensorflow/python/kernel_tests/linalg:linear_operator_block_diag_test_gpu \\\n--//tensorflow/python/kernel_tests/linalg:linear_operator_block_diag_test_cpu \\\n--//tensorflow/python/kernel_tests/linalg:linear_operator_block_lower_triangular_test_gpu \\\n--//tensorflow/python/kernel_tests/linalg:linear_operator_block_lower_triangular_test_cpu \\\n--//tensorflow/python/kernel_tests/linalg:linalg_ops_test_gpu \\\n--//tensorflow/python/kernel_tests/linalg:linalg_ops_test_cpu \\\n--//tensorflow/python/kernel_tests/linalg:linear_operator_composition_test_gpu \\\n--//tensorflow/python/kernel_tests/linalg:linear_operator_composition_test_cpu""\n+-//tensorflow/python/training:server_lib_test""\ndiff --git a/third_party/compute_library/acl_fixed_format_kernels_striding.patch b/third_party/compute_library/acl_fixed_format_kernels_striding.patch\nindex b3f38b047c856..8e501a1d6d9c7 100644\n--- a/third_party/compute_library/acl_fixed_format_kernels_striding.patch\n+++ b/third_party/compute_library/acl_fixed_format_kernels_striding.patch\n@@ -16,33 +16,55 @@\n  *******************************************************************************\n \n diff --git a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n-index 77da83070..44aef28c6 100644\n+index 77da83070..985f96761 100644\n --- a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n +++ b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n-@@ -506,7 +506,7 @@ void Fallback<TypeInput, TypeOutput, OutputStage>::run(ITensorPack &tensors)\n-             ITensorInfo      *tensor_info     = b->info();\n-             const DataLayout  data_layout     = tensor_info->data_layout();\n-             const TensorShape tensor_shape    = tensor_info->tensor_shape();\n+@@ -495,48 +495,6 @@ void Fallback<TypeInput, TypeOutput, OutputStage>::run(ITensorPack &tensors)\n+     {\n+         ldb                                = b->info()->strides_in_bytes().y() / sizeof(TypeInput);\n+         multi_stride_b                     = b->info()->strides_in_bytes().z() / sizeof(TypeInput);\n+-        const arm_compute::WeightFormat wf = assembly_utils::map_to_arm_compute_weight_format(_gemm_kernel_asm->get_config().weight_format);\n+-        if(is_fixed_format(wf))\n+-        {\n+-            // The 4D tensor of dimension O\'HWI\' created for the\n+-            // OHWIo<interleave_by>i<block_by> format is in reality seen\n+-            // as a 2D tensor at arm_gemm level, where the rows are\n+-            // O\'/<interleave_by> and the columns are <interleave_by> *\n+-            // H * W * I\'.\n+-            ITensorInfo      *tensor_info     = b->info();\n+-            const DataLayout  data_layout     = tensor_info->data_layout();\n+-            const TensorShape tensor_shape    = tensor_info->tensor_shape();\n -            const int         tensor_height   = tensor_shape[get_data_layout_dimension_index(data_layout, DataLayoutDimension::HEIGHT)];\n-+            int               tensor_height   = tensor_shape[get_data_layout_dimension_index(data_layout, DataLayoutDimension::HEIGHT)];\n-             const int         tensor_width    = tensor_shape[get_data_layout_dimension_index(data_layout, DataLayoutDimension::WIDTH)];\n-             int               tensor_channels = tensor_shape[get_data_layout_dimension_index(data_layout, DataLayoutDimension::CHANNEL)];\n-             const int         interleave_by   = arm_compute::interleave_by(wf);\n-@@ -528,6 +528,17 @@ void Fallback<TypeInput, TypeOutput, OutputStage>::run(ITensorPack &tensors)\n-             {\n-                 // In this case dimension that is packed is only height\n-                 // so we need to stride only height by interleave_by\n-+                if(tensor_height % blocked_by != 0) {\n-+                    tensor_height = arm_gemm::iceildiv(tensor_height, blocked_by) * blocked_by;\n-+                    if(multi_stride_b != 0) {\n-+                        multi_stride_b = tensor_height * tensor_width;\n-+                    }\n-+                }\n-+\n-+                if(tensor_width % interleave_by != 0) {\n-+                    multi_stride_b = arm_gemm::iceildiv(tensor_width, interleave_by) * interleave_by * tensor_height;\n-+                }\n-+\n-                 ldb = interleave_by * tensor_height;\n-             }\n-             else\n+-            const int         tensor_width    = tensor_shape[get_data_layout_dimension_index(data_layout, DataLayoutDimension::WIDTH)];\n+-            int               tensor_channels = tensor_shape[get_data_layout_dimension_index(data_layout, DataLayoutDimension::CHANNEL)];\n+-            const int         interleave_by   = arm_compute::interleave_by(wf);\n+-            const int         blocked_by      = arm_compute::block_by(wf);\n+-            // We need to find a new stride that is distance from the data for one\n+-            // set of output channels to the next\n+-            if(ldb == tensor_channels && multi_stride_b == tensor_channels * tensor_width)\n+-            {\n+-                // In this case dimensions that are packed are height, width and channel\n+-                // so we need to stride it by interleave_by\n+-                if(tensor_channels % blocked_by != 0)\n+-                {\n+-                    // We need to pad\n+-                    tensor_channels = arm_gemm::iceildiv(tensor_channels, blocked_by) * blocked_by;\n+-                }\n+-                ldb = interleave_by * tensor_height * tensor_width * tensor_channels;\n+-            }\n+-            else if(multi_stride_b == 0 || (ldb == tensor_width && multi_stride_b == tensor_height * tensor_width))\n+-            {\n+-                // In this case dimension that is packed is only height\n+-                // so we need to stride only height by interleave_by\n+-                ldb = interleave_by * tensor_height;\n+-            }\n+-            else\n+-            {\n+-                // If dimensions are not packed as above error is thrown\n+-                // as at the moment other forms of packing are not supported\n+-                ARM_COMPUTE_ERROR(""Unsupported packing for fixed format kernel"");\n+-            }\n+-        }\n+         in1_ptr = reinterpret_cast<const TypeInput *>(b->buffer() + b->info()->offset_first_element_in_bytes());\n+     }\n+ \ndiff --git a/third_party/mkl_dnn/onednn_acl_depthwise_convolution.patch b/third_party/mkl_dnn/onednn_acl_depthwise_convolution.patch\nindex 78cf4e233a0d3..95f0374ec4ddd 100644\n--- a/third_party/mkl_dnn/onednn_acl_depthwise_convolution.patch\n+++ b/third_party/mkl_dnn/onednn_acl_depthwise_convolution.patch\n@@ -14,9 +14,9 @@\n  See the License for the specific language governing permissions and\n  limitations under the License.\n  *******************************************************************************\n- \n+\n diff --git a/src/cpu/aarch64/acl_convolution_utils.cpp b/src/cpu/aarch64/acl_convolution_utils.cpp\n-index 6a840b973..47a3a4a92 100644\n+index fc93d2aa9..6ebac0d17 100644\n --- a/src/cpu/aarch64/acl_convolution_utils.cpp\n +++ b/src/cpu/aarch64/acl_convolution_utils.cpp\n @@ -54,10 +54,12 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,\n@@ -73,7 +73,7 @@ index 6a840b973..47a3a4a92 100644\n      acp.weights_info = arm_compute::WeightsInfo(\n          false,\n          kw,\n-@@ -297,6 +311,10 @@ status_t init_conf_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -302,6 +316,10 @@ status_t init_conf_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n          const primitive_attr_t &attr) {\n      acp.is_indirect = false;\n  \n@@ -84,7 +84,7 @@ index 6a840b973..47a3a4a92 100644\n      // General Compute Library checks, memory tags are also set there\n      CHECK(acl_init_conf(acp, src_md, weights_md, dst_md, bias_md, cd, attr));\n  \n-@@ -325,7 +343,8 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -330,7 +348,8 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n      auto math_mode = get_fpmath_mode();\n      // Indirect convolution results in slowdown for low thread count or 1x1\n      // kernels, so fall back to GEMM-based convolution in these cases\n@@ -94,7 +94,7 @@ index 6a840b973..47a3a4a92 100644\n                  weights_md.dims[3] == 1, // kw\n                  (!math_mode && dnnl_get_max_threads() < 28))) {\n          return status::unimplemented;\n-@@ -350,6 +369,27 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -355,6 +374,27 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n      return status::success;\n  }\n  \n@@ -122,7 +122,7 @@ index 6a840b973..47a3a4a92 100644\n  status_t init_conf_wino(acl_conv_conf_t &acp, memory_desc_t &src_md,\n          memory_desc_t &weights_md, memory_desc_t &dst_md,\n          memory_desc_t &bias_md, const convolution_desc_t &cd,\n-@@ -359,7 +399,8 @@ status_t init_conf_wino(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -364,7 +404,8 @@ status_t init_conf_wino(acl_conv_conf_t &acp, memory_desc_t &src_md,\n      // Under these conditions, fallback to faster GEMM-based convolution\n      // unless the user explicitly specifies Winograd algorithm\n      // clang-format off\n@@ -217,10 +217,10 @@ index 000000000..1beb8b8af\n +}\n diff --git a/src/cpu/aarch64/acl_depthwise_convolution.hpp b/src/cpu/aarch64/acl_depthwise_convolution.hpp\n new file mode 100644\n-index 000000000..97e0a3a30\n+index 000000000..d84fc4fb5\n --- /dev/null\n +++ b/src/cpu/aarch64/acl_depthwise_convolution.hpp\n-@@ -0,0 +1,137 @@\n+@@ -0,0 +1,139 @@\n +/*******************************************************************************\n +* Copyright 2022 Arm Ltd. and affiliates\n +*\n@@ -266,7 +266,9 @@ index 000000000..97e0a3a30\n +            &acl_obj_->wei_tensor,\n +            acp.with_bias ? &acl_obj_->bia_tensor : nullptr,\n +            &acl_obj_->dst_tensor,\n-+            acp.padstride_info);\n++            acp.padstride_info,\n++            1, // depth multiplier default value\n++            acp.act_info);\n +\n +        // clang-format on\n +        return status::success;\ndiff --git a/third_party/mkl_dnn/onednn_acl_fixed_format_kernels.patch b/third_party/mkl_dnn/onednn_acl_fixed_format_kernels.patch\nindex 02b25db914777..2c8af08ab8a4f 100644\n--- a/third_party/mkl_dnn/onednn_acl_fixed_format_kernels.patch\n+++ b/third_party/mkl_dnn/onednn_acl_fixed_format_kernels.patch\n@@ -14,12 +14,12 @@\n  See the License for the specific language governing permissions and\n  limitations under the License.\n  *******************************************************************************\n- \n+\n diff --git a/src/cpu/aarch64/acl_convolution_utils.cpp b/src/cpu/aarch64/acl_convolution_utils.cpp\n-index c46d69757..6a840b973 100644\n+index c46d69757..fc93d2aa9 100644\n --- a/src/cpu/aarch64/acl_convolution_utils.cpp\n +++ b/src/cpu/aarch64/acl_convolution_utils.cpp\n-@@ -212,6 +212,82 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -212,6 +212,87 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,\n                  arm_compute::QuantizationInfo(1.0f / scales[0], 0));\n      }\n  \n@@ -82,6 +82,11 @@ index c46d69757..6a840b973 100644\n +    want_wei_md.format_desc.blocking.strides[2] = interleaved_by*ic_multiply*kw;\n +    want_wei_md.format_desc.blocking.strides[3] = interleaved_by*ic_multiply;\n +\n++    acl_utils::update_strides_y_and_z(\n++        acp.wei_info,\n++        want_wei_md.format_desc.blocking.strides[0] * wei_d.data_type_size(),\n++        acp.wei_info.strides_in_bytes().z());\n++\n +    // Set blocking\n +    want_wei_md.format_desc.blocking.inner_nblks = (block_by > 1) + 1;\n +    want_wei_md.format_desc.blocking.inner_idxs[0] = 0; // second to last dimension in abcd format\n@@ -102,7 +107,7 @@ index c46d69757..6a840b973 100644\n      return status::success;\n  }\n  \n-@@ -219,6 +295,7 @@ status_t init_conf_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -219,6 +300,7 @@ status_t init_conf_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n          memory_desc_t &weights_md, memory_desc_t &dst_md,\n          memory_desc_t &bias_md, const convolution_desc_t &cd,\n          const primitive_attr_t &attr) {\n@@ -110,7 +115,7 @@ index c46d69757..6a840b973 100644\n  \n      // General Compute Library checks, memory tags are also set there\n      CHECK(acl_init_conf(acp, src_md, weights_md, dst_md, bias_md, cd, attr));\n-@@ -244,11 +321,13 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -244,11 +326,13 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n          memory_desc_t &weights_md, memory_desc_t &dst_md,\n          memory_desc_t &bias_md, const convolution_desc_t &cd,\n          const primitive_attr_t &attr) {\n@@ -125,7 +130,7 @@ index c46d69757..6a840b973 100644\n          return status::unimplemented;\n      }\n  \n-@@ -275,6 +354,7 @@ status_t init_conf_wino(acl_conv_conf_t &acp, memory_desc_t &src_md,\n+@@ -275,6 +359,7 @@ status_t init_conf_wino(acl_conv_conf_t &acp, memory_desc_t &src_md,\n          memory_desc_t &weights_md, memory_desc_t &dst_md,\n          memory_desc_t &bias_md, const convolution_desc_t &cd,\n          const primitive_attr_t &attr) {\n@@ -169,7 +174,7 @@ index bcf031a77..4ddc8cf91 100644\n  \n          return status::success;\n diff --git a/src/cpu/aarch64/acl_inner_product.hpp b/src/cpu/aarch64/acl_inner_product.hpp\n-index c5e507085..15ea61173 100644\n+index c5e507085..163ff066e 100644\n --- a/src/cpu/aarch64/acl_inner_product.hpp\n +++ b/src/cpu/aarch64/acl_inner_product.hpp\n @@ -45,6 +45,7 @@ struct acl_ip_conf_t {\n@@ -238,7 +243,7 @@ index c5e507085..15ea61173 100644\n  \n              // Fast math mode\n              auto math_mode = get_fpmath_mode();\n-@@ -214,6 +212,74 @@ struct acl_inner_product_fwd_t : public primitive_t {\n+@@ -214,6 +212,80 @@ struct acl_inner_product_fwd_t : public primitive_t {\n                      aip.fc_info.activation_info));\n              aip.use_dst_acc = post_ops.has_sum();\n  \n@@ -296,6 +301,12 @@ index c5e507085..15ea61173 100644\n +                want_wei_md.padded_dims[0] = padded_dim;\n +            }\n +\n++            int data_type_size = memory_desc_wrapper(want_wei_md).data_type_size();\n++            acl_utils::update_strides_y_and_z(\n++                aip.wei_info,\n++                want_wei_md.format_desc.blocking.strides[0] * data_type_size,\n++                want_wei_md.format_desc.blocking.strides[1] * data_type_size);\n++\n +            want_wei_md.format_desc.blocking.inner_nblks = (block_by > 1) + 1;\n +            want_wei_md.format_desc.blocking.inner_idxs[0] = 0;\n +            want_wei_md.format_desc.blocking.inner_blks[0] = interleaved_by;\n@@ -313,8 +324,55 @@ index c5e507085..15ea61173 100644\n              // clang-format off\n              // Validate fully connected layer manually to check for return status\n              ACL_CHECK_VALID(arm_compute::NEFullyConnectedLayer::validate(\n+diff --git a/src/cpu/aarch64/acl_utils.cpp b/src/cpu/aarch64/acl_utils.cpp\n+index 79ea775d6..7ee4c7398 100644\n+--- a/src/cpu/aarch64/acl_utils.cpp\n++++ b/src/cpu/aarch64/acl_utils.cpp\n+@@ -157,6 +157,28 @@ status_t tensor_info(\n+     return status::success;\n+ }\n+ \n++status_t update_strides_y_and_z(\n++    arm_compute::TensorInfo &info, const int y, const int z) {\n++\n++    arm_compute::TensorShape shape = info.tensor_shape();\n++    arm_compute::Strides old_strides_in_bytes = info.strides_in_bytes();\n++\n++    arm_compute::Strides new_strides_in_bytes;\n++    for(size_t i = 0; i < shape.num_dimensions(); ++i) {\n++        new_strides_in_bytes.set(i, old_strides_in_bytes[i]);\n++    }\n++\n++    // set y\n++    new_strides_in_bytes.set(1, y);\n++    // set z\n++    new_strides_in_bytes.set(2, z);\n++\n++    info.init(info.tensor_shape(), info.num_channels(), info.data_type(),\n++            new_strides_in_bytes, info.offset_first_element_in_bytes(), info.total_size());\n++\n++    return status::success;\n++}\n++\n+ status_t insert_singleton_dimension(arm_compute::TensorInfo &ti, size_t dim_i) {\n+ \n+     // Max 6 dims in ACL, so we can\'t insert another\n+diff --git a/src/cpu/aarch64/acl_utils.hpp b/src/cpu/aarch64/acl_utils.hpp\n+index 28693bb16..c7c9e1278 100644\n+--- a/src/cpu/aarch64/acl_utils.hpp\n++++ b/src/cpu/aarch64/acl_utils.hpp\n+@@ -62,6 +62,9 @@ status_t tensor_info(arm_compute::TensorInfo &info, const memory_desc_t &md);\n+ status_t tensor_info(\n+         arm_compute::TensorInfo &info, const memory_desc_wrapper &md);\n+ \n++// Update y and z strides in arm_compute::TensorInfo\n++status_t update_strides_y_and_z(arm_compute::TensorInfo &info, const int y, const int z);\n++\n+ // Insert a dimension of size 1 at the index dim_i of TensorInfo\n+ status_t insert_singleton_dimension(arm_compute::TensorInfo &ti, size_t dim_i);\n+ \n diff --git a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp\n-index 679baec3a..4aa219376 100644\n+index 679baec3a..853277e37 100644\n --- a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp\n +++ b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp\n @@ -66,15 +66,12 @@ status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,\n@@ -335,7 +393,7 @@ index 679baec3a..4aa219376 100644\n  \n      amp.src_info = arm_compute::TensorInfo(\n              arm_compute::TensorShape(K, M, 1, src_batch), 1,\n-@@ -103,6 +100,125 @@ status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,\n+@@ -103,6 +100,140 @@ status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,\n          ACL_CHECK_VALID(arm_compute::NETranspose::validate(\n                  &amp.wei_acc_info, &amp.wei_info));\n  \n@@ -389,6 +447,11 @@ index 679baec3a..4aa219376 100644\n +                want_wei_md.padded_dims[1] = utils::div_up(want_wei_md.dims[1], interleaved_by) * interleaved_by;\n +            }\n +\n++            acl_utils::update_strides_y_and_z(\n++                amp.wei_info,\n++                want_wei_md.format_desc.blocking.strides[1] * wei_d.data_type_size(),\n++                want_wei_md.format_desc.blocking.strides[0] * wei_d.data_type_size());\n++\n +            blocked_first_dimension = 1;\n +            blocked_second_dimension = 0;\n +\n@@ -408,6 +471,11 @@ index 679baec3a..4aa219376 100644\n +           }\n +           want_wei_md.format_desc.blocking.strides[0] = want_wei_md.padded_dims[2] * want_wei_md.padded_dims[1];\n +\n++           acl_utils::update_strides_y_and_z(\n++                amp.wei_info,\n++                want_wei_md.format_desc.blocking.strides[2] * wei_d.data_type_size(),\n++                want_wei_md.format_desc.blocking.strides[0] * wei_d.data_type_size());\n++\n +           blocked_first_dimension = 2;\n +           blocked_second_dimension = 1;\n +\n@@ -434,6 +502,11 @@ index 679baec3a..4aa219376 100644\n +            want_wei_md.format_desc.blocking.strides[2] = interleaved_by*block_by;\n +            want_wei_md.format_desc.blocking.strides[3] = interleaved_by*C_padded;\n +\n++            acl_utils::update_strides_y_and_z(\n++                amp.wei_info,\n++                want_wei_md.format_desc.blocking.strides[3] * wei_d.data_type_size(),\n++                want_wei_md.format_desc.blocking.strides[1] * wei_d.data_type_size());\n++\n +            blocked_first_dimension = 3;\n +            blocked_second_dimension = 2;\n +\n'","['Declare strides when ACL objects init and activation in ACL depthwise conv\n\nThe following fixes are in PR:\n\n(1) Since when we are configuring ACL objects we know exactly what is expected formats for weights so we should set strides at that point and not leave it to ACL to estimate based on weights dimensions,\n\n(2) If depthwise convolution comes with post op that converts to ACL’s activation layer operation we were not executing that activation function because the convolution was not configured with it.']",[],2022-10-26 12:35:19
58314,"r2.8 cherry-pick: 77e710d7744 ""Upgrade sqlite to 3.39.4""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/77e710d7744be740d515b0318176e1925ff0bd25,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex 9ad26d289a048..0129ff7f4203e 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -299,10 +299,10 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""org_sqlite"",\n         build_file = ""//third_party:sqlite.BUILD"",\n-        sha256 = ""87775784f8b22d0d0f1d7811870d39feaa7896319c7c20b849a4181c5a50609b"",\n-        strip_prefix = ""sqlite-amalgamation-3390200"",\n+        sha256 = ""9c99955b21d2374f3a385d67a1f64cbacb1d4130947473d25c77ad609c03b4cd"",\n+        strip_prefix = ""sqlite-amalgamation-3390400"",\n         system_build_file = ""//third_party/systemlibs:sqlite.BUILD"",\n-        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390200.zip""),\n+        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390400.zip""),\n     )\n \n     tf_http_archive(\n'",['Upgrade sqlite to 3.39.4\n\nThis is urgently needed due to https://blog.trailofbits.com/2022/10/25/sqlite-vulnerability-july-2022-library-api/\n\nPiperOrigin-RevId: 483738307'],[],2022-10-25 20:59:39
58313,"r2.10 cherry-pick: 77e710d7744 ""Upgrade sqlite to 3.39.4""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/77e710d7744be740d515b0318176e1925ff0bd25,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex e255103df986c..56c5832208543 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -308,10 +308,10 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""org_sqlite"",\n         build_file = ""//third_party:sqlite.BUILD"",\n-        sha256 = ""87775784f8b22d0d0f1d7811870d39feaa7896319c7c20b849a4181c5a50609b"",\n-        strip_prefix = ""sqlite-amalgamation-3390200"",\n+        sha256 = ""9c99955b21d2374f3a385d67a1f64cbacb1d4130947473d25c77ad609c03b4cd"",\n+        strip_prefix = ""sqlite-amalgamation-3390400"",\n         system_build_file = ""//third_party/systemlibs:sqlite.BUILD"",\n-        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390200.zip""),\n+        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390400.zip""),\n     )\n \n     tf_http_archive(\n'",['Upgrade sqlite to 3.39.4\n\nThis is urgently needed due to https://blog.trailofbits.com/2022/10/25/sqlite-vulnerability-july-2022-library-api/\n\nPiperOrigin-RevId: 483738307'],[],2022-10-25 20:59:28
58312,"r2.9 cherry-pick: 77e710d7744 ""Upgrade sqlite to 3.39.4""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/77e710d7744be740d515b0318176e1925ff0bd25,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex c9d2c75ab170d..1354f92cf56b9 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -300,10 +300,10 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""org_sqlite"",\n         build_file = ""//third_party:sqlite.BUILD"",\n-        sha256 = ""87775784f8b22d0d0f1d7811870d39feaa7896319c7c20b849a4181c5a50609b"",\n-        strip_prefix = ""sqlite-amalgamation-3390200"",\n+        sha256 = ""9c99955b21d2374f3a385d67a1f64cbacb1d4130947473d25c77ad609c03b4cd"",\n+        strip_prefix = ""sqlite-amalgamation-3390400"",\n         system_build_file = ""//third_party/systemlibs:sqlite.BUILD"",\n-        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390200.zip""),\n+        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390400.zip""),\n     )\n \n     tf_http_archive(\n'",['Upgrade sqlite to 3.39.4\n\nThis is urgently needed due to https://blog.trailofbits.com/2022/10/25/sqlite-vulnerability-july-2022-library-api/\n\nPiperOrigin-RevId: 483738307'],[],2022-10-25 20:59:14
58311,"r2.11 cherry-pick: 77e710d7744 ""Upgrade sqlite to 3.39.4""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/77e710d7744be740d515b0318176e1925ff0bd25,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex aee820d6e4025..a9a7665cdbb33 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -311,10 +311,10 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""org_sqlite"",\n         build_file = ""//third_party:sqlite.BUILD"",\n-        sha256 = ""87775784f8b22d0d0f1d7811870d39feaa7896319c7c20b849a4181c5a50609b"",\n-        strip_prefix = ""sqlite-amalgamation-3390200"",\n+        sha256 = ""9c99955b21d2374f3a385d67a1f64cbacb1d4130947473d25c77ad609c03b4cd"",\n+        strip_prefix = ""sqlite-amalgamation-3390400"",\n         system_build_file = ""//third_party/systemlibs:sqlite.BUILD"",\n-        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390200.zip""),\n+        urls = tf_mirror_urls(""https://www.sqlite.org/2022/sqlite-amalgamation-3390400.zip""),\n     )\n \n     tf_http_archive(\n'",['Upgrade sqlite to 3.39.4\n\nThis is urgently needed due to https://blog.trailofbits.com/2022/10/25/sqlite-vulnerability-july-2022-library-api/\n\nPiperOrigin-RevId: 483738307'],[],2022-10-25 20:59:11
58309,"r2.11 cherry-pick: a40f9be4ded ""Fix strided slice bug where output is always writes at least one element.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a40f9be4ded6433478b81331b31c9adf817b49b5,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/lite/kernels/internal/BUILD b/tensorflow/lite/kernels/internal/BUILD\nindex 6d377d7c8e8b0..5038f7ec11a60 100644\n--- a/tensorflow/lite/kernels/internal/BUILD\n+++ b/tensorflow/lite/kernels/internal/BUILD\n@@ -1077,7 +1077,6 @@ cc_test(\n     srcs = [\n         ""strided_slice_logic_test.cc"",\n     ],\n-    shard_count = 4,\n     deps = [\n         "":strided_slice_logic"",\n         ""@com_google_googletest//:gtest_main"",\ndiff --git a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\nindex d76fa11204524..154340d2c76b6 100644\n--- a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n+++ b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n@@ -4673,108 +4673,6 @@ inline void Slice(const tflite::SliceParams& op_params,\n   return Slice(op_params, input_shape, output_shape, &writer);\n }\n \n-// Note: This implementation is only optimized for the case where the inner\n-// stride == 1.\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const RuntimeShape& unextended_output_shape,\n-                         SequentialTensorWriter<T>* writer) {\n-  using strided_slice::LoopCondition;\n-  using strided_slice::StartForAxis;\n-  using strided_slice::StopForAxis;\n-\n-  ruy::profiler::ScopeLabel label(""StridedSlice"");\n-\n-  // Note that the output_shape is not used herein.\n-  tflite::StridedSliceParams params_copy = op_params;\n-\n-  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 5);\n-  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 5);\n-  const RuntimeShape input_shape =\n-      RuntimeShape::ExtendedShape(5, unextended_input_shape);\n-  const RuntimeShape output_shape =\n-      RuntimeShape::ExtendedShape(5, unextended_output_shape);\n-\n-  // Reverse and pad to 5 dimensions because that is what the runtime code\n-  // requires (ie. all shapes must be 5D and are given backwards).\n-  strided_slice::StridedSlicePadIndices(&params_copy, 5);\n-\n-  const int start_0 = StartForAxis(params_copy, input_shape, 0);\n-  const int stop_0 = StopForAxis(params_copy, input_shape, 0, start_0);\n-  const int start_1 = StartForAxis(params_copy, input_shape, 1);\n-  const int stop_1 = StopForAxis(params_copy, input_shape, 1, start_1);\n-  const int start_2 = StartForAxis(params_copy, input_shape, 2);\n-  const int stop_2 = StopForAxis(params_copy, input_shape, 2, start_2);\n-  const int start_3 = StartForAxis(params_copy, input_shape, 3);\n-  const int stop_3 = StopForAxis(params_copy, input_shape, 3, start_3);\n-  const int start_4 = StartForAxis(params_copy, input_shape, 4);\n-  const int stop_4 = StopForAxis(params_copy, input_shape, 4, start_4);\n-  const bool inner_stride_is_1 = params_copy.strides[4] == 1;\n-\n-  for (int offset_0 = start_0 * input_shape.Dims(1),\n-           end_0 = stop_0 * input_shape.Dims(1),\n-           step_0 = params_copy.strides[0] * input_shape.Dims(1);\n-       !LoopCondition(offset_0, end_0, params_copy.strides[0]);\n-       offset_0 += step_0) {\n-    for (int offset_1 = (offset_0 + start_1) * input_shape.Dims(2),\n-             end_1 = (offset_0 + stop_1) * input_shape.Dims(2),\n-             step_1 = params_copy.strides[1] * input_shape.Dims(2);\n-         !LoopCondition(offset_1, end_1, params_copy.strides[1]);\n-         offset_1 += step_1) {\n-      for (int offset_2 = (offset_1 + start_2) * input_shape.Dims(3),\n-               end_2 = (offset_1 + stop_2) * input_shape.Dims(3),\n-               step_2 = params_copy.strides[2] * input_shape.Dims(3);\n-           !LoopCondition(offset_2, end_2, params_copy.strides[2]);\n-           offset_2 += step_2) {\n-        for (int offset_3 = (offset_2 + start_3) * input_shape.Dims(4),\n-                 end_3 = (offset_2 + stop_3) * input_shape.Dims(4),\n-                 step_3 = params_copy.strides[3] * input_shape.Dims(4);\n-             !LoopCondition(offset_3, end_3, params_copy.strides[3]);\n-             offset_3 += step_3) {\n-          // When the stride is 1, the inner loop is equivalent to the\n-          // optimized slice inner loop. Otherwise, it is identical to the\n-          // strided_slice reference implementation inner loop.\n-          if (inner_stride_is_1) {\n-            const int len = stop_4 - start_4;\n-            if (len > 0) {\n-              writer->WriteN(offset_3 + start_4, len);\n-            }\n-          } else {\n-            for (int offset_4 = offset_3 + start_4, end_4 = offset_3 + stop_4;\n-                 !LoopCondition(offset_4, end_4, params_copy.strides[4]);\n-                 offset_4 += params_copy.strides[4]) {\n-              writer->Write(offset_4);\n-            }\n-          }\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const T* input_data,\n-                         const RuntimeShape& unextended_output_shape,\n-                         T* output_data) {\n-  SequentialTensorWriter<T> writer(input_data, output_data);\n-  StridedSlice<T>(op_params, unextended_input_shape, unextended_output_shape,\n-                  &writer);\n-}\n-\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const TfLiteTensor* input,\n-                         const RuntimeShape& unextended_output_shape,\n-                         TfLiteTensor* output) {\n-  SequentialTensorWriter<T> writer(input, output);\n-  StridedSlice<T>(op_params, unextended_input_shape, unextended_output_shape,\n-                  &writer);\n-}\n-\n template <typename T>\n void Minimum(const RuntimeShape& input1_shape, const T* input1_data,\n              const T* input2_data, const RuntimeShape& output_shape,\ndiff --git a/tensorflow/lite/kernels/internal/reference/strided_slice.h b/tensorflow/lite/kernels/internal/reference/strided_slice.h\nindex 40dc2e9102201..ff367cf95f19b 100644\n--- a/tensorflow/lite/kernels/internal/reference/strided_slice.h\n+++ b/tensorflow/lite/kernels/internal/reference/strided_slice.h\n@@ -31,10 +31,6 @@ inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n                          const RuntimeShape& unextended_input_shape,\n                          const RuntimeShape& unextended_output_shape,\n                          SequentialTensorWriter<T>* writer) {\n-  using strided_slice::LoopCondition;\n-  using strided_slice::StartForAxis;\n-  using strided_slice::StopForAxis;\n-\n   ruy::profiler::ScopeLabel label(""StridedSlice"");\n \n   // Note that the output_shape is not used herein.\n@@ -51,41 +47,67 @@ inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n   // requires (ie. all shapes must be 5D and are given backwards).\n   strided_slice::StridedSlicePadIndices(&params_copy, 5);\n \n-  const int start_0 = StartForAxis(params_copy, input_shape, 0);\n-  const int stop_0 = StopForAxis(params_copy, input_shape, 0, start_0);\n-  const int start_1 = StartForAxis(params_copy, input_shape, 1);\n-  const int stop_1 = StopForAxis(params_copy, input_shape, 1, start_1);\n-  const int start_2 = StartForAxis(params_copy, input_shape, 2);\n-  const int stop_2 = StopForAxis(params_copy, input_shape, 2, start_2);\n-  const int start_3 = StartForAxis(params_copy, input_shape, 3);\n-  const int stop_3 = StopForAxis(params_copy, input_shape, 3, start_3);\n-  const int start_4 = StartForAxis(params_copy, input_shape, 4);\n-  const int stop_4 = StopForAxis(params_copy, input_shape, 4, start_4);\n-\n-  for (int offset_0 = start_0 * input_shape.Dims(1),\n-           end_0 = stop_0 * input_shape.Dims(1),\n-           step_0 = params_copy.strides[0] * input_shape.Dims(1);\n-       !LoopCondition(offset_0, end_0, params_copy.strides[0]);\n-       offset_0 += step_0) {\n-    for (int offset_1 = (offset_0 + start_1) * input_shape.Dims(2),\n-             end_1 = (offset_0 + stop_1) * input_shape.Dims(2),\n-             step_1 = params_copy.strides[1] * input_shape.Dims(2);\n-         !LoopCondition(offset_1, end_1, params_copy.strides[1]);\n-         offset_1 += step_1) {\n-      for (int offset_2 = (offset_1 + start_2) * input_shape.Dims(3),\n-               end_2 = (offset_1 + stop_2) * input_shape.Dims(3),\n-               step_2 = params_copy.strides[2] * input_shape.Dims(3);\n-           !LoopCondition(offset_2, end_2, params_copy.strides[2]);\n-           offset_2 += step_2) {\n-        for (int offset_3 = (offset_2 + start_3) * input_shape.Dims(4),\n-                 end_3 = (offset_2 + stop_3) * input_shape.Dims(4),\n-                 step_3 = params_copy.strides[3] * input_shape.Dims(4);\n-             !LoopCondition(offset_3, end_3, params_copy.strides[3]);\n-             offset_3 += step_3) {\n-          for (int offset_4 = offset_3 + start_4, end_4 = offset_3 + stop_4;\n-               !LoopCondition(offset_4, end_4, params_copy.strides[4]);\n-               offset_4 += params_copy.strides[4]) {\n-            writer->Write(offset_4);\n+  const int start_0 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 0);\n+  const int stop_0 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 0, start_0);\n+  const int start_1 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 1);\n+  const int stop_1 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 1, start_1);\n+  const int start_2 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 2);\n+  const int stop_2 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 2, start_2);\n+  const int start_3 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 3);\n+  const int stop_3 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 3, start_3);\n+  const int start_4 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 4);\n+  const int stop_4 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 4, start_4);\n+\n+  auto lc = [&](int end, int stride, int index) {\n+    if (stride < 0) {\n+      return index > end;\n+    } else {\n+      return index < end;\n+    }\n+  };\n+  const int* shape = input_shape.DimsData();\n+  const int* stride = params_copy.strides;\n+  const bool inner_stride_is_1 = params_copy.strides[4] == 1;\n+\n+  for (int offset_0 = start_0; lc(stop_0, stride[0], offset_0);\n+       offset_0 += stride[0]) {\n+    for (int offset_1 = start_1; lc(stop_1, stride[1], offset_1);\n+         offset_1 += stride[1]) {\n+      for (int offset_2 = start_2; lc(stop_2, stride[2], offset_2);\n+           offset_2 += stride[2]) {\n+        for (int offset_3 = start_3; lc(stop_3, stride[3], offset_3);\n+             offset_3 += stride[3]) {\n+          // When the stride is 1, the inner loop is equivalent to the\n+          // optimized slice inner loop. Otherwise, it is identical to the\n+          // strided_slice reference implementation inner loop.\n+          if (inner_stride_is_1) {\n+            const int len = stop_4 - start_4;\n+            int index = start_4 + offset_3 * shape[4] +\n+                        offset_2 * shape[3] * shape[4] +\n+                        offset_1 * shape[2] * shape[3] * shape[4] +\n+                        offset_0 * shape[1] * shape[2] * shape[3] * shape[4];\n+            if (len > 0) {\n+              writer->WriteN(index, len);\n+            }\n+          } else {\n+            for (int offset_4 = start_4; lc(stop_4, stride[4], offset_4);\n+                 offset_4 += stride[4]) {\n+              int index = offset_4 + offset_3 * shape[4] +\n+                          offset_2 * shape[3] * shape[4] +\n+                          offset_1 * shape[2] * shape[3] * shape[4] +\n+                          offset_0 * shape[1] * shape[2] * shape[3] * shape[4];\n+              writer->Write(index);\n+            }\n           }\n         }\n       }\ndiff --git a/tensorflow/lite/kernels/internal/strided_slice_logic.h b/tensorflow/lite/kernels/internal/strided_slice_logic.h\nindex bfe84050dca15..2efdcf26fe07a 100644\n--- a/tensorflow/lite/kernels/internal/strided_slice_logic.h\n+++ b/tensorflow/lite/kernels/internal/strided_slice_logic.h\n@@ -69,6 +69,69 @@ inline void StridedSlicePadIndices(tflite::StridedSliceParams* p,\n   p->strides_count = dim_count;\n }\n \n+// Return the index for the first element along that axis. This index will be a\n+// positive integer between [0, axis_size] (or [-1, axis_size -1] if stride < 0)\n+// that can be used to index directly into the data.\n+inline int StridedSliceStartForAxis(const tflite::StridedSliceParams& params,\n+                                    const RuntimeShape& input_shape,\n+                                    int32_t axis) {\n+  const int32_t axis_size = input_shape.Dims(axis);\n+  int32_t start = params.start_indices[axis];\n+  const int32_t stride = params.strides[axis];\n+  const int32_t begin_mask = (params.begin_mask & 1 << axis);\n+  if (start < 0) {\n+    start += axis_size;\n+  }\n+  if (stride > 0) {\n+    start = Clamp(start, 0, axis_size);\n+  } else {\n+    start = Clamp(start, -1, axis_size - 1);\n+  }\n+  if (begin_mask) {\n+    if (stride > 0) {\n+      start = 0;\n+    } else {\n+      start = axis_size - 1;\n+    }\n+  }\n+  return start;\n+}\n+\n+inline int StridedSliceEndForAxis(const tflite::StridedSliceParams& params,\n+                                  const RuntimeShape& input_shape, int axis,\n+                                  int start) {\n+  const auto shrink_axis_mask = params.shrink_axis_mask;\n+  const bool shrink_axis = shrink_axis_mask & (1 << axis);\n+  const int axis_size = input_shape.Dims(axis);\n+  if (shrink_axis) {\n+    if (start >= axis_size) {\n+      return start;\n+    } else {\n+      return start + 1;\n+    }\n+  }\n+  const auto* indices = params.stop_indices;\n+  int end = indices[axis];\n+  const int32_t stride = params.strides[axis];\n+  const int32_t end_mask = (params.end_mask & 1 << axis);\n+  if (end < 0) {\n+    end += axis_size;\n+  }\n+  if (stride > 0) {\n+    end = Clamp(end, 0, axis_size);\n+  } else {\n+    end = Clamp(end, -1, axis_size - 1);\n+  }\n+  if (end_mask) {\n+    if (stride > 0) {\n+      end = axis_size;\n+    } else {\n+      end = -1;\n+    }\n+  }\n+  return end;\n+}\n+\n // Return the index for the first element along that axis. This index will be a\n // positive integer between [0, axis_size] (or [-1, axis_size -1] if stride < 0)\n // that can be used to index directly into the data.\ndiff --git a/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc b/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\nindex b48c647278b6a..d4aa8b94e141e 100644\n--- a/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\n+++ b/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\n@@ -78,5 +78,119 @@ TEST(RunStridedSlicePadIndices, Pad3) {\n   );\n }\n \n+TEST(StridedSliceStartForAxis, NegativeOOBIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -11;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, NegativeOneTheBoundaryIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -10;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, NegativeWithinBoundsIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -9;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 1);\n+}\n+\n+TEST(StridedSliceStartForAxis, MinusOneIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -1;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 9);\n+}\n+\n+TEST(StridedSliceStartForAxis, ZeroIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 0;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, OneIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 1;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 1);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveBoundaryIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 9;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 9);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveOOBIndexSizeofArray) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 10;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 10);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveOOBIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 11;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 10);\n+}\n+\n+TEST(StridedSliceStartForAxis, TenFourMinus1) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 5;\n+  params.stop_indices[0] = 2;\n+  params.strides[0] = -1;\n+  int start = strided_slice::StridedSliceStartForAxis(params, RuntimeShape({4}),\n+                                                      /*axis=*/0);\n+  int stop = strided_slice::StridedSliceEndForAxis(params, RuntimeShape({4}),\n+                                                   /*axis=*/0, start);\n+  EXPECT_EQ(start, 3);\n+  EXPECT_EQ(stop, 2);\n+}\n+\n }  // namespace\n }  // namespace tflite\ndiff --git a/tensorflow/lite/kernels/strided_slice.cc b/tensorflow/lite/kernels/strided_slice.cc\nindex ffcf7c2a0fc4a..34d3d8be72ce3 100644\n--- a/tensorflow/lite/kernels/strided_slice.cc\n+++ b/tensorflow/lite/kernels/strided_slice.cc\n@@ -24,7 +24,6 @@ limitations under the License.\n #include ""tensorflow/lite/c/builtin_op_data.h""\n #include ""tensorflow/lite/c/common.h""\n #include ""tensorflow/lite/kernels/internal/compatibility.h""\n-#include ""tensorflow/lite/kernels/internal/optimized/optimized_ops.h""\n #include ""tensorflow/lite/kernels/internal/strided_slice_logic.h""\n #include ""tensorflow/lite/kernels/internal/tensor.h""\n #include ""tensorflow/lite/kernels/internal/tensor_ctypes.h""\n@@ -70,7 +69,7 @@ struct StridedSliceContext {\n };\n \n StridedSliceParams BuildStridedSliceParams(StridedSliceContext* op_context) {\n-  StridedSliceParams op_params;\n+  StridedSliceParams op_params{};\n \n   // The ellipsis_mask and new_axis_mask in op_params are not used. Those masks\n   // are processed here to update begin_mask, end_mask and the index range.\n@@ -196,9 +195,9 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n     int32_t stride = op_params.strides[idx];\n     TF_LITE_ENSURE_MSG(context, stride != 0, ""stride value has to be non-zero"");\n \n-    int32_t begin = ::tflite::strided_slice::StartForAxis(\n+    int32_t begin = ::tflite::strided_slice::StridedSliceStartForAxis(\n         op_params, effective_input_shape, idx);\n-    int32_t end = ::tflite::strided_slice::StopForAxis(\n+    int32_t end = ::tflite::strided_slice::StridedSliceEndForAxis(\n         op_params, effective_input_shape, idx, begin);\n \n     // When shrinking an axis, the end position does not matter (and can be\n@@ -272,43 +271,46 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   }\n   StridedSliceParams op_params = BuildStridedSliceParams(&op_context);\n \n-#define TF_LITE_STRIDED_SLICE(data_type)                                 \\\n-  {                                                                      \\\n-    if (kernel_type == kGenericOptimized) {                              \\\n-      optimized_ops::StridedSlice<data_type>(                            \\\n-          op_params, op_context.effective_input_shape, op_context.input, \\\n-          GetTensorShape(op_context.output), op_context.output);         \\\n-    } else {                                                             \\\n-      reference_ops::StridedSlice<data_type>(                            \\\n-          op_params, op_context.effective_input_shape, op_context.input, \\\n-          GetTensorShape(op_context.output), op_context.output);         \\\n-    }                                                                    \\\n-  }\n-\n   switch (op_context.input->type) {\n     case kTfLiteFloat32:\n-      TF_LITE_STRIDED_SLICE(float);\n+      reference_ops::StridedSlice<float>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt32:\n-      TF_LITE_STRIDED_SLICE(int32_t);\n+      reference_ops::StridedSlice<int32_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt64:\n-      TF_LITE_STRIDED_SLICE(int64_t);\n+      reference_ops::StridedSlice<int64_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteUInt8:\n-      TF_LITE_STRIDED_SLICE(uint8_t);\n+      reference_ops::StridedSlice<uint8_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt8:\n-      TF_LITE_STRIDED_SLICE(int8_t);\n+      reference_ops::StridedSlice<int8_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt16:\n-      TF_LITE_STRIDED_SLICE(int16_t);\n+      reference_ops::StridedSlice<int16_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteBool:\n-      TF_LITE_STRIDED_SLICE(bool);\n+      reference_ops::StridedSlice<bool>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteString:\n-      TF_LITE_STRIDED_SLICE(string);\n+      reference_ops::StridedSlice<string>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     default:\n       TF_LITE_KERNEL_LOG(context,\ndiff --git a/tensorflow/lite/kernels/strided_slice_test.cc b/tensorflow/lite/kernels/strided_slice_test.cc\nindex 1fe1974a1b3c1..41180435a2e6f 100644\n--- a/tensorflow/lite/kernels/strided_slice_test.cc\n+++ b/tensorflow/lite/kernels/strided_slice_test.cc\n@@ -27,6 +27,7 @@ namespace tflite {\n namespace {\n \n using ::testing::ElementsAreArray;\n+using ::testing::IsEmpty;\n \n template <typename input_type>\n class StridedSliceOpModel : public SingleOpModel {\n@@ -36,7 +37,7 @@ class StridedSliceOpModel : public SingleOpModel {\n                       std::initializer_list<int> end_shape,\n                       std::initializer_list<int> strides_shape, int begin_mask,\n                       int end_mask, int ellipsis_mask, int new_axis_mask,\n-                      int shrink_axis_mask) {\n+                      int shrink_axis_mask, bool use_simple_allocator = true) {\n     input_ = AddInput(GetTensorType<input_type>());\n     begin_ = AddInput(TensorType_INT32);\n     end_ = AddInput(TensorType_INT32);\n@@ -47,7 +48,8 @@ class StridedSliceOpModel : public SingleOpModel {\n         CreateStridedSliceOptions(builder_, begin_mask, end_mask, ellipsis_mask,\n                                   new_axis_mask, shrink_axis_mask)\n             .Union());\n-    BuildInterpreter({input_shape, begin_shape, end_shape, strides_shape});\n+    BuildInterpreter({input_shape, begin_shape, end_shape, strides_shape},\n+                     use_simple_allocator);\n   }\n \n   void SetInput(std::initializer_list<input_type> data) {\n@@ -670,7 +672,7 @@ TYPED_TEST(StridedSliceOpTest, In3D_SmallBeginWithhrinkAxis1) {\n   EXPECT_THAT(m.GetOutput(), ElementsAreArray({1, 2, 3, 4, 5, 6}));\n }\n \n-TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n+TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBeginEndMask) {\n   StridedSliceOpModel<TypeParam> m({1, 1, 2}, {1}, {1}, {1}, 0, 1, 0, 0, 0);\n   m.SetInput({1, 2});\n   m.SetBegin({1});\n@@ -680,6 +682,16 @@ TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n   EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0, 1, 2}));\n }\n \n+TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n+  StridedSliceOpModel<TypeParam> m({1, 1, 2}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2});\n+  m.SetBegin({1});\n+  m.SetEnd({0});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0, 1, 2}));\n+}\n+\n TYPED_TEST(StridedSliceOpTest, In3D_Backward) {\n   StridedSliceOpModel<TypeParam> m({1, 1, 2}, {3}, {3}, {3}, 6, 7, 0, 0, 0);\n   m.SetInput({1, 2});\n@@ -854,5 +866,86 @@ TYPED_TEST(StridedSliceOpTest, NoInfiniteLoop) {\n   ASSERT_EQ(m.Invoke(), kTfLiteOk);\n }\n \n+TYPED_TEST(StridedSliceOpTest, MinusThreeMinusFourMinusOne) {\n+  StridedSliceOpModel<TypeParam> m({4}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4});\n+  m.SetBegin({-3});\n+  m.SetEnd({-4});\n+  m.SetStrides({-1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({1}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({2}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, MinusFourMinusThreeOne) {\n+  StridedSliceOpModel<TypeParam> m({4}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4});\n+  m.SetBegin({-4});\n+  m.SetEnd({-3});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({1}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({1}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOne) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({2});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOneShrinkAxis) {\n+  StridedSliceOpModel<TypeParam> m({3}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetInput({1, 2, 3});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({2}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOneShrinkAxisOOB) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetInput({2});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OutOfBounds) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetBegin({1});\n+  m.SetEnd({2});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, StrideOutOfBounds) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetBegin({1});\n+  m.SetEnd({4});\n+  m.SetStrides({7});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, NegEndMask) {\n+  StridedSliceOpModel<TypeParam> m({2, 3}, {2}, {2}, {2}, 0, 0b10, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4, 5, 6});\n+  m.SetBegin({0, -1});\n+  m.SetEnd({2, -3});\n+  m.SetStrides({1, -1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({2, 3}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({3, 2, 1, 6, 5, 4}));\n+}\n }  // namespace\n }  // namespace tflite\ndiff --git a/tensorflow/lite/kernels/test_util.cc b/tensorflow/lite/kernels/test_util.cc\nindex e069701c7dc6c..6411974ad818b 100644\n--- a/tensorflow/lite/kernels/test_util.cc\n+++ b/tensorflow/lite/kernels/test_util.cc\n@@ -178,7 +178,8 @@ void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n                                      int num_threads,\n                                      bool allow_fp32_relax_to_fp16,\n                                      bool apply_delegate,\n-                                     bool allocate_and_delegate) {\n+                                     bool allocate_and_delegate,\n+                                     bool use_simple_allocator) {\n   input_shapes_ = input_shapes;\n   allow_fp32_relax_to_fp16_ = allow_fp32_relax_to_fp16;\n   apply_delegate_ = apply_delegate;\n@@ -203,7 +204,7 @@ void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n   uint8_t* buffer_pointer = builder_.GetBufferPointer();\n   UpdateOpVersion(buffer_pointer);\n \n-  bool use_simple_allocator =\n+  use_simple_allocator |=\n       tflite::KernelTestDelegateProviders::Get()->ConstParams().Get<bool>(\n           tflite::KernelTestDelegateProviders::kUseSimpleAllocator);\n \n@@ -288,11 +289,12 @@ TfLiteStatus SingleOpModel::ApplyDelegate() {\n \n TfLiteStatus SingleOpModel::Invoke() { return interpreter_->Invoke(); }\n \n-void SingleOpModel::BuildInterpreter(\n-    std::vector<std::vector<int>> input_shapes) {\n+void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n+                                     bool use_simple_allocator) {\n   BuildInterpreter(input_shapes, /*num_threads=*/-1,\n                    /*allow_fp32_relax_to_fp16=*/false,\n-                   /*apply_delegate=*/true, /*allocate_and_delegate=*/true);\n+                   /*apply_delegate=*/true, /*allocate_and_delegate=*/true,\n+                   use_simple_allocator);\n }\n \n // static\ndiff --git a/tensorflow/lite/kernels/test_util.h b/tensorflow/lite/kernels/test_util.h\nindex c4890c80635da..5c6841ece9162 100644\n--- a/tensorflow/lite/kernels/test_util.h\n+++ b/tensorflow/lite/kernels/test_util.h\n@@ -538,9 +538,11 @@ class SingleOpModel {\n   // `apply_delegate` is ignored.\n   void BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n                         int num_threads, bool allow_fp32_relax_to_fp16,\n-                        bool apply_delegate, bool allocate_and_delegate = true);\n+                        bool apply_delegate, bool allocate_and_delegate = true,\n+                        bool use_simple_allocator = false);\n \n-  void BuildInterpreter(std::vector<std::vector<int>> input_shapes);\n+  void BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n+                        bool use_simple_allocator = false);\n \n   // Executes inference and return status code.\n   TfLiteStatus Invoke();\n'","['Fix strided slice bug where output is always writes at least one element.\n\na[1:1:1] should be empty, but one element is written.\n\nPiperOrigin-RevId: 482436216']",[],2022-10-25 17:53:44
58307,"Revert ""Fix OOB error when op input sizes do not match.""",Reverts tensorflow/tensorflow#58059,vinila21,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex c4edc9fe6af06..4ad2e2d60aa2a 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -289,38 +289,8 @@ inline tensorflow::Fprint128 FingerprintCat128(const tensorflow::Fprint128& a,\n   return {x, tensorflow::FingerprintCat64(a.high64, x)};\n }\n \n-const KernelDef* GetKernelDef(const EagerOperation& op, const NodeDef* node_def,\n-                              const Device* op_device) {\n-  if (node_def == nullptr || op_device == nullptr) return nullptr;\n-  const KernelDef* kernel_def = nullptr;\n-  Status s = FindKernelDef(DeviceType(op_device->device_type()), *node_def,\n-                           &kernel_def,\n-                           /*kernel_class_name=*/nullptr);\n-  if (!s.ok()) return nullptr;\n-  return kernel_def;\n-}\n-\n-bool IsHostMemoryArg(const EagerOperation& op, const NodeDef* node_def,\n-                     const Device* op_device, const KernelDef* kernel_def,\n-                     const int port_id) {\n-  if (op.is_function()) return false;\n-  if (node_def == nullptr) return false;\n-  if (kernel_def == nullptr || op_device == nullptr) return false;\n-  const auto& host_memory_args = kernel_def->host_memory_arg();\n-  const OpDef& op_def = OpRegistry::Global()->LookUp(op.Name())->op_def;\n-  const int arg_id = OpPortIdToArgId(*node_def, op_def.input_arg(), port_id);\n-  // Fail if argument ID not found.\n-  if (arg_id < 0) {\n-    return false;\n-  }\n-  return std::find(host_memory_args.begin(), host_memory_args.end(),\n-                   op_def.input_arg(arg_id).name()) != host_memory_args.end();\n-}\n-\n-Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n-                         const bool is_host_memory_arg,\n-                         TensorHandle* tensor_handle, Device** result) {\n->>>>>>> f5381e0e10b (Fix OOB error when op input sizes do not match.)\n+Status GetDeviceForInput(const EagerContext& ctx, TensorHandle* tensor_handle,\n+                         Device** result) {\n   Device* cpu_device = ctx.HostCPU();\n   string device_name;\n   if (tensor_handle->Type() != TensorHandle::LOCAL) {\ndiff --git a/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py b/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py\nindex 05e0cb6be2925..28dc151aec6eb 100644\n--- a/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py\n+++ b/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py\n@@ -18,7 +18,6 @@\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n-from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import data_flow_ops\n@@ -309,29 +308,6 @@ def testHigherRankGPU(self):\n     for datum, grad in zip(data, self.evaluate(grads[3:])):\n       self.assertAllEqual(7.0 * self.evaluate(datum), grad)\n \n-  @test_util.run_in_graph_and_eager_modes\n-  def testMismatchedDataAndIndexListSizes(self):\n-    indices = [\n-        constant_op.constant([2]),\n-        constant_op.constant([1]),\n-        constant_op.constant([0]),\n-        constant_op.constant([3]),\n-    ]\n-    data = [\n-        constant_op.constant([1.0]),\n-        constant_op.constant([2.0]),\n-        constant_op.constant([3.0]),\n-        constant_op.constant([4.0])\n-    ]\n-    with self.assertRaisesRegex(\n-        (ValueError, errors.InvalidArgumentError),\n-        ""expected inputs .* do not match|List argument .* must match""):\n-      self.evaluate(data_flow_ops.dynamic_stitch(indices[0:2], data))\n-\n-    with self.assertRaisesRegex(\n-        (ValueError, errors.InvalidArgumentError),\n-        ""expected inputs .* do not match|List argument .* must match""):\n-      self.evaluate(data_flow_ops.dynamic_stitch(indices, data[0:2]))\n \n if __name__ == ""__main__"":\n   test.main()\n'","['Revert ""Fix OOB error when op input sizes do not match.""']",[],2022-10-25 17:45:03
58306,"Revert ""Fix OOB error when op input sizes do not match.""",Reverts tensorflow/tensorflow#58058,vinila21,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex 04c508ed52e79..98fe59ee274a5 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -290,38 +290,8 @@ inline tensorflow::Fprint128 FingerprintCat128(const tensorflow::Fprint128& a,\n   return {x, tensorflow::FingerprintCat64(a.high64, x)};\n }\n \n-const KernelDef* GetKernelDef(const EagerOperation& op, const NodeDef* node_def,\n-                              const Device* op_device) {\n-  if (node_def == nullptr || op_device == nullptr) return nullptr;\n-  const KernelDef* kernel_def = nullptr;\n-  Status s = FindKernelDef(DeviceType(op_device->device_type()), *node_def,\n-                           &kernel_def,\n-                           /*kernel_class_name=*/nullptr);\n-  if (!s.ok()) return nullptr;\n-  return kernel_def;\n-}\n-\n-bool IsHostMemoryArg(const EagerOperation& op, const NodeDef* node_def,\n-                     const Device* op_device, const KernelDef* kernel_def,\n-                     const int port_id) {\n-  if (op.is_function()) return false;\n-  if (node_def == nullptr) return false;\n-  if (kernel_def == nullptr || op_device == nullptr) return false;\n-  const auto& host_memory_args = kernel_def->host_memory_arg();\n-  const OpDef& op_def = OpRegistry::Global()->LookUp(op.Name())->op_def;\n-  const int arg_id = OpPortIdToArgId(*node_def, op_def.input_arg(), port_id);\n-  // Fail if argument ID not found.\n-  if (arg_id < 0) {\n-    return false;\n-  }\n-  return std::find(host_memory_args.begin(), host_memory_args.end(),\n-                   op_def.input_arg(arg_id).name()) != host_memory_args.end();\n-}\n-\n-Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n-                         const bool is_host_memory_arg,\n-                         TensorHandle* tensor_handle, Device** result) {\n->>>>>>> f5381e0e10b (Fix OOB error when op input sizes do not match.)\n+Status GetDeviceForInput(const EagerContext& ctx, TensorHandle* tensor_handle,\n+                         Device** result) {\n   Device* cpu_device = ctx.HostCPU();\n   string device_name;\n   if (tensor_handle->Type() != TensorHandle::LOCAL) {\ndiff --git a/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py b/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py\nindex 05e0cb6be2925..28dc151aec6eb 100644\n--- a/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py\n+++ b/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py\n@@ -18,7 +18,6 @@\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n-from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import data_flow_ops\n@@ -309,29 +308,6 @@ def testHigherRankGPU(self):\n     for datum, grad in zip(data, self.evaluate(grads[3:])):\n       self.assertAllEqual(7.0 * self.evaluate(datum), grad)\n \n-  @test_util.run_in_graph_and_eager_modes\n-  def testMismatchedDataAndIndexListSizes(self):\n-    indices = [\n-        constant_op.constant([2]),\n-        constant_op.constant([1]),\n-        constant_op.constant([0]),\n-        constant_op.constant([3]),\n-    ]\n-    data = [\n-        constant_op.constant([1.0]),\n-        constant_op.constant([2.0]),\n-        constant_op.constant([3.0]),\n-        constant_op.constant([4.0])\n-    ]\n-    with self.assertRaisesRegex(\n-        (ValueError, errors.InvalidArgumentError),\n-        ""expected inputs .* do not match|List argument .* must match""):\n-      self.evaluate(data_flow_ops.dynamic_stitch(indices[0:2], data))\n-\n-    with self.assertRaisesRegex(\n-        (ValueError, errors.InvalidArgumentError),\n-        ""expected inputs .* do not match|List argument .* must match""):\n-      self.evaluate(data_flow_ops.dynamic_stitch(indices, data[0:2]))\n \n if __name__ == ""__main__"":\n   test.main()\n'","['Revert ""Fix OOB error when op input sizes do not match.""']",[],2022-10-25 17:42:59
58305,"Revert ""Removed merge conflict marker""",Reverts tensorflow/tensorflow#58187,vinila21,['mihaimaruseac'],['Need to immediately be followed by the revert of the cherrypick'],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex 73a45e18a084a..04c508ed52e79 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -321,6 +321,7 @@ bool IsHostMemoryArg(const EagerOperation& op, const NodeDef* node_def,\n Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n                          const bool is_host_memory_arg,\n                          TensorHandle* tensor_handle, Device** result) {\n+>>>>>>> f5381e0e10b (Fix OOB error when op input sizes do not match.)\n   Device* cpu_device = ctx.HostCPU();\n   string device_name;\n   if (tensor_handle->Type() != TensorHandle::LOCAL) {\n'","['Revert ""Removed merge conflict marker""']",[],2022-10-25 17:36:50
58304,Resolving bad merge conflict in Cherry-pick,https://github.com/tensorflow/tensorflow/pull/58059,vinila21,['mihaimaruseac'],['This PR just complicates matters. The original PR needs to be reverted and the original fix cherrypicked properly.'],[],[],[],"b'diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex c4edc9fe6af06..a77bec657d19d 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -320,7 +320,6 @@ bool IsHostMemoryArg(const EagerOperation& op, const NodeDef* node_def,\n Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n                          const bool is_host_memory_arg,\n                          TensorHandle* tensor_handle, Device** result) {\n->>>>>>> f5381e0e10b (Fix OOB error when op input sizes do not match.)\n   Device* cpu_device = ctx.HostCPU();\n   string device_name;\n   if (tensor_handle->Type() != TensorHandle::LOCAL) {\n'",['Resolving bad merge conflict in Cherry-pick \n\nhttps://github.com/tensorflow/tensorflow/pull/58059'],[],2022-10-25 17:25:52
58303,"r2.9 cherry-pick: a40f9be4ded ""Fix strided slice bug where output is always writes at least one element.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a40f9be4ded6433478b81331b31c9adf817b49b5,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/lite/kernels/internal/BUILD b/tensorflow/lite/kernels/internal/BUILD\nindex 975aa0b470597..52591ad706da8 100644\n--- a/tensorflow/lite/kernels/internal/BUILD\n+++ b/tensorflow/lite/kernels/internal/BUILD\n@@ -1058,7 +1058,6 @@ cc_test(\n     srcs = [\n         ""strided_slice_logic_test.cc"",\n     ],\n-    shard_count = 4,\n     deps = [\n         "":strided_slice_logic"",\n         ""@com_google_googletest//:gtest_main"",\ndiff --git a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\nindex 500f2454da806..162d16d44848c 100644\n--- a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n+++ b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n@@ -5000,108 +5000,6 @@ inline void Slice(const tflite::SliceParams& op_params,\n   return Slice(op_params, input_shape, output_shape, &writer);\n }\n \n-// Note: This implementation is only optimized for the case where the inner\n-// stride == 1.\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const RuntimeShape& unextended_output_shape,\n-                         SequentialTensorWriter<T>* writer) {\n-  using strided_slice::LoopCondition;\n-  using strided_slice::StartForAxis;\n-  using strided_slice::StopForAxis;\n-\n-  ruy::profiler::ScopeLabel label(""StridedSlice"");\n-\n-  // Note that the output_shape is not used herein.\n-  tflite::StridedSliceParams params_copy = op_params;\n-\n-  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 5);\n-  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 5);\n-  const RuntimeShape input_shape =\n-      RuntimeShape::ExtendedShape(5, unextended_input_shape);\n-  const RuntimeShape output_shape =\n-      RuntimeShape::ExtendedShape(5, unextended_output_shape);\n-\n-  // Reverse and pad to 5 dimensions because that is what the runtime code\n-  // requires (ie. all shapes must be 5D and are given backwards).\n-  strided_slice::StridedSlicePadIndices(&params_copy, 5);\n-\n-  const int start_0 = StartForAxis(params_copy, input_shape, 0);\n-  const int stop_0 = StopForAxis(params_copy, input_shape, 0, start_0);\n-  const int start_1 = StartForAxis(params_copy, input_shape, 1);\n-  const int stop_1 = StopForAxis(params_copy, input_shape, 1, start_1);\n-  const int start_2 = StartForAxis(params_copy, input_shape, 2);\n-  const int stop_2 = StopForAxis(params_copy, input_shape, 2, start_2);\n-  const int start_3 = StartForAxis(params_copy, input_shape, 3);\n-  const int stop_3 = StopForAxis(params_copy, input_shape, 3, start_3);\n-  const int start_4 = StartForAxis(params_copy, input_shape, 4);\n-  const int stop_4 = StopForAxis(params_copy, input_shape, 4, start_4);\n-  const bool inner_stride_is_1 = params_copy.strides[4] == 1;\n-\n-  for (int offset_0 = start_0 * input_shape.Dims(1),\n-           end_0 = stop_0 * input_shape.Dims(1),\n-           step_0 = params_copy.strides[0] * input_shape.Dims(1);\n-       !LoopCondition(offset_0, end_0, params_copy.strides[0]);\n-       offset_0 += step_0) {\n-    for (int offset_1 = (offset_0 + start_1) * input_shape.Dims(2),\n-             end_1 = (offset_0 + stop_1) * input_shape.Dims(2),\n-             step_1 = params_copy.strides[1] * input_shape.Dims(2);\n-         !LoopCondition(offset_1, end_1, params_copy.strides[1]);\n-         offset_1 += step_1) {\n-      for (int offset_2 = (offset_1 + start_2) * input_shape.Dims(3),\n-               end_2 = (offset_1 + stop_2) * input_shape.Dims(3),\n-               step_2 = params_copy.strides[2] * input_shape.Dims(3);\n-           !LoopCondition(offset_2, end_2, params_copy.strides[2]);\n-           offset_2 += step_2) {\n-        for (int offset_3 = (offset_2 + start_3) * input_shape.Dims(4),\n-                 end_3 = (offset_2 + stop_3) * input_shape.Dims(4),\n-                 step_3 = params_copy.strides[3] * input_shape.Dims(4);\n-             !LoopCondition(offset_3, end_3, params_copy.strides[3]);\n-             offset_3 += step_3) {\n-          // When the stride is 1, the inner loop is equivalent to the\n-          // optimized slice inner loop. Otherwise, it is identical to the\n-          // strided_slice reference implementation inner loop.\n-          if (inner_stride_is_1) {\n-            const int len = stop_4 - start_4;\n-            if (len > 0) {\n-              writer->WriteN(offset_3 + start_4, len);\n-            }\n-          } else {\n-            for (int offset_4 = offset_3 + start_4, end_4 = offset_3 + stop_4;\n-                 !LoopCondition(offset_4, end_4, params_copy.strides[4]);\n-                 offset_4 += params_copy.strides[4]) {\n-              writer->Write(offset_4);\n-            }\n-          }\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const T* input_data,\n-                         const RuntimeShape& unextended_output_shape,\n-                         T* output_data) {\n-  SequentialTensorWriter<T> writer(input_data, output_data);\n-  StridedSlice<T>(op_params, unextended_input_shape, unextended_output_shape,\n-                  &writer);\n-}\n-\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const TfLiteTensor* input,\n-                         const RuntimeShape& unextended_output_shape,\n-                         TfLiteTensor* output) {\n-  SequentialTensorWriter<T> writer(input, output);\n-  StridedSlice<T>(op_params, unextended_input_shape, unextended_output_shape,\n-                  &writer);\n-}\n-\n template <typename T>\n void Minimum(const RuntimeShape& input1_shape, const T* input1_data,\n              const T* input2_data, const RuntimeShape& output_shape,\ndiff --git a/tensorflow/lite/kernels/internal/reference/strided_slice.h b/tensorflow/lite/kernels/internal/reference/strided_slice.h\nindex 40dc2e9102201..ff367cf95f19b 100644\n--- a/tensorflow/lite/kernels/internal/reference/strided_slice.h\n+++ b/tensorflow/lite/kernels/internal/reference/strided_slice.h\n@@ -31,10 +31,6 @@ inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n                          const RuntimeShape& unextended_input_shape,\n                          const RuntimeShape& unextended_output_shape,\n                          SequentialTensorWriter<T>* writer) {\n-  using strided_slice::LoopCondition;\n-  using strided_slice::StartForAxis;\n-  using strided_slice::StopForAxis;\n-\n   ruy::profiler::ScopeLabel label(""StridedSlice"");\n \n   // Note that the output_shape is not used herein.\n@@ -51,41 +47,67 @@ inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n   // requires (ie. all shapes must be 5D and are given backwards).\n   strided_slice::StridedSlicePadIndices(&params_copy, 5);\n \n-  const int start_0 = StartForAxis(params_copy, input_shape, 0);\n-  const int stop_0 = StopForAxis(params_copy, input_shape, 0, start_0);\n-  const int start_1 = StartForAxis(params_copy, input_shape, 1);\n-  const int stop_1 = StopForAxis(params_copy, input_shape, 1, start_1);\n-  const int start_2 = StartForAxis(params_copy, input_shape, 2);\n-  const int stop_2 = StopForAxis(params_copy, input_shape, 2, start_2);\n-  const int start_3 = StartForAxis(params_copy, input_shape, 3);\n-  const int stop_3 = StopForAxis(params_copy, input_shape, 3, start_3);\n-  const int start_4 = StartForAxis(params_copy, input_shape, 4);\n-  const int stop_4 = StopForAxis(params_copy, input_shape, 4, start_4);\n-\n-  for (int offset_0 = start_0 * input_shape.Dims(1),\n-           end_0 = stop_0 * input_shape.Dims(1),\n-           step_0 = params_copy.strides[0] * input_shape.Dims(1);\n-       !LoopCondition(offset_0, end_0, params_copy.strides[0]);\n-       offset_0 += step_0) {\n-    for (int offset_1 = (offset_0 + start_1) * input_shape.Dims(2),\n-             end_1 = (offset_0 + stop_1) * input_shape.Dims(2),\n-             step_1 = params_copy.strides[1] * input_shape.Dims(2);\n-         !LoopCondition(offset_1, end_1, params_copy.strides[1]);\n-         offset_1 += step_1) {\n-      for (int offset_2 = (offset_1 + start_2) * input_shape.Dims(3),\n-               end_2 = (offset_1 + stop_2) * input_shape.Dims(3),\n-               step_2 = params_copy.strides[2] * input_shape.Dims(3);\n-           !LoopCondition(offset_2, end_2, params_copy.strides[2]);\n-           offset_2 += step_2) {\n-        for (int offset_3 = (offset_2 + start_3) * input_shape.Dims(4),\n-                 end_3 = (offset_2 + stop_3) * input_shape.Dims(4),\n-                 step_3 = params_copy.strides[3] * input_shape.Dims(4);\n-             !LoopCondition(offset_3, end_3, params_copy.strides[3]);\n-             offset_3 += step_3) {\n-          for (int offset_4 = offset_3 + start_4, end_4 = offset_3 + stop_4;\n-               !LoopCondition(offset_4, end_4, params_copy.strides[4]);\n-               offset_4 += params_copy.strides[4]) {\n-            writer->Write(offset_4);\n+  const int start_0 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 0);\n+  const int stop_0 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 0, start_0);\n+  const int start_1 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 1);\n+  const int stop_1 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 1, start_1);\n+  const int start_2 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 2);\n+  const int stop_2 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 2, start_2);\n+  const int start_3 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 3);\n+  const int stop_3 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 3, start_3);\n+  const int start_4 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 4);\n+  const int stop_4 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 4, start_4);\n+\n+  auto lc = [&](int end, int stride, int index) {\n+    if (stride < 0) {\n+      return index > end;\n+    } else {\n+      return index < end;\n+    }\n+  };\n+  const int* shape = input_shape.DimsData();\n+  const int* stride = params_copy.strides;\n+  const bool inner_stride_is_1 = params_copy.strides[4] == 1;\n+\n+  for (int offset_0 = start_0; lc(stop_0, stride[0], offset_0);\n+       offset_0 += stride[0]) {\n+    for (int offset_1 = start_1; lc(stop_1, stride[1], offset_1);\n+         offset_1 += stride[1]) {\n+      for (int offset_2 = start_2; lc(stop_2, stride[2], offset_2);\n+           offset_2 += stride[2]) {\n+        for (int offset_3 = start_3; lc(stop_3, stride[3], offset_3);\n+             offset_3 += stride[3]) {\n+          // When the stride is 1, the inner loop is equivalent to the\n+          // optimized slice inner loop. Otherwise, it is identical to the\n+          // strided_slice reference implementation inner loop.\n+          if (inner_stride_is_1) {\n+            const int len = stop_4 - start_4;\n+            int index = start_4 + offset_3 * shape[4] +\n+                        offset_2 * shape[3] * shape[4] +\n+                        offset_1 * shape[2] * shape[3] * shape[4] +\n+                        offset_0 * shape[1] * shape[2] * shape[3] * shape[4];\n+            if (len > 0) {\n+              writer->WriteN(index, len);\n+            }\n+          } else {\n+            for (int offset_4 = start_4; lc(stop_4, stride[4], offset_4);\n+                 offset_4 += stride[4]) {\n+              int index = offset_4 + offset_3 * shape[4] +\n+                          offset_2 * shape[3] * shape[4] +\n+                          offset_1 * shape[2] * shape[3] * shape[4] +\n+                          offset_0 * shape[1] * shape[2] * shape[3] * shape[4];\n+              writer->Write(index);\n+            }\n           }\n         }\n       }\ndiff --git a/tensorflow/lite/kernels/internal/strided_slice_logic.h b/tensorflow/lite/kernels/internal/strided_slice_logic.h\nindex bfe84050dca15..2efdcf26fe07a 100644\n--- a/tensorflow/lite/kernels/internal/strided_slice_logic.h\n+++ b/tensorflow/lite/kernels/internal/strided_slice_logic.h\n@@ -69,6 +69,69 @@ inline void StridedSlicePadIndices(tflite::StridedSliceParams* p,\n   p->strides_count = dim_count;\n }\n \n+// Return the index for the first element along that axis. This index will be a\n+// positive integer between [0, axis_size] (or [-1, axis_size -1] if stride < 0)\n+// that can be used to index directly into the data.\n+inline int StridedSliceStartForAxis(const tflite::StridedSliceParams& params,\n+                                    const RuntimeShape& input_shape,\n+                                    int32_t axis) {\n+  const int32_t axis_size = input_shape.Dims(axis);\n+  int32_t start = params.start_indices[axis];\n+  const int32_t stride = params.strides[axis];\n+  const int32_t begin_mask = (params.begin_mask & 1 << axis);\n+  if (start < 0) {\n+    start += axis_size;\n+  }\n+  if (stride > 0) {\n+    start = Clamp(start, 0, axis_size);\n+  } else {\n+    start = Clamp(start, -1, axis_size - 1);\n+  }\n+  if (begin_mask) {\n+    if (stride > 0) {\n+      start = 0;\n+    } else {\n+      start = axis_size - 1;\n+    }\n+  }\n+  return start;\n+}\n+\n+inline int StridedSliceEndForAxis(const tflite::StridedSliceParams& params,\n+                                  const RuntimeShape& input_shape, int axis,\n+                                  int start) {\n+  const auto shrink_axis_mask = params.shrink_axis_mask;\n+  const bool shrink_axis = shrink_axis_mask & (1 << axis);\n+  const int axis_size = input_shape.Dims(axis);\n+  if (shrink_axis) {\n+    if (start >= axis_size) {\n+      return start;\n+    } else {\n+      return start + 1;\n+    }\n+  }\n+  const auto* indices = params.stop_indices;\n+  int end = indices[axis];\n+  const int32_t stride = params.strides[axis];\n+  const int32_t end_mask = (params.end_mask & 1 << axis);\n+  if (end < 0) {\n+    end += axis_size;\n+  }\n+  if (stride > 0) {\n+    end = Clamp(end, 0, axis_size);\n+  } else {\n+    end = Clamp(end, -1, axis_size - 1);\n+  }\n+  if (end_mask) {\n+    if (stride > 0) {\n+      end = axis_size;\n+    } else {\n+      end = -1;\n+    }\n+  }\n+  return end;\n+}\n+\n // Return the index for the first element along that axis. This index will be a\n // positive integer between [0, axis_size] (or [-1, axis_size -1] if stride < 0)\n // that can be used to index directly into the data.\ndiff --git a/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc b/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\nindex 628e72698917c..494d07690a210 100644\n--- a/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\n+++ b/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\n@@ -76,5 +76,119 @@ TEST(RunStridedSlicePadIndices, Pad3) {\n   );\n }\n \n+TEST(StridedSliceStartForAxis, NegativeOOBIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -11;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, NegativeOneTheBoundaryIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -10;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, NegativeWithinBoundsIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -9;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 1);\n+}\n+\n+TEST(StridedSliceStartForAxis, MinusOneIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -1;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 9);\n+}\n+\n+TEST(StridedSliceStartForAxis, ZeroIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 0;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, OneIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 1;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 1);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveBoundaryIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 9;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 9);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveOOBIndexSizeofArray) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 10;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 10);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveOOBIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 11;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 10);\n+}\n+\n+TEST(StridedSliceStartForAxis, TenFourMinus1) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 5;\n+  params.stop_indices[0] = 2;\n+  params.strides[0] = -1;\n+  int start = strided_slice::StridedSliceStartForAxis(params, RuntimeShape({4}),\n+                                                      /*axis=*/0);\n+  int stop = strided_slice::StridedSliceEndForAxis(params, RuntimeShape({4}),\n+                                                   /*axis=*/0, start);\n+  EXPECT_EQ(start, 3);\n+  EXPECT_EQ(stop, 2);\n+}\n+\n }  // namespace\n }  // namespace tflite\ndiff --git a/tensorflow/lite/kernels/strided_slice.cc b/tensorflow/lite/kernels/strided_slice.cc\nindex 55aecc9276531..f6f5d584610b2 100644\n--- a/tensorflow/lite/kernels/strided_slice.cc\n+++ b/tensorflow/lite/kernels/strided_slice.cc\n@@ -24,7 +24,6 @@ limitations under the License.\n #include ""tensorflow/lite/c/builtin_op_data.h""\n #include ""tensorflow/lite/c/common.h""\n #include ""tensorflow/lite/kernels/internal/compatibility.h""\n-#include ""tensorflow/lite/kernels/internal/optimized/optimized_ops.h""\n #include ""tensorflow/lite/kernels/internal/strided_slice_logic.h""\n #include ""tensorflow/lite/kernels/internal/tensor.h""\n #include ""tensorflow/lite/kernels/internal/tensor_ctypes.h""\n@@ -70,7 +69,7 @@ struct StridedSliceContext {\n };\n \n StridedSliceParams BuildStridedSliceParams(StridedSliceContext* op_context) {\n-  StridedSliceParams op_params;\n+  StridedSliceParams op_params{};\n \n   // The ellipsis_mask and new_axis_mask in op_params are not used. Those masks\n   // are processed here to update begin_mask, end_mask and the index range.\n@@ -196,9 +195,9 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n     int32_t stride = op_params.strides[idx];\n     TF_LITE_ENSURE_MSG(context, stride != 0, ""stride value has to be non-zero"");\n \n-    int32_t begin = ::tflite::strided_slice::StartForAxis(\n+    int32_t begin = ::tflite::strided_slice::StridedSliceStartForAxis(\n         op_params, effective_input_shape, idx);\n-    int32_t end = ::tflite::strided_slice::StopForAxis(\n+    int32_t end = ::tflite::strided_slice::StridedSliceEndForAxis(\n         op_params, effective_input_shape, idx, begin);\n \n     // When shrinking an axis, the end position does not matter (and can be\n@@ -272,43 +271,46 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   }\n   StridedSliceParams op_params = BuildStridedSliceParams(&op_context);\n \n-#define TF_LITE_STRIDED_SLICE(data_type)                                 \\\n-  {                                                                      \\\n-    if (kernel_type == kGenericOptimized) {                              \\\n-      optimized_ops::StridedSlice<data_type>(                            \\\n-          op_params, op_context.effective_input_shape, op_context.input, \\\n-          GetTensorShape(op_context.output), op_context.output);         \\\n-    } else {                                                             \\\n-      reference_ops::StridedSlice<data_type>(                            \\\n-          op_params, op_context.effective_input_shape, op_context.input, \\\n-          GetTensorShape(op_context.output), op_context.output);         \\\n-    }                                                                    \\\n-  }\n-\n   switch (op_context.input->type) {\n     case kTfLiteFloat32:\n-      TF_LITE_STRIDED_SLICE(float);\n+      reference_ops::StridedSlice<float>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt32:\n-      TF_LITE_STRIDED_SLICE(int32_t);\n+      reference_ops::StridedSlice<int32_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt64:\n-      TF_LITE_STRIDED_SLICE(int64_t);\n+      reference_ops::StridedSlice<int64_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteUInt8:\n-      TF_LITE_STRIDED_SLICE(uint8_t);\n+      reference_ops::StridedSlice<uint8_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt8:\n-      TF_LITE_STRIDED_SLICE(int8_t);\n+      reference_ops::StridedSlice<int8_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt16:\n-      TF_LITE_STRIDED_SLICE(int16_t);\n+      reference_ops::StridedSlice<int16_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteBool:\n-      TF_LITE_STRIDED_SLICE(bool);\n+      reference_ops::StridedSlice<bool>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteString:\n-      TF_LITE_STRIDED_SLICE(string);\n+      reference_ops::StridedSlice<string>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     default:\n       TF_LITE_KERNEL_LOG(context,\ndiff --git a/tensorflow/lite/kernels/strided_slice_test.cc b/tensorflow/lite/kernels/strided_slice_test.cc\nindex 2dd5777f07d60..c4c5805a4eaf2 100644\n--- a/tensorflow/lite/kernels/strided_slice_test.cc\n+++ b/tensorflow/lite/kernels/strided_slice_test.cc\n@@ -26,6 +26,7 @@ namespace tflite {\n namespace {\n \n using ::testing::ElementsAreArray;\n+using ::testing::IsEmpty;\n \n template <typename input_type>\n class StridedSliceOpModel : public SingleOpModel {\n@@ -35,7 +36,7 @@ class StridedSliceOpModel : public SingleOpModel {\n                       std::initializer_list<int> end_shape,\n                       std::initializer_list<int> strides_shape, int begin_mask,\n                       int end_mask, int ellipsis_mask, int new_axis_mask,\n-                      int shrink_axis_mask) {\n+                      int shrink_axis_mask, bool use_simple_allocator = true) {\n     input_ = AddInput(GetTensorType<input_type>());\n     begin_ = AddInput(TensorType_INT32);\n     end_ = AddInput(TensorType_INT32);\n@@ -46,7 +47,8 @@ class StridedSliceOpModel : public SingleOpModel {\n         CreateStridedSliceOptions(builder_, begin_mask, end_mask, ellipsis_mask,\n                                   new_axis_mask, shrink_axis_mask)\n             .Union());\n-    BuildInterpreter({input_shape, begin_shape, end_shape, strides_shape});\n+    BuildInterpreter({input_shape, begin_shape, end_shape, strides_shape},\n+                     use_simple_allocator);\n   }\n \n   void SetInput(std::initializer_list<input_type> data) {\n@@ -669,7 +671,7 @@ TYPED_TEST(StridedSliceOpTest, In3D_SmallBeginWithhrinkAxis1) {\n   EXPECT_THAT(m.GetOutput(), ElementsAreArray({1, 2, 3, 4, 5, 6}));\n }\n \n-TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n+TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBeginEndMask) {\n   StridedSliceOpModel<TypeParam> m({1, 1, 2}, {1}, {1}, {1}, 0, 1, 0, 0, 0);\n   m.SetInput({1, 2});\n   m.SetBegin({1});\n@@ -679,6 +681,16 @@ TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n   EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0, 1, 2}));\n }\n \n+TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n+  StridedSliceOpModel<TypeParam> m({1, 1, 2}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2});\n+  m.SetBegin({1});\n+  m.SetEnd({0});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0, 1, 2}));\n+}\n+\n TYPED_TEST(StridedSliceOpTest, In3D_Backward) {\n   StridedSliceOpModel<TypeParam> m({1, 1, 2}, {3}, {3}, {3}, 6, 7, 0, 0, 0);\n   m.SetInput({1, 2});\n@@ -853,5 +865,86 @@ TYPED_TEST(StridedSliceOpTest, NoInfiniteLoop) {\n   ASSERT_EQ(m.InvokeUnchecked(), kTfLiteOk);\n }\n \n+TYPED_TEST(StridedSliceOpTest, MinusThreeMinusFourMinusOne) {\n+  StridedSliceOpModel<TypeParam> m({4}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4});\n+  m.SetBegin({-3});\n+  m.SetEnd({-4});\n+  m.SetStrides({-1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({1}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({2}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, MinusFourMinusThreeOne) {\n+  StridedSliceOpModel<TypeParam> m({4}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4});\n+  m.SetBegin({-4});\n+  m.SetEnd({-3});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({1}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({1}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOne) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({2});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOneShrinkAxis) {\n+  StridedSliceOpModel<TypeParam> m({3}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetInput({1, 2, 3});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({2}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOneShrinkAxisOOB) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetInput({2});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OutOfBounds) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetBegin({1});\n+  m.SetEnd({2});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, StrideOutOfBounds) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetBegin({1});\n+  m.SetEnd({4});\n+  m.SetStrides({7});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, NegEndMask) {\n+  StridedSliceOpModel<TypeParam> m({2, 3}, {2}, {2}, {2}, 0, 0b10, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4, 5, 6});\n+  m.SetBegin({0, -1});\n+  m.SetEnd({2, -3});\n+  m.SetStrides({1, -1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({2, 3}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({3, 2, 1, 6, 5, 4}));\n+}\n }  // namespace\n }  // namespace tflite\ndiff --git a/tensorflow/lite/kernels/test_util.cc b/tensorflow/lite/kernels/test_util.cc\nindex 0e97b89bca4d3..4084193ab48eb 100644\n--- a/tensorflow/lite/kernels/test_util.cc\n+++ b/tensorflow/lite/kernels/test_util.cc\n@@ -177,7 +177,8 @@ void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n                                      int num_threads,\n                                      bool allow_fp32_relax_to_fp16,\n                                      bool apply_delegate,\n-                                     bool allocate_and_delegate) {\n+                                     bool allocate_and_delegate,\n+                                     bool use_simple_allocator) {\n   input_shapes_ = input_shapes;\n   allow_fp32_relax_to_fp16_ = allow_fp32_relax_to_fp16;\n   apply_delegate_ = apply_delegate;\n@@ -202,7 +203,7 @@ void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n   uint8_t* buffer_pointer = builder_.GetBufferPointer();\n   UpdateOpVersion(buffer_pointer);\n \n-  bool use_simple_allocator =\n+  use_simple_allocator |=\n       tflite::KernelTestDelegateProviders::Get()->ConstParams().Get<bool>(\n           tflite::KernelTestDelegateProviders::kUseSimpleAllocator);\n \n@@ -289,11 +290,12 @@ void SingleOpModel::Invoke() { ASSERT_EQ(interpreter_->Invoke(), kTfLiteOk); }\n \n TfLiteStatus SingleOpModel::InvokeUnchecked() { return interpreter_->Invoke(); }\n \n-void SingleOpModel::BuildInterpreter(\n-    std::vector<std::vector<int>> input_shapes) {\n+void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n+                                     bool use_simple_allocator) {\n   BuildInterpreter(input_shapes, /*num_threads=*/-1,\n                    /*allow_fp32_relax_to_fp16=*/false,\n-                   /*apply_delegate=*/true, /*allocate_and_delegate=*/true);\n+                   /*apply_delegate=*/true, /*allocate_and_delegate=*/true,\n+                   use_simple_allocator);\n }\n \n // static\ndiff --git a/tensorflow/lite/kernels/test_util.h b/tensorflow/lite/kernels/test_util.h\nindex cf61f32a9c97b..4f3aa2fe27e32 100644\n--- a/tensorflow/lite/kernels/test_util.h\n+++ b/tensorflow/lite/kernels/test_util.h\n@@ -511,9 +511,11 @@ class SingleOpModel {\n   // `apply_delegate` is ignored.\n   void BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n                         int num_threads, bool allow_fp32_relax_to_fp16,\n-                        bool apply_delegate, bool allocate_and_delegate = true);\n+                        bool apply_delegate, bool allocate_and_delegate = true,\n+                        bool use_simple_allocator = false);\n \n-  void BuildInterpreter(std::vector<std::vector<int>> input_shapes);\n+  void BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n+                        bool use_simple_allocator = false);\n \n   // Executes inference, asserting success.\n   void Invoke();\n'","['Fix strided slice bug where output is always writes at least one element.\n\na[1:1:1] should be empty, but one element is written.\n\nPiperOrigin-RevId: 482436216']",[],2022-10-25 17:13:06
58302,"r2.10 cherry-pick: a40f9be4ded ""Fix strided slice bug where output is always writes at least one element.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a40f9be4ded6433478b81331b31c9adf817b49b5,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/lite/kernels/internal/BUILD b/tensorflow/lite/kernels/internal/BUILD\nindex 095c75c626e96..e10eb9e2b9d52 100644\n--- a/tensorflow/lite/kernels/internal/BUILD\n+++ b/tensorflow/lite/kernels/internal/BUILD\n@@ -1073,7 +1073,6 @@ cc_test(\n     srcs = [\n         ""strided_slice_logic_test.cc"",\n     ],\n-    shard_count = 4,\n     deps = [\n         "":strided_slice_logic"",\n         ""@com_google_googletest//:gtest_main"",\ndiff --git a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\nindex d76fa11204524..154340d2c76b6 100644\n--- a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n+++ b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n@@ -4673,108 +4673,6 @@ inline void Slice(const tflite::SliceParams& op_params,\n   return Slice(op_params, input_shape, output_shape, &writer);\n }\n \n-// Note: This implementation is only optimized for the case where the inner\n-// stride == 1.\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const RuntimeShape& unextended_output_shape,\n-                         SequentialTensorWriter<T>* writer) {\n-  using strided_slice::LoopCondition;\n-  using strided_slice::StartForAxis;\n-  using strided_slice::StopForAxis;\n-\n-  ruy::profiler::ScopeLabel label(""StridedSlice"");\n-\n-  // Note that the output_shape is not used herein.\n-  tflite::StridedSliceParams params_copy = op_params;\n-\n-  TFLITE_DCHECK_LE(unextended_input_shape.DimensionsCount(), 5);\n-  TFLITE_DCHECK_LE(unextended_output_shape.DimensionsCount(), 5);\n-  const RuntimeShape input_shape =\n-      RuntimeShape::ExtendedShape(5, unextended_input_shape);\n-  const RuntimeShape output_shape =\n-      RuntimeShape::ExtendedShape(5, unextended_output_shape);\n-\n-  // Reverse and pad to 5 dimensions because that is what the runtime code\n-  // requires (ie. all shapes must be 5D and are given backwards).\n-  strided_slice::StridedSlicePadIndices(&params_copy, 5);\n-\n-  const int start_0 = StartForAxis(params_copy, input_shape, 0);\n-  const int stop_0 = StopForAxis(params_copy, input_shape, 0, start_0);\n-  const int start_1 = StartForAxis(params_copy, input_shape, 1);\n-  const int stop_1 = StopForAxis(params_copy, input_shape, 1, start_1);\n-  const int start_2 = StartForAxis(params_copy, input_shape, 2);\n-  const int stop_2 = StopForAxis(params_copy, input_shape, 2, start_2);\n-  const int start_3 = StartForAxis(params_copy, input_shape, 3);\n-  const int stop_3 = StopForAxis(params_copy, input_shape, 3, start_3);\n-  const int start_4 = StartForAxis(params_copy, input_shape, 4);\n-  const int stop_4 = StopForAxis(params_copy, input_shape, 4, start_4);\n-  const bool inner_stride_is_1 = params_copy.strides[4] == 1;\n-\n-  for (int offset_0 = start_0 * input_shape.Dims(1),\n-           end_0 = stop_0 * input_shape.Dims(1),\n-           step_0 = params_copy.strides[0] * input_shape.Dims(1);\n-       !LoopCondition(offset_0, end_0, params_copy.strides[0]);\n-       offset_0 += step_0) {\n-    for (int offset_1 = (offset_0 + start_1) * input_shape.Dims(2),\n-             end_1 = (offset_0 + stop_1) * input_shape.Dims(2),\n-             step_1 = params_copy.strides[1] * input_shape.Dims(2);\n-         !LoopCondition(offset_1, end_1, params_copy.strides[1]);\n-         offset_1 += step_1) {\n-      for (int offset_2 = (offset_1 + start_2) * input_shape.Dims(3),\n-               end_2 = (offset_1 + stop_2) * input_shape.Dims(3),\n-               step_2 = params_copy.strides[2] * input_shape.Dims(3);\n-           !LoopCondition(offset_2, end_2, params_copy.strides[2]);\n-           offset_2 += step_2) {\n-        for (int offset_3 = (offset_2 + start_3) * input_shape.Dims(4),\n-                 end_3 = (offset_2 + stop_3) * input_shape.Dims(4),\n-                 step_3 = params_copy.strides[3] * input_shape.Dims(4);\n-             !LoopCondition(offset_3, end_3, params_copy.strides[3]);\n-             offset_3 += step_3) {\n-          // When the stride is 1, the inner loop is equivalent to the\n-          // optimized slice inner loop. Otherwise, it is identical to the\n-          // strided_slice reference implementation inner loop.\n-          if (inner_stride_is_1) {\n-            const int len = stop_4 - start_4;\n-            if (len > 0) {\n-              writer->WriteN(offset_3 + start_4, len);\n-            }\n-          } else {\n-            for (int offset_4 = offset_3 + start_4, end_4 = offset_3 + stop_4;\n-                 !LoopCondition(offset_4, end_4, params_copy.strides[4]);\n-                 offset_4 += params_copy.strides[4]) {\n-              writer->Write(offset_4);\n-            }\n-          }\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const T* input_data,\n-                         const RuntimeShape& unextended_output_shape,\n-                         T* output_data) {\n-  SequentialTensorWriter<T> writer(input_data, output_data);\n-  StridedSlice<T>(op_params, unextended_input_shape, unextended_output_shape,\n-                  &writer);\n-}\n-\n-template <typename T>\n-inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n-                         const RuntimeShape& unextended_input_shape,\n-                         const TfLiteTensor* input,\n-                         const RuntimeShape& unextended_output_shape,\n-                         TfLiteTensor* output) {\n-  SequentialTensorWriter<T> writer(input, output);\n-  StridedSlice<T>(op_params, unextended_input_shape, unextended_output_shape,\n-                  &writer);\n-}\n-\n template <typename T>\n void Minimum(const RuntimeShape& input1_shape, const T* input1_data,\n              const T* input2_data, const RuntimeShape& output_shape,\ndiff --git a/tensorflow/lite/kernels/internal/reference/strided_slice.h b/tensorflow/lite/kernels/internal/reference/strided_slice.h\nindex 40dc2e9102201..ff367cf95f19b 100644\n--- a/tensorflow/lite/kernels/internal/reference/strided_slice.h\n+++ b/tensorflow/lite/kernels/internal/reference/strided_slice.h\n@@ -31,10 +31,6 @@ inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n                          const RuntimeShape& unextended_input_shape,\n                          const RuntimeShape& unextended_output_shape,\n                          SequentialTensorWriter<T>* writer) {\n-  using strided_slice::LoopCondition;\n-  using strided_slice::StartForAxis;\n-  using strided_slice::StopForAxis;\n-\n   ruy::profiler::ScopeLabel label(""StridedSlice"");\n \n   // Note that the output_shape is not used herein.\n@@ -51,41 +47,67 @@ inline void StridedSlice(const tflite::StridedSliceParams& op_params,\n   // requires (ie. all shapes must be 5D and are given backwards).\n   strided_slice::StridedSlicePadIndices(&params_copy, 5);\n \n-  const int start_0 = StartForAxis(params_copy, input_shape, 0);\n-  const int stop_0 = StopForAxis(params_copy, input_shape, 0, start_0);\n-  const int start_1 = StartForAxis(params_copy, input_shape, 1);\n-  const int stop_1 = StopForAxis(params_copy, input_shape, 1, start_1);\n-  const int start_2 = StartForAxis(params_copy, input_shape, 2);\n-  const int stop_2 = StopForAxis(params_copy, input_shape, 2, start_2);\n-  const int start_3 = StartForAxis(params_copy, input_shape, 3);\n-  const int stop_3 = StopForAxis(params_copy, input_shape, 3, start_3);\n-  const int start_4 = StartForAxis(params_copy, input_shape, 4);\n-  const int stop_4 = StopForAxis(params_copy, input_shape, 4, start_4);\n-\n-  for (int offset_0 = start_0 * input_shape.Dims(1),\n-           end_0 = stop_0 * input_shape.Dims(1),\n-           step_0 = params_copy.strides[0] * input_shape.Dims(1);\n-       !LoopCondition(offset_0, end_0, params_copy.strides[0]);\n-       offset_0 += step_0) {\n-    for (int offset_1 = (offset_0 + start_1) * input_shape.Dims(2),\n-             end_1 = (offset_0 + stop_1) * input_shape.Dims(2),\n-             step_1 = params_copy.strides[1] * input_shape.Dims(2);\n-         !LoopCondition(offset_1, end_1, params_copy.strides[1]);\n-         offset_1 += step_1) {\n-      for (int offset_2 = (offset_1 + start_2) * input_shape.Dims(3),\n-               end_2 = (offset_1 + stop_2) * input_shape.Dims(3),\n-               step_2 = params_copy.strides[2] * input_shape.Dims(3);\n-           !LoopCondition(offset_2, end_2, params_copy.strides[2]);\n-           offset_2 += step_2) {\n-        for (int offset_3 = (offset_2 + start_3) * input_shape.Dims(4),\n-                 end_3 = (offset_2 + stop_3) * input_shape.Dims(4),\n-                 step_3 = params_copy.strides[3] * input_shape.Dims(4);\n-             !LoopCondition(offset_3, end_3, params_copy.strides[3]);\n-             offset_3 += step_3) {\n-          for (int offset_4 = offset_3 + start_4, end_4 = offset_3 + stop_4;\n-               !LoopCondition(offset_4, end_4, params_copy.strides[4]);\n-               offset_4 += params_copy.strides[4]) {\n-            writer->Write(offset_4);\n+  const int start_0 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 0);\n+  const int stop_0 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 0, start_0);\n+  const int start_1 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 1);\n+  const int stop_1 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 1, start_1);\n+  const int start_2 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 2);\n+  const int stop_2 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 2, start_2);\n+  const int start_3 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 3);\n+  const int stop_3 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 3, start_3);\n+  const int start_4 =\n+      strided_slice::StridedSliceStartForAxis(params_copy, input_shape, 4);\n+  const int stop_4 = strided_slice::StridedSliceEndForAxis(\n+      params_copy, input_shape, 4, start_4);\n+\n+  auto lc = [&](int end, int stride, int index) {\n+    if (stride < 0) {\n+      return index > end;\n+    } else {\n+      return index < end;\n+    }\n+  };\n+  const int* shape = input_shape.DimsData();\n+  const int* stride = params_copy.strides;\n+  const bool inner_stride_is_1 = params_copy.strides[4] == 1;\n+\n+  for (int offset_0 = start_0; lc(stop_0, stride[0], offset_0);\n+       offset_0 += stride[0]) {\n+    for (int offset_1 = start_1; lc(stop_1, stride[1], offset_1);\n+         offset_1 += stride[1]) {\n+      for (int offset_2 = start_2; lc(stop_2, stride[2], offset_2);\n+           offset_2 += stride[2]) {\n+        for (int offset_3 = start_3; lc(stop_3, stride[3], offset_3);\n+             offset_3 += stride[3]) {\n+          // When the stride is 1, the inner loop is equivalent to the\n+          // optimized slice inner loop. Otherwise, it is identical to the\n+          // strided_slice reference implementation inner loop.\n+          if (inner_stride_is_1) {\n+            const int len = stop_4 - start_4;\n+            int index = start_4 + offset_3 * shape[4] +\n+                        offset_2 * shape[3] * shape[4] +\n+                        offset_1 * shape[2] * shape[3] * shape[4] +\n+                        offset_0 * shape[1] * shape[2] * shape[3] * shape[4];\n+            if (len > 0) {\n+              writer->WriteN(index, len);\n+            }\n+          } else {\n+            for (int offset_4 = start_4; lc(stop_4, stride[4], offset_4);\n+                 offset_4 += stride[4]) {\n+              int index = offset_4 + offset_3 * shape[4] +\n+                          offset_2 * shape[3] * shape[4] +\n+                          offset_1 * shape[2] * shape[3] * shape[4] +\n+                          offset_0 * shape[1] * shape[2] * shape[3] * shape[4];\n+              writer->Write(index);\n+            }\n           }\n         }\n       }\ndiff --git a/tensorflow/lite/kernels/internal/strided_slice_logic.h b/tensorflow/lite/kernels/internal/strided_slice_logic.h\nindex bfe84050dca15..2efdcf26fe07a 100644\n--- a/tensorflow/lite/kernels/internal/strided_slice_logic.h\n+++ b/tensorflow/lite/kernels/internal/strided_slice_logic.h\n@@ -69,6 +69,69 @@ inline void StridedSlicePadIndices(tflite::StridedSliceParams* p,\n   p->strides_count = dim_count;\n }\n \n+// Return the index for the first element along that axis. This index will be a\n+// positive integer between [0, axis_size] (or [-1, axis_size -1] if stride < 0)\n+// that can be used to index directly into the data.\n+inline int StridedSliceStartForAxis(const tflite::StridedSliceParams& params,\n+                                    const RuntimeShape& input_shape,\n+                                    int32_t axis) {\n+  const int32_t axis_size = input_shape.Dims(axis);\n+  int32_t start = params.start_indices[axis];\n+  const int32_t stride = params.strides[axis];\n+  const int32_t begin_mask = (params.begin_mask & 1 << axis);\n+  if (start < 0) {\n+    start += axis_size;\n+  }\n+  if (stride > 0) {\n+    start = Clamp(start, 0, axis_size);\n+  } else {\n+    start = Clamp(start, -1, axis_size - 1);\n+  }\n+  if (begin_mask) {\n+    if (stride > 0) {\n+      start = 0;\n+    } else {\n+      start = axis_size - 1;\n+    }\n+  }\n+  return start;\n+}\n+\n+inline int StridedSliceEndForAxis(const tflite::StridedSliceParams& params,\n+                                  const RuntimeShape& input_shape, int axis,\n+                                  int start) {\n+  const auto shrink_axis_mask = params.shrink_axis_mask;\n+  const bool shrink_axis = shrink_axis_mask & (1 << axis);\n+  const int axis_size = input_shape.Dims(axis);\n+  if (shrink_axis) {\n+    if (start >= axis_size) {\n+      return start;\n+    } else {\n+      return start + 1;\n+    }\n+  }\n+  const auto* indices = params.stop_indices;\n+  int end = indices[axis];\n+  const int32_t stride = params.strides[axis];\n+  const int32_t end_mask = (params.end_mask & 1 << axis);\n+  if (end < 0) {\n+    end += axis_size;\n+  }\n+  if (stride > 0) {\n+    end = Clamp(end, 0, axis_size);\n+  } else {\n+    end = Clamp(end, -1, axis_size - 1);\n+  }\n+  if (end_mask) {\n+    if (stride > 0) {\n+      end = axis_size;\n+    } else {\n+      end = -1;\n+    }\n+  }\n+  return end;\n+}\n+\n // Return the index for the first element along that axis. This index will be a\n // positive integer between [0, axis_size] (or [-1, axis_size -1] if stride < 0)\n // that can be used to index directly into the data.\ndiff --git a/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc b/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\nindex b48c647278b6a..d4aa8b94e141e 100644\n--- a/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\n+++ b/tensorflow/lite/kernels/internal/strided_slice_logic_test.cc\n@@ -78,5 +78,119 @@ TEST(RunStridedSlicePadIndices, Pad3) {\n   );\n }\n \n+TEST(StridedSliceStartForAxis, NegativeOOBIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -11;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, NegativeOneTheBoundaryIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -10;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, NegativeWithinBoundsIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -9;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 1);\n+}\n+\n+TEST(StridedSliceStartForAxis, MinusOneIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = -1;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 9);\n+}\n+\n+TEST(StridedSliceStartForAxis, ZeroIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 0;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 0);\n+}\n+\n+TEST(StridedSliceStartForAxis, OneIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 1;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 1);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveBoundaryIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 9;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 9);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveOOBIndexSizeofArray) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 10;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 10);\n+}\n+\n+TEST(StridedSliceStartForAxis, PositiveOOBIndex) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 11;\n+  params.strides[0] = 1;\n+  int start = strided_slice::StridedSliceStartForAxis(\n+      params, RuntimeShape({10}), /*axis=*/0);\n+  EXPECT_EQ(start, 10);\n+}\n+\n+TEST(StridedSliceStartForAxis, TenFourMinus1) {\n+  StridedSliceParams params{};\n+  params.begin_mask = 0;\n+  params.end_mask = 0;\n+  params.start_indices[0] = 5;\n+  params.stop_indices[0] = 2;\n+  params.strides[0] = -1;\n+  int start = strided_slice::StridedSliceStartForAxis(params, RuntimeShape({4}),\n+                                                      /*axis=*/0);\n+  int stop = strided_slice::StridedSliceEndForAxis(params, RuntimeShape({4}),\n+                                                   /*axis=*/0, start);\n+  EXPECT_EQ(start, 3);\n+  EXPECT_EQ(stop, 2);\n+}\n+\n }  // namespace\n }  // namespace tflite\ndiff --git a/tensorflow/lite/kernels/strided_slice.cc b/tensorflow/lite/kernels/strided_slice.cc\nindex 55aecc9276531..f6f5d584610b2 100644\n--- a/tensorflow/lite/kernels/strided_slice.cc\n+++ b/tensorflow/lite/kernels/strided_slice.cc\n@@ -24,7 +24,6 @@ limitations under the License.\n #include ""tensorflow/lite/c/builtin_op_data.h""\n #include ""tensorflow/lite/c/common.h""\n #include ""tensorflow/lite/kernels/internal/compatibility.h""\n-#include ""tensorflow/lite/kernels/internal/optimized/optimized_ops.h""\n #include ""tensorflow/lite/kernels/internal/strided_slice_logic.h""\n #include ""tensorflow/lite/kernels/internal/tensor.h""\n #include ""tensorflow/lite/kernels/internal/tensor_ctypes.h""\n@@ -70,7 +69,7 @@ struct StridedSliceContext {\n };\n \n StridedSliceParams BuildStridedSliceParams(StridedSliceContext* op_context) {\n-  StridedSliceParams op_params;\n+  StridedSliceParams op_params{};\n \n   // The ellipsis_mask and new_axis_mask in op_params are not used. Those masks\n   // are processed here to update begin_mask, end_mask and the index range.\n@@ -196,9 +195,9 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n     int32_t stride = op_params.strides[idx];\n     TF_LITE_ENSURE_MSG(context, stride != 0, ""stride value has to be non-zero"");\n \n-    int32_t begin = ::tflite::strided_slice::StartForAxis(\n+    int32_t begin = ::tflite::strided_slice::StridedSliceStartForAxis(\n         op_params, effective_input_shape, idx);\n-    int32_t end = ::tflite::strided_slice::StopForAxis(\n+    int32_t end = ::tflite::strided_slice::StridedSliceEndForAxis(\n         op_params, effective_input_shape, idx, begin);\n \n     // When shrinking an axis, the end position does not matter (and can be\n@@ -272,43 +271,46 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   }\n   StridedSliceParams op_params = BuildStridedSliceParams(&op_context);\n \n-#define TF_LITE_STRIDED_SLICE(data_type)                                 \\\n-  {                                                                      \\\n-    if (kernel_type == kGenericOptimized) {                              \\\n-      optimized_ops::StridedSlice<data_type>(                            \\\n-          op_params, op_context.effective_input_shape, op_context.input, \\\n-          GetTensorShape(op_context.output), op_context.output);         \\\n-    } else {                                                             \\\n-      reference_ops::StridedSlice<data_type>(                            \\\n-          op_params, op_context.effective_input_shape, op_context.input, \\\n-          GetTensorShape(op_context.output), op_context.output);         \\\n-    }                                                                    \\\n-  }\n-\n   switch (op_context.input->type) {\n     case kTfLiteFloat32:\n-      TF_LITE_STRIDED_SLICE(float);\n+      reference_ops::StridedSlice<float>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt32:\n-      TF_LITE_STRIDED_SLICE(int32_t);\n+      reference_ops::StridedSlice<int32_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt64:\n-      TF_LITE_STRIDED_SLICE(int64_t);\n+      reference_ops::StridedSlice<int64_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteUInt8:\n-      TF_LITE_STRIDED_SLICE(uint8_t);\n+      reference_ops::StridedSlice<uint8_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt8:\n-      TF_LITE_STRIDED_SLICE(int8_t);\n+      reference_ops::StridedSlice<int8_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteInt16:\n-      TF_LITE_STRIDED_SLICE(int16_t);\n+      reference_ops::StridedSlice<int16_t>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteBool:\n-      TF_LITE_STRIDED_SLICE(bool);\n+      reference_ops::StridedSlice<bool>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     case kTfLiteString:\n-      TF_LITE_STRIDED_SLICE(string);\n+      reference_ops::StridedSlice<string>(\n+          op_params, op_context.effective_input_shape, op_context.input,\n+          GetTensorShape(op_context.output), op_context.output);\n       break;\n     default:\n       TF_LITE_KERNEL_LOG(context,\ndiff --git a/tensorflow/lite/kernels/strided_slice_test.cc b/tensorflow/lite/kernels/strided_slice_test.cc\nindex 1fe1974a1b3c1..41180435a2e6f 100644\n--- a/tensorflow/lite/kernels/strided_slice_test.cc\n+++ b/tensorflow/lite/kernels/strided_slice_test.cc\n@@ -27,6 +27,7 @@ namespace tflite {\n namespace {\n \n using ::testing::ElementsAreArray;\n+using ::testing::IsEmpty;\n \n template <typename input_type>\n class StridedSliceOpModel : public SingleOpModel {\n@@ -36,7 +37,7 @@ class StridedSliceOpModel : public SingleOpModel {\n                       std::initializer_list<int> end_shape,\n                       std::initializer_list<int> strides_shape, int begin_mask,\n                       int end_mask, int ellipsis_mask, int new_axis_mask,\n-                      int shrink_axis_mask) {\n+                      int shrink_axis_mask, bool use_simple_allocator = true) {\n     input_ = AddInput(GetTensorType<input_type>());\n     begin_ = AddInput(TensorType_INT32);\n     end_ = AddInput(TensorType_INT32);\n@@ -47,7 +48,8 @@ class StridedSliceOpModel : public SingleOpModel {\n         CreateStridedSliceOptions(builder_, begin_mask, end_mask, ellipsis_mask,\n                                   new_axis_mask, shrink_axis_mask)\n             .Union());\n-    BuildInterpreter({input_shape, begin_shape, end_shape, strides_shape});\n+    BuildInterpreter({input_shape, begin_shape, end_shape, strides_shape},\n+                     use_simple_allocator);\n   }\n \n   void SetInput(std::initializer_list<input_type> data) {\n@@ -670,7 +672,7 @@ TYPED_TEST(StridedSliceOpTest, In3D_SmallBeginWithhrinkAxis1) {\n   EXPECT_THAT(m.GetOutput(), ElementsAreArray({1, 2, 3, 4, 5, 6}));\n }\n \n-TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n+TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBeginEndMask) {\n   StridedSliceOpModel<TypeParam> m({1, 1, 2}, {1}, {1}, {1}, 0, 1, 0, 0, 0);\n   m.SetInput({1, 2});\n   m.SetBegin({1});\n@@ -680,6 +682,16 @@ TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n   EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0, 1, 2}));\n }\n \n+TYPED_TEST(StridedSliceOpTest, In3D_BackwardSmallBegin) {\n+  StridedSliceOpModel<TypeParam> m({1, 1, 2}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2});\n+  m.SetBegin({1});\n+  m.SetEnd({0});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0, 1, 2}));\n+}\n+\n TYPED_TEST(StridedSliceOpTest, In3D_Backward) {\n   StridedSliceOpModel<TypeParam> m({1, 1, 2}, {3}, {3}, {3}, 6, 7, 0, 0, 0);\n   m.SetInput({1, 2});\n@@ -854,5 +866,86 @@ TYPED_TEST(StridedSliceOpTest, NoInfiniteLoop) {\n   ASSERT_EQ(m.Invoke(), kTfLiteOk);\n }\n \n+TYPED_TEST(StridedSliceOpTest, MinusThreeMinusFourMinusOne) {\n+  StridedSliceOpModel<TypeParam> m({4}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4});\n+  m.SetBegin({-3});\n+  m.SetEnd({-4});\n+  m.SetStrides({-1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({1}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({2}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, MinusFourMinusThreeOne) {\n+  StridedSliceOpModel<TypeParam> m({4}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4});\n+  m.SetBegin({-4});\n+  m.SetEnd({-3});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({1}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({1}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOne) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 0);\n+  m.SetInput({2});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOneShrinkAxis) {\n+  StridedSliceOpModel<TypeParam> m({3}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetInput({1, 2, 3});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({2}));\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OneOneOneShrinkAxisOOB) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetInput({2});\n+  m.SetBegin({1});\n+  m.SetEnd({1});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, OutOfBounds) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetBegin({1});\n+  m.SetEnd({2});\n+  m.SetStrides({1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, StrideOutOfBounds) {\n+  StridedSliceOpModel<TypeParam> m({1}, {1}, {1}, {1}, 0, 0, 0, 0, 1);\n+  m.SetBegin({1});\n+  m.SetEnd({4});\n+  m.SetStrides({7});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), IsEmpty());\n+}\n+\n+TYPED_TEST(StridedSliceOpTest, NegEndMask) {\n+  StridedSliceOpModel<TypeParam> m({2, 3}, {2}, {2}, {2}, 0, 0b10, 0, 0, 0);\n+  m.SetInput({1, 2, 3, 4, 5, 6});\n+  m.SetBegin({0, -1});\n+  m.SetEnd({2, -3});\n+  m.SetStrides({1, -1});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({2, 3}));\n+  EXPECT_THAT(m.GetOutput(), ElementsAreArray({3, 2, 1, 6, 5, 4}));\n+}\n }  // namespace\n }  // namespace tflite\ndiff --git a/tensorflow/lite/kernels/test_util.cc b/tensorflow/lite/kernels/test_util.cc\nindex c0242f7a911d6..71cb3cb181812 100644\n--- a/tensorflow/lite/kernels/test_util.cc\n+++ b/tensorflow/lite/kernels/test_util.cc\n@@ -178,7 +178,8 @@ void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n                                      int num_threads,\n                                      bool allow_fp32_relax_to_fp16,\n                                      bool apply_delegate,\n-                                     bool allocate_and_delegate) {\n+                                     bool allocate_and_delegate,\n+                                     bool use_simple_allocator) {\n   input_shapes_ = input_shapes;\n   allow_fp32_relax_to_fp16_ = allow_fp32_relax_to_fp16;\n   apply_delegate_ = apply_delegate;\n@@ -203,7 +204,7 @@ void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n   uint8_t* buffer_pointer = builder_.GetBufferPointer();\n   UpdateOpVersion(buffer_pointer);\n \n-  bool use_simple_allocator =\n+  use_simple_allocator |=\n       tflite::KernelTestDelegateProviders::Get()->ConstParams().Get<bool>(\n           tflite::KernelTestDelegateProviders::kUseSimpleAllocator);\n \n@@ -288,11 +289,12 @@ TfLiteStatus SingleOpModel::ApplyDelegate() {\n \n TfLiteStatus SingleOpModel::Invoke() { return interpreter_->Invoke(); }\n \n-void SingleOpModel::BuildInterpreter(\n-    std::vector<std::vector<int>> input_shapes) {\n+void SingleOpModel::BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n+                                     bool use_simple_allocator) {\n   BuildInterpreter(input_shapes, /*num_threads=*/-1,\n                    /*allow_fp32_relax_to_fp16=*/false,\n-                   /*apply_delegate=*/true, /*allocate_and_delegate=*/true);\n+                   /*apply_delegate=*/true, /*allocate_and_delegate=*/true,\n+                   use_simple_allocator);\n }\n \n // static\ndiff --git a/tensorflow/lite/kernels/test_util.h b/tensorflow/lite/kernels/test_util.h\nindex 0e69c310fcc57..1116dd78add2c 100644\n--- a/tensorflow/lite/kernels/test_util.h\n+++ b/tensorflow/lite/kernels/test_util.h\n@@ -538,9 +538,11 @@ class SingleOpModel {\n   // `apply_delegate` is ignored.\n   void BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n                         int num_threads, bool allow_fp32_relax_to_fp16,\n-                        bool apply_delegate, bool allocate_and_delegate = true);\n+                        bool apply_delegate, bool allocate_and_delegate = true,\n+                        bool use_simple_allocator = false);\n \n-  void BuildInterpreter(std::vector<std::vector<int>> input_shapes);\n+  void BuildInterpreter(std::vector<std::vector<int>> input_shapes,\n+                        bool use_simple_allocator = false);\n \n   // Executes inference and return status code.\n   TfLiteStatus Invoke();\n'","['Fix strided slice bug where output is always writes at least one element.\n\na[1:1:1] should be empty, but one element is written.\n\nPiperOrigin-RevId: 482436216']",[],2022-10-25 17:12:02
58301,r2.11 cherry-pick: [oneDNN] Fix conv_ops_benchmark_test when oneDNN is on,"Original PR: https://github.com/tensorflow/tensorflow/pull/58216
Original commit: https://github.com/tensorflow/tensorflow/commit/526fdac88a0b5c55a484090b401cfb805b2d7341",tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/conv_ops_benchmark_test.cc b/tensorflow/core/kernels/conv_ops_benchmark_test.cc\nindex 297a6c14102b9..1197fd7106d00 100644\n--- a/tensorflow/core/kernels/conv_ops_benchmark_test.cc\n+++ b/tensorflow/core/kernels/conv_ops_benchmark_test.cc\n@@ -250,16 +250,20 @@ static Graph* FusedConv2DWithBias(int batch, int height, int width,\n \n   Node* conv;\n   auto builder =\n-      IsMKLEnabled()\n-          ? NodeBuilder(graph->NewName(""conv""), ""_MklNativeFusedConv2D"")\n-                .Attr(""_kernel"", MKL_OP_LABEL)\n-          : NodeBuilder(graph->NewName(""conv""), ""_FusedConv2D"");\n-  TF_CHECK_OK(builder.Input(images)\n-                  .Input(filter)\n-                  .Attr(""num_args"", 1)\n-                  .Input(args)\n-                  .Input(host_args)\n-                  .Attr(""T"", DataTypeToEnum<T>::value)\n+      NodeBuilder(graph->NewName(""conv""),\n+                  IsMKLEnabled() ? ""_MklNativeFusedConv2D"" : ""_FusedConv2D"")\n+          .Input(images)\n+          .Input(filter)\n+          .Attr(""num_args"", 1)\n+          .Input(args);\n+\n+  if (IsMKLEnabled()) {\n+    builder.Attr(""_kernel"", MKL_OP_LABEL);\n+  } else {\n+    builder.Input(host_args);\n+  }\n+\n+  TF_CHECK_OK(builder.Attr(""T"", DataTypeToEnum<T>::value)\n                   .Attr(""strides"", {1, 1, 1, 1})\n                   .Attr(""padding"", ""SAME"")\n                   .Attr(""fused_ops"", fused_ops)\n@@ -301,16 +305,20 @@ static Graph* FusedConv2DWithBatchNorm(\n \n   Node* conv;\n   auto builder =\n-      IsMKLEnabled()\n-          ? NodeBuilder(graph->NewName(""conv""), ""_MklNativeFusedConv2D"")\n-                .Attr(""_kernel"", MKL_OP_LABEL)\n-          : NodeBuilder(graph->NewName(""conv""), ""_FusedConv2D"");\n-  TF_CHECK_OK(builder.Input(images)\n-                  .Input(filter)\n-                  .Attr(""num_args"", 4)\n-                  .Input(args)\n-                  .Input(host_args)\n-                  .Attr(""T"", DataTypeToEnum<T>::value)\n+      NodeBuilder(graph->NewName(""conv""),\n+                  IsMKLEnabled() ? ""_MklNativeFusedConv2D"" : ""_FusedConv2D"")\n+          .Input(images)\n+          .Input(filter)\n+          .Attr(""num_args"", 4)\n+          .Input(args);\n+\n+  if (IsMKLEnabled()) {\n+    builder.Attr(""_kernel"", MKL_OP_LABEL);\n+  } else {\n+    builder.Input(host_args);\n+  }\n+\n+  TF_CHECK_OK(builder.Attr(""T"", DataTypeToEnum<T>::value)\n                   .Attr(""strides"", {1, 1, 1, 1})\n                   .Attr(""padding"", ""SAME"")\n                   .Attr(""fused_ops"", fused_ops)\n'","['Do not pass 4th argument to _MklNativeFusedConv2D\n\nThe recent change https://github.com/tensorflow/tensorflow/commit/0d5820c180613c0e292c1f3e99aa70162661b612 introduced 4th argument to _FusedConv2D, but _MklNativeFusedConv2D when running with TF_ENABLE_ONEDNN_OPTS=1 still accepting only 3 input arguemnts. This patch makes sure when building node with _MklNativeFsuedConv2D we only define it with 3 input arguments.']",[],2022-10-25 15:37:54
58300,r2.11 cherry-pick: [oneDNN] Upgrade oneDNN to the latest version v2.7.1,"Original PR: https://github.com/tensorflow/tensorflow/pull/58269
Original commit: https://github.com/tensorflow/tensorflow/commit/edc9daa34a18d5029b6ff66f0edc3c738bb87e8d",tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex aee820d6e4025..5b230d194b286 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -186,9 +186,9 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""mkl_dnn_v1"",\n         build_file = ""//third_party/mkl_dnn:mkldnn_v1.BUILD"",\n-        sha256 = ""fc2b617ec8dbe907bb10853ea47c46f7acd8817bc4012748623d911aca43afbb"",\n-        strip_prefix = ""oneDNN-2.7"",\n-        urls = tf_mirror_urls(""https://github.com/oneapi-src/oneDNN/archive/refs/tags/v2.7.tar.gz""),\n+        sha256 = ""dc2b9bc851cd8d5a6c4622f7dc215bdb6b32349962875f8bf55cceed45a4c449"",\n+        strip_prefix = ""oneDNN-2.7.1"",\n+        urls = tf_mirror_urls(""https://github.com/oneapi-src/oneDNN/archive/refs/tags/v2.7.1.tar.gz""),\n     )\n \n     tf_http_archive(\ndiff --git a/third_party/mkl_dnn/mkldnn_v1.BUILD b/third_party/mkl_dnn/mkldnn_v1.BUILD\nindex 3c1c9d85d0a23..a60fe78a57ad1 100644\n--- a/third_party/mkl_dnn/mkldnn_v1.BUILD\n+++ b/third_party/mkl_dnn/mkldnn_v1.BUILD\n@@ -104,7 +104,7 @@ template_rule(\n     substitutions = {\n         ""@DNNL_VERSION_MAJOR@"": ""2"",\n         ""@DNNL_VERSION_MINOR@"": ""7"",\n-        ""@DNNL_VERSION_PATCH@"": ""0"",\n+        ""@DNNL_VERSION_PATCH@"": ""1"",\n         ""@DNNL_VERSION_HASH@"": ""N/A"",\n     },\n )\n@@ -116,7 +116,6 @@ _COPTS_LIST = select({\n     ""-UUSE_MKL"",\n     ""-UUSE_CBLAS"",\n     ""-DDNNL_ENABLE_MAX_CPU_ISA"",\n-    ""-DDNNL_DISABLE_PRIMITIVE_CACHE"",\n ] + tf_openmp_copts()\n \n _INCLUDES_LIST = [\n'",['Upgrading to the latest oneDNN 2.7.1'],[],2022-10-25 15:26:01
58299,r2.11 cherry-pick: [oneDNN] Fix a bug in primitive cache key,"Original PR: https://github.com/tensorflow/tensorflow/pull/58149
Original commit: https://github.com/tensorflow/tensorflow/commit/0de42bcd5a44ff9b484bd3a3d34f88e464a8182e",tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/mkl/mkl_conv_ops.cc b/tensorflow/core/kernels/mkl/mkl_conv_ops.cc\nindex fc1ad71a69b0e..82f91744db9da 100644\n--- a/tensorflow/core/kernels/mkl/mkl_conv_ops.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_conv_ops.cc\n@@ -511,6 +511,7 @@ class MklConvFwdPrimitiveFactory : public MklPrimitiveFactory<float> {\n     for (auto const& post_op_param : convFwdDims.post_op_params) {\n       key_creator.AddAsKey(post_op_param.name);\n       if (post_op_param.name == ""activation"") {\n+        key_creator.AddAsKey(post_op_param.alg);\n         DCHECK_EQ(post_op_param.param.size(), 3);\n         for (auto& param : post_op_param.param) {\n           key_creator.AddAsKey(param);\n'",['Fixing a bug in primitive cache key'],[],2022-10-25 15:19:54
58282,Improving converters for Select/SelectV2 operations.,The converters for `Select/SelectV2` operations have been improved to cover some additional `DynamicShape` mode test cases. ,drivanov,['drivanov'],['@bixia1 : This is a replacement for [PR#](https://github.com/tensorflow/tensorflow/pull/58256) which was unexpectedly closed when I tried to resolve the merge conflicts.'],"['bixia1', 'tfeher']","['bixia1', 'tfeher']",['gbaned'],"b'diff --git a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\nindex 92227d0be139d..4c0ec78da21a2 100644\n--- a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\n+++ b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\n@@ -6112,6 +6112,14 @@ bool OutputEdgeValidator::operator()(const Edge* out_edge) const {\n   return true;\n }\n \n+ITensorProxyPtr TRT_TensorOrWeights::as_tensor(const OpConverterParams* params) {\n+  if (is_tensor()) {\n+    return tensor();\n+  } else {\n+    return params->converter->CreateConstantLayer(weights(), GetTrtDims());\n+  }\n+}\n+\n std::string unexpected_type_error_msg(nvinfer1::DataType type_being_checked,\n                                       nvinfer1::DataType type_expected,\n                                       const NodeDef& node_def, int idx) {\ndiff --git a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.h b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.h\nindex c8734305f5323..db67e6e358b83 100644\n--- a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.h\n+++ b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.h\n@@ -556,6 +556,11 @@ StatusOr<ITensorProxyPtr> ConvertMatMulImpl(const OpConverterParams* params,\n                                             TRT_TensorOrWeights input_b,\n                                             bool transpose_a, bool transpose_b);\n \n+Status ApplyBroadcast(std::unique_ptr<TRT_TensorOrWeights>& operand,\n+                      const DimsAdapter& broadcasted_dims,\n+                      const OpConverterParams* params,\n+                      std::optional<int> op_instance);\n+\n std::string convert_range_error_msg(float start, float limit, float delta);\n std::string convert_range_expected_msg(const NodeDef& node_def);\n std::string bool_weight_error_msg(const NodeDef& node_def);\ndiff --git a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc\nindex d51e319e68b84..0d2f2ec5f6b63 100644\n--- a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc\n+++ b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc\n@@ -9387,11 +9387,20 @@ void OpConverter_Select::RunTest(const string& opName) {\n     }\n   };\n \n-  auto shape_error_msg = [&](const NodeDef& node, bool same_then_else) {\n+  auto shape_error_msg = [&](const NodeDef& node, bool same_then_else = true) {\n     nvinfer1::Dims shape[3];\n     const auto j = same_then_else ? 0 : 1;\n-    for (int i = 0; i < 2; i++) {\n-      DimsAdapter(*par_dims[i + j]).TrtDims(&shape[i + j]);\n+    if (trt_mode_ == TrtTestMode::kDynamicShape) {\n+      // Creating dynamic shapes corresponding to \'cond\' and \'then\' parameters.\n+      for (int i = 0; i < 2; i++) {\n+        for (int j = shape[i].nbDims = par_dims[i]->size(); j--;) {\n+          shape[i].d[j] = -1;\n+        }\n+      }\n+    } else {\n+      for (int i = 0; i < 2; i++) {\n+        DimsAdapter(*par_dims[i + j]).TrtDims(&shape[i + j]);\n+      }\n     }\n \n     return input_shapes_error_msg(shape[j], shape[j + 1], node,\n@@ -9530,7 +9539,7 @@ void OpConverter_Select::RunTest(const string& opName) {\n           err_msg = ""Infeasible broadcast scheme ("" + bc_comment[k] + "" vs "" +\n                     bc_comment[1 - k];\n         } else {\n-          err_msg = shape_error_msg(node, true);\n+          err_msg = shape_error_msg(node);\n         }\n \n         set_parameters();\n@@ -9754,6 +9763,41 @@ void OpConverter_Select::RunTest(const string& opName) {\n                         ElementsAreArray(expected_output));\n       }\n     }\n+\n+    // Restoring the original value.\n+    par_type[2] = tf_type_;\n+  }\n+\n+  if (trt_mode_ == TrtTestMode::kDynamicShape) {\n+    std::vector<float> values_then {1, 2, 3, 4, 5, 6};\n+    std::vector<float> values_else {-1, -2, -3, -4, -5, -6};\n+    std::vector<float> expected_output {1, -2, 3, 4, -5, 6};\n+    data_cond = std::vector<int>{1, 0, 1};\n+    const std::vector<int> cond_dims{1, 3}, input_dims{1, 2, 3};\n+    par_dims = {&cond_dims, &input_dims, &input_dims};\n+    // Loop when condition is reversed and the expected_output\n+    // should change from \'else\' to \'then\'.\n+    const auto len_cond = data_cond.size();\n+    for (int i = 0; i < 2; i++) {\n+      par_value[i + 1] = &values_then;\n+      par_value[2 - i] = &values_else;\n+      for (int j = 0; j < values_then.size(); j++) {\n+        expected_output[j] = par_value[2 - data_cond[j % len_cond]]->at(j);\n+      }\n+\n+      set_parameters();\n+      if (testing_SelectV2) {\n+        TestOpConverter(node, input_dims, OkStatus(), OkStatus(),\n+                        ElementsAreArray(expected_output));\n+      } else {\n+        const auto err_msg = shape_error_msg(node);\n+        RunValidationAndConversion(node, error::INVALID_ARGUMENT, err_msg);\n+      }\n+      // Changing the condition and expected_output.\n+      for (int j = len_cond; j--;) {\n+        data_cond[j] = 1 - data_cond[j];\n+      }\n+    }\n   }\n }\n \ndiff --git a/tensorflow/compiler/tf2tensorrt/convert/ops/selectv2.cc b/tensorflow/compiler/tf2tensorrt/convert/ops/selectv2.cc\nindex 346fad34327bb..bac350d07d36b 100644\n--- a/tensorflow/compiler/tf2tensorrt/convert/ops/selectv2.cc\n+++ b/tensorflow/compiler/tf2tensorrt/convert/ops/selectv2.cc\n@@ -99,9 +99,10 @@ class ConvertSelectBase : public OpConverterBase<ConvertSelectBase> {\n \n     for (int i = 0; i < tensor_.size(); i++) {\n       // This will also convert constants to tensors.\n-      TF_RETURN_IF_ERROR(PrepareTensorForShape(\n-          params.converter, inputs.at(i), broadcasted_dims[i],\n-          params.validation_only, &tensor_[i], node, i));\n+      tensor_[i] = std::make_unique<TRT_TensorOrWeights>(inputs.at(i));\n+      TF_RETURN_IF_ERROR(ApplyBroadcast(tensor_[i],\n+                                        broadcasted_dims[i],\n+                                        this->params_, 0));\n     }\n \n     return OkStatus();\n@@ -112,9 +113,9 @@ class ConvertSelectBase : public OpConverterBase<ConvertSelectBase> {\n     auto* converter = params.converter;\n \n     nvinfer1::ISelectLayer* select_layer = converter->network()->addSelect(\n-        *tensor_[0]->trt_tensor(),  // cond_tensor\n-        *tensor_[1]->trt_tensor(),  // then_tensor\n-        *tensor_[2]->trt_tensor()   // else_tensor\n+        *tensor_[0].get()->as_tensor(params_)->trt_tensor(),  // cond_tensor\n+        *tensor_[1].get()->as_tensor(params_)->trt_tensor(),  // then_tensor\n+        *tensor_[2].get()->as_tensor(params_)->trt_tensor()   // else_tensor\n     );\n \n     converter->SetLayerName(select_layer, params.node_def.name(), layer_name_);\n@@ -151,17 +152,14 @@ class ConvertSelectBase : public OpConverterBase<ConvertSelectBase> {\n     const int idx = then_vs_else ? 1 : 0;\n     for (int i = 0; i < 2; ++i) {\n       const auto& input = inputs.at(i + idx);\n-      if (input.is_tensor()) {\n-        const auto* dims = input.GetTrtDims().d;\n-        for (int j = input.GetTrtDims().nbDims; --j >= 0;) {\n-          if (*(dims + j) < 0) return true;\n-        }\n+      if (input.is_tensor() && !HasStaticShape(input.GetTrtDims())) {\n+        return true;\n       }\n     }\n     return false;\n   }\n \n-  std::array<ITensorProxyPtr, 3> tensor_{nullptr, nullptr, nullptr};\n+  std::array<std::unique_ptr<TRT_TensorOrWeights>, 3> tensor_;\n   const std::string layer_name_;\n };\n \ndiff --git a/tensorflow/compiler/tf2tensorrt/convert/weights.h b/tensorflow/compiler/tf2tensorrt/convert/weights.h\nindex a17d9ceab288e..20b66e9852b73 100644\n--- a/tensorflow/compiler/tf2tensorrt/convert/weights.h\n+++ b/tensorflow/compiler/tf2tensorrt/convert/weights.h\n@@ -172,6 +172,8 @@ enum class TRT_ArgumentType {\n   RESOURCE = 2,\n };\n \n+struct OpConverterParams;\n+\n // Represents a TRT-style input to a TF node, it can be either a\n // ITensorProxyPtr (representing nvinfer1::ITensor* or SimpleITensor),\n // or TRT_ShapedWeights which is compile-time constant.\n@@ -222,6 +224,8 @@ class TRT_TensorOrWeights {\n \n   ResourceHandle resource() const;\n \n+  ITensorProxyPtr as_tensor(const OpConverterParams* params);\n+\n   TRT_ShapedWeights& weights() {\n     DCHECK(is_weights());\n     return weights_;\n'",['Improving converters for Select/SelectV2 operations.'],[],2022-10-24 16:48:51
58279,r2.11 cherry-pick: [oneDNN] Fix AvgPool3d Floating point exception,"Original PR: https://github.com/tensorflow/tensorflow/pull/57998
Piper: 481588030
",penpornk,[],[],['learning-to-play'],['learning-to-play'],[],"b'diff --git a/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc b/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc\nindex 3c90cb5a76ff7..00a0f10db92d4 100644\n--- a/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc\n@@ -70,9 +70,11 @@ class MklAvgPoolingOp : public MklPoolingForwardOpBase<T> {\n       Tensor* output_tensor = nullptr;\n       memory::dims output_dims_mkl_order;\n       this->GetOutputDims(pool_params, &output_dims_mkl_order);\n+      // Check for corner case - if output is an empty tensor, return.\n+      TensorShape out_tf_shape = MklDnnDimsToTFShape(output_dims_mkl_order);\n \n       // If input is an empty tensor, allocate an empty output tensor.\n-      if (input_tensor.NumElements() == 0) {\n+      if (input_tensor.NumElements() == 0 || out_tf_shape.num_elements() == 0) {\n         const int kOutputIndex = 0;\n         this->AllocateEmptyOutputTensor(context, kOutputIndex, &pool_params,\n                                         output_dims_mkl_order, &output_tensor);\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py b/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py\nindex 9c8f11eb74309..5dcb3b6ebe67e 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py\n@@ -245,6 +245,22 @@ def testMaxPool3DEmptyTensorOutputShape(self):\n     values = self.evaluate(max_pool_3d)\n     self.assertEqual(values.shape, (0, 56, 56, 56, 64))\n \n+  # TODO(penporn): Determine if we will allow input_sizes[3] < ksize[3].\n+  def DISABLED_testAvgPool3dEmptyOutTensor(self):\n+    input_sizes = [30, 19, 4, 19, 17]\n+    input_data = 1.0\n+    input_tensor = constant_op.constant(\n+        input_data, shape=input_sizes, name=""input"")\n+    avg_pool_3d= nn_ops.avg_pool3d(\n+        input_tensor,\n+        ksize=(1, 13, 3, 20, 1),\n+        strides=(1, 14, 4, 1, 1),\n+        padding=""VALID"",\n+        data_format=""NDHWC"",\n+        name=""avg_pool_3d"")\n+    values = self.evaluate(avg_pool_3d)\n+    self.assertEqual(values.shape, (30, 1, 1, 0, 17))\n+\n   def _ConstructAndTestGradientForConfig(self,\n                                          pool_func,\n                                          input_sizes,\n'","['Add empty out tensor check', 'Temporarily disable testAvgPool3dEmptyOutTensor.\n\nThe test has input_sizes[3] < ksize[3]. Shape inference assumes all input dimensions >= filter dimensions and will return an InvalidArgument error.']",[],2022-10-24 09:59:37
58276,r2.11 cherry-pick: [oneDNN] Fix AvgPool3d Floating point exception,"Original PR: https://github.com/tensorflow/tensorflow/pull/57998
Original commit: https://github.com/tensorflow/tensorflow/commit/4553398e4ec290209577a832140d4b260f4c3373",tensorflow-jenkins,['penpornk'],"[""Closing this PR as I forgot that I made additional changes to the [original PR](https://github.com/tensorflow/tensorflow/pull/57998) during merge, so we can't just use the original commit. Creating a new one soon.""]",[],[],[],"b'diff --git a/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc b/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc\nindex 3c90cb5a76ff7..00a0f10db92d4 100644\n--- a/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc\n@@ -70,9 +70,11 @@ class MklAvgPoolingOp : public MklPoolingForwardOpBase<T> {\n       Tensor* output_tensor = nullptr;\n       memory::dims output_dims_mkl_order;\n       this->GetOutputDims(pool_params, &output_dims_mkl_order);\n+      // Check for corner case - if output is an empty tensor, return.\n+      TensorShape out_tf_shape = MklDnnDimsToTFShape(output_dims_mkl_order);\n \n       // If input is an empty tensor, allocate an empty output tensor.\n-      if (input_tensor.NumElements() == 0) {\n+      if (input_tensor.NumElements() == 0 || out_tf_shape.num_elements() == 0) {\n         const int kOutputIndex = 0;\n         this->AllocateEmptyOutputTensor(context, kOutputIndex, &pool_params,\n                                         output_dims_mkl_order, &output_tensor);\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py b/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py\nindex 9c8f11eb74309..139c09dbaf51e 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py\n@@ -245,6 +245,21 @@ def testMaxPool3DEmptyTensorOutputShape(self):\n     values = self.evaluate(max_pool_3d)\n     self.assertEqual(values.shape, (0, 56, 56, 56, 64))\n \n+  def testAvgPool3dEmptyOutTensor(self):\n+    input_sizes = [30, 19, 4, 19, 17]\n+    input_data = 1.0\n+    input_tensor = constant_op.constant(\n+        input_data, shape=input_sizes, name=""input"")\n+    avg_pool_3d= nn_ops.avg_pool3d(\n+        input_tensor,\n+        ksize=(1, 13, 3, 20, 1),\n+        strides=(1, 14, 4, 1, 1),\n+        padding=""VALID"",\n+        data_format=""NDHWC"",\n+        name=""avg_pool_3d"")\n+    values = self.evaluate(avg_pool_3d)\n+    self.assertEqual(values.shape, (30, 1, 1, 0, 17))\n+\n   def _ConstructAndTestGradientForConfig(self,\n                                          pool_func,\n                                          input_sizes,\n'",['Add empty out tensor check'],[],2022-10-24 09:11:47
58269,Upgrading to the latest oneDNN 2.7.1,Upgrading to the latest oneDNN 2.7.1,ashiqimranintel,"['agramesh1', 'ashiqimranintel', 'penpornk']","['@ashiqimranintel This is intentional, right?', 'hi @penpornk yes.  This reverts a change in 2.10 https://github.com/tensorflow/tensorflow/pull/57071 due to a mem corruption that is now fixed. ', '@agramesh1 Thank you for the quick reply!', '@penpornk , can you approve this PR?', '[ARM CI](https://github.com/tensorflow/tensorflow/actions/runs/3309074945/jobs/5461899463) failed, but it seems to be an existing failure since [another run](https://github.com/tensorflow/tensorflow/actions/runs/3308078945) before it (from another PR) also got the same failure.', ""@penpornk , I think it's unrelated""]","['penpornk', 'penpornk', 'agramesh1', 'penpornk']","['penpornk', 'penpornk', 'agramesh1', 'penpornk']","['penpornk', 'gbaned']","b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex 2384952580e9d..5f25f1a2c92bf 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -187,9 +187,9 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""mkl_dnn_v1"",\n         build_file = ""//third_party/mkl_dnn:mkldnn_v1.BUILD"",\n-        sha256 = ""fc2b617ec8dbe907bb10853ea47c46f7acd8817bc4012748623d911aca43afbb"",\n-        strip_prefix = ""oneDNN-2.7"",\n-        urls = tf_mirror_urls(""https://github.com/oneapi-src/oneDNN/archive/refs/tags/v2.7.tar.gz""),\n+        sha256 = ""dc2b9bc851cd8d5a6c4622f7dc215bdb6b32349962875f8bf55cceed45a4c449"",\n+        strip_prefix = ""oneDNN-2.7.1"",\n+        urls = tf_mirror_urls(""https://github.com/oneapi-src/oneDNN/archive/refs/tags/v2.7.1.tar.gz""),\n     )\n \n     tf_http_archive(\ndiff --git a/third_party/mkl_dnn/mkldnn_v1.BUILD b/third_party/mkl_dnn/mkldnn_v1.BUILD\nindex 3c1c9d85d0a23..a60fe78a57ad1 100644\n--- a/third_party/mkl_dnn/mkldnn_v1.BUILD\n+++ b/third_party/mkl_dnn/mkldnn_v1.BUILD\n@@ -104,7 +104,7 @@ template_rule(\n     substitutions = {\n         ""@DNNL_VERSION_MAJOR@"": ""2"",\n         ""@DNNL_VERSION_MINOR@"": ""7"",\n-        ""@DNNL_VERSION_PATCH@"": ""0"",\n+        ""@DNNL_VERSION_PATCH@"": ""1"",\n         ""@DNNL_VERSION_HASH@"": ""N/A"",\n     },\n )\n@@ -116,7 +116,6 @@ _COPTS_LIST = select({\n     ""-UUSE_MKL"",\n     ""-UUSE_CBLAS"",\n     ""-DDNNL_ENABLE_MAX_CPU_ISA"",\n-    ""-DDNNL_DISABLE_PRIMITIVE_CACHE"",\n ] + tf_openmp_copts()\n \n _INCLUDES_LIST = [\n'",['Upgrading to the latest oneDNN 2.7.1'],[],2022-10-23 23:59:51
58268,Upgrading to the latest oneDNN-2.7.1 version,,ashiqimranintel,[],[],[],[],"['penpornk', 'gbaned']","b'diff --git a/RELEASE.md b/RELEASE.md\nindex 0fa310871fb1c..ae9df4f18d64e 100644\n--- a/RELEASE.md\n+++ b/RELEASE.md\n@@ -1,128 +1,67 @@\n # Release 2.11.0\n \n-<INSERT SMALL BLURB ABOUT RELEASE FOCUS AREA AND POTENTIAL TOOLCHAIN CHANGES>\n-\n-* `tensorflow::StatusOr::ConsumeValueOrDie`, deprecated in TF 2.10 has been\n-  removed.\n-\n ## Breaking Changes\n-*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and\n-    old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.\n-    If you find your workflow failing due to this change,\n-    you may be facing one of the following issues:\n-\n-    *   **Checkpoint loading failure.** The new optimizer handles optimizer\n-        state differently from the old optimizer, which simplies the logic of\n-        checkpoint saving/loading, but at the cost of breaking checkpoint\n-        backward compatibility in some cases. If you want to keep using an old\n-        checkpoint, please change your optimizer to\n-        `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n-    *   **TF1 compatibility.** The new optimizer does not support TF1 any more,\n-        so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.\n-        We highly recommend to migrate your workflow to TF2 for stable\n-        support and new features.\n-    *   **API not found.** The new optimizer has a different set of public APIs\n-        from the old optimizer. These API changes are mostly related to\n-        getting rid of slot variables and TF1 support. Please check the API\n-        documentation to find alternatives to the missing API. If you must\n-        call the deprecated API, please change your optimizer to the legacy\n-        optimizer.\n-    *   **Learning rate schedule access.** When using a `LearningRateSchedule`,\n-        The new optimizer\'s `learning_rate` property returns the\n-        current learning rate value instead of a `LearningRateSchedule` object\n-        as before. If you need to access the `LearningRateSchedule` object,\n-        please use `optimizer._learning_rate`.\n-    *   **You implemented a custom optimizer based on the old optimizer.**\n-        Please set your optimizer to subclass\n-        `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new\n-        optimizer and find it does not support your optimizer, please file\n-        an issue in the Keras GitHub repo.\n-    *   **Error such as `Cannot recognize variable...`.** The new optimizer\n-        requires all optimizer variables to be created at the first\n-        `apply_gradients()` or `minimize()` call. If your workflow calls\n-        optimizer to update different parts of model in multiple stages,\n-        please call `optimizer.build(model.trainable_variables)` before the\n-        training loop.\n-    *   **Timeout or performance loss.** We don\'t anticipate this to happen, but\n-        if you see such issues, please use the legacy optimizer, and file\n-        an issue in the Keras GitHub repo.\n-\n-    The old Keras optimizer will never be deleted, but will not see any\n-    new feature additions.\n-    New optimizers (e.g., `Adafactor`) will\n-    only be implemented based on `tf.keras.optimizers.Optimizer`, the new\n-    base class.\n-\n-## Known Caveats\n-\n-* <CAVEATS REGARDING THE RELEASE (BUT NOT BREAKING CHANGES).>\n-* <ADDING/BUMPING DEPENDENCIES SHOULD GO HERE>\n-* <KNOWN LACK OF SUPPORT ON SOME PLATFORM, SHOULD GO HERE>\n+*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.  \n+    If you find your workflow failing due to this change, you may be facing one of the following issues:\n+    *   **Checkpoint loading failure.** The new optimizer handles optimizer state differently from the old optimizer, which simplifies the logic of checkpoint saving/loading, but at the cost of breaking checkpoint backward compatibility in some cases. If you want to keep using an old checkpoint, please change your optimizer to `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n+    *   **TF1 compatibility.** The new optimizer, `tf.keras.optimizers.Optimizer`, does not support TF1 any more, so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.  \n+        We highly recommend to migrate your workflow to TF2 for stable support and new features.\n+    *   **Old optimizer API not found.** The new optimizer, `tf.keras.optimizers.Optimizer`, has a different set of public APIs from the old optimizer.  \n+        These API changes are mostly related to getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives to the missing API. If you must call the deprecated API, please change your optimizer to the legacy optimizer.\n+    *   **Learning rate schedule access.** When using a `LearningRateSchedule`, The new optimizer\'s `learning_rate` property returns the current learning rate value instead of a `LearningRateSchedule` object as before. If you need to access the `LearningRateSchedule` object, please use `optimizer._learning_rate`.\n+    *   **If you implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new optimizer and find it does not support your optimizer, please file an issue in the Keras GitHub repo.\n+    *   **Errors, such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first `apply_gradients()` or `minimize()` call. If your workflow calls optimizer to update different parts of model in multiple stages, please call `optimizer.build(model.trainable_variables)` before the training loop.\n+    *   **Timeout or performance loss.** We don\'t anticipate this to happen, but if you see such issues, please use the legacy optimizer, and file an issue in the Keras GitHub repo.\n+\n+    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (for example, `tf.keras.optimizers.Adafactor`) will only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n+\n+*   `tensorflow/python/keras` code is a legacy copy of Keras since 2.7 release, and will be deleted in 2.12 release. Please remove any import of `tensorflow.python.keras` and use public API with `from tensorflow import keras` or `import tensorflow as tf; tf.keras`.\n \n ## Major Features and Improvements\n \n *   `tf.lite`:\n \n-    *   New operations supported:\n-          * tf.unsortedsegmentmin op is supported.\n-          * tf.atan2 op is supported.\n-          * tf.sign op is supported.\n+    *   New operations supported: `tf.unsortedsegmentmin`, `tf.atan2` and `tf.sign`.\n     *   Updates to existing operations:\n-          * tfl.mul now supports complex32 inputs.\n+          * `tfl.mul` now supports complex32 inputs.\n \n *   `tf.experimental.StructuredTensor`\n \n-    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible\n-        and Tensorflow-native way to encode structured data such as protocol\n-        buffers or pandas dataframes.\n+    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and TensorFlow-native way to encode structured data such as protocol buffers or pandas dataframes.\n \n *   `tf.keras`:\n \n-    *   Added method `get_metrics_result()` to `tf.keras.models.Model`.\n+    *   Added a new `get_metrics_result()` method to `tf.keras.models.Model`.\n         *   Returns the current metrics values of the model as a dict.\n-    *   Added group normalization layer `tf.keras.layers.GroupNormalization`.\n+    *   Added a new group normalization layer - `tf.keras.layers.GroupNormalization`.\n     *   Added weight decay support for all Keras optimizers.\n     *   Added Adafactor optimizer `tf.keras.optimizers.Adafactor`.\n     *   Added `warmstart_embedding_matrix` to `tf.keras.utils`.\n-        This utility can be used to warmstart an embeddings matrix so you\n-        reuse previously-learned word embeddings when working with a new set\n-        of words which may include previously unseen words (the embedding\n-        vectors for unseen words will be randomly initialized).\n+        *   This utility can be used to warmstart an embeddings matrix, so you reuse previously-learned word embeddings when working with a new set of words which may include previously unseen words (the embedding vectors for unseen words will be randomly initialized).\n \n *   `tf.Variable`:\n \n-    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`. This\n-        allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n-    *   Added a new constructor argument `experimental_enable_variable_lifting`\n-        to `tf.Variable`, defaulting to True. When it\'s `False`, the variable\n-        won\'t be lifted out of `tf.function`, thus it can be used as a\n-        `tf.function`-local variable: during each execution of the\n-        `tf.function`, the variable will be created and then disposed, similar\n-        to a local (i.e. stack-allocated) variable in C/C++. Currently\n-        `experimental_enable_variable_lifting=False` only works on non-XLA\n-        devices (e.g. under `@tf.function(jit_compile=False)`).\n+    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`.\n+        *   This allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n+    *   Added a new constructor argument `experimental_enable_variable_lifting` to `tf.Variable`, defaulting to True.\n+        *   When it\'s `False`, the variable won\'t be lifted out of `tf.function`, thus it can be used as a `tf.function`-local variable: during each execution of the `tf.function`, the variable will be created and then disposed, similar to a local (that is, stack-allocated) variable in C/C++. Currently, `experimental_enable_variable_lifting=False` only works on non-XLA devices (for example, under `@tf.function(jit_compile=False)`).\n \n *   TF SavedModel:\n-    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb`\n-        file is a protobuf containing the ""fingerprint"" of the SavedModel. See\n-        the [RFC](https://github.com/tensorflow/community/pull/415) for more\n-        details regarding its design and properties.\n+    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb` file is a protobuf containing the ""fingerprint"" of the SavedModel. See the [RFC](https://github.com/tensorflow/community/pull/415) for more details regarding its design and properties.\n+        \n+*   TF pip:\n+    *   Windows CPU-builds for x86/x64 processors are now built, maintained, tested and released by a third party: Intel. Installing the windows-native pip packages for `tensorflow` or `tensorflow-cpu` would install Intel\'s tensorflow-intel package. These packages are provided as-is. Tensorflow will use reasonable efforts to maintain the availability and integrity of this pip package. There may be delays if the third party fails to release the pip package. For using TensorFlow GPU on Windows, you will need to install TensorFlow in WSL2.\n \n ## Bug Fixes and Other Changes\n \n *   `tf.image`\n-    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which\n-        causes the returned value to be the local SSIM map instead of the global\n-        mean.\n+    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which causes the returned value to be the local SSIM map instead of the global mean.\n \n *   TF Core:\n \n-    *   `tf.custom_gradient` can now be applied to functions that accept\n-        ""composite"" tensors, such as `tf.RaggedTensor`, as inputs.\n-    *   Fix device placement issues related to datasets with ragged tensors of\n-        strings (i.e. variant encoded data with types not supported on GPU).\n-    *   \'experimental_follow_type_hints\' for tf.function has been deprecated.\n-        Please use input_signature or reduce_retracing to minimize retracing.\n+    *   `tf.custom_gradient` can now be applied to functions that accept ""composite"" tensors, such as `tf.RaggedTensor`, as inputs.\n+    *   Fix device placement issues related to datasets with ragged tensors of strings (i.e. variant encoded data with types not supported on GPU).\n+    *   `experimental_follow_type_hints` for tf.function has been deprecated. Please `use input_signature` or `reduce_retracing` to minimize retracing.\n \n *   `tf.SparseTensor`:\n     *   Introduced `set_shape`, which sets the static dense shape of the sparse tensor and has the same semantics as `tf.Tensor.set_shape`.\n@@ -131,7 +70,8 @@\n \n This release contains contributions from many people at Google, as well as:\n \n-<INSERT>, <NAME>, <HERE>, <USING>, <GITHUB>, <HANDLE>\n+103yiran, 8bitmp3, Aakar Dwivedi, Alexander Grund, alif_elham, Aman Agarwal, amoitra, Andrei Ivanov, andreii, Andrew Goodbody, angerson, Ashay Rane, Azeem Shaikh, Ben Barsdell, bhack, Bhavani Subramanian, Cedric Nugteren, Chandra Kumar Ramasamy, Christopher Bate, CohenAriel, Cotarou, cramasam, Enrico Minack, Francisco Unda, Frederic Bastien, gadagashwini, Gauri1 Deshpande, george, Jake, Jeff, Jerry Ge, Jingxuan He, Jojimon Varghese, Jonathan Dekhtiar, Kaixi Hou, Kanvi Khanna, kcoul, Keith Smiley, Kevin Hu, Kun Lu, kushanam, Lianmin Zheng, liuyuanqiang, Louis Sugy, Mahmoud Abuzaina, Marius Brehler, mdfaijul, Meenakshi Venkataraman, Milos Puzovic, mohantym, Namrata-Ibm, Nathan John Sircombe, Nathan Luehr, Olaf Lipinski, Om Thakkar, Osman F Bayram, Patrice Vignola, Pavani Majety, Philipp Hack, Prianka Liz Kariat, Rahul Batra, RajeshT, Renato Golin, riestere, Roger Iyengar, Rohit Santhanam, Rsanthanam-Amd, Sadeed Pv, Samuel Marks, Shimokawa, Naoaki, Siddhesh Kothadi, Simengliu-Nv, Sindre Seppola, snadampal, Srinivasan Narayanamoorthy, sushreebarsa, syedshahbaaz, Tamas Bela Feher, Tatwai Chong, Thibaut Goetghebuer-Planchon, tilakrayal, Tom Anderson, Tomohiro Endo, Trevor Morris, vibhutisawant, Victor Zhang, Vremold, Xavier Bonaventura, Yanming Wang, Yasir Modak, Yimei Sun, Yong Tang, Yulv-Git, zhuoran.liu, zotanika\n+\n \n # Release 2.10.0\n \n@@ -331,7 +271,8 @@ This release contains contributions from many people at Google, as well as:\n         bfloat16 auto-mixed precision grappler graph optimization pass has been\n         renamed from `auto_mixed_precision_mkl` to\n         `auto_mixed_precision_onednn_bfloat16`. See example usage\n-        [here](https://www.intel.com/content/www/us/en/developer/articles/guide/getting-started-with-automixedprecisionmkl.html).\n+        [here](https://www.\n+        .com/content/www/us/en/developer/articles/guide/getting-started-with-automixedprecisionmkl.html).\n     *   **aarch64 CPUs:** Experimental performance optimizations from\n         [Compute Library for the Arm\xc2\xae Architecture (ACL)](https://github.com/ARM-software/ComputeLibrary)\n         are available through oneDNN in the default Linux aarch64 package (`pip\ndiff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 14c0d4a0e6ef4..74f1a1bd03e8a 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -29,6 +29,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/tensor.h""\n \n+#include <memory>\n #include <utility>\n \n #include ""absl/strings/escaping.h""\n@@ -1183,12 +1184,10 @@ void PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n }\n \n template <typename T>\n-string SummarizeArray(int64_t limit, int64_t num_elts,\n-                      const TensorShape& tensor_shape, const char* data,\n-                      const bool print_v2) {\n+string SummarizeArrayInternal(int64_t limit, int64_t num_elts,\n+                              const TensorShape& tensor_shape, const T* array,\n+                              const bool print_v2) {\n   string ret;\n-  const T* array = reinterpret_cast<const T*>(data);\n-\n   const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n   if (shape.empty()) {\n     for (int64_t i = 0; i < limit; ++i) {\n@@ -1211,6 +1210,29 @@ string SummarizeArray(int64_t limit, int64_t num_elts,\n \n   return ret;\n }\n+\n+template <typename T>\n+string SummarizeArray(int64_t limit, int64_t num_elts,\n+                      const TensorShape& tensor_shape, const char* data,\n+                      const bool print_v2) {\n+  const T* array = reinterpret_cast<const T*>(data);\n+  return SummarizeArrayInternal<T>(limit, num_elts, tensor_shape, array,\n+                                   print_v2);\n+}\n+\n+template <>\n+string SummarizeArray<bool>(int64_t limit, int64_t num_elts,\n+                            const TensorShape& tensor_shape, const char* data,\n+                            const bool print_v2) {\n+  // We first convert all chars to be 0/1 to not get InvalidEnumValue sanitizer\n+  // error\n+  auto mutable_data = std::unique_ptr<char[]>(new char[num_elts]);\n+  for (int64_t i = 0; i < num_elts; ++i)\n+    mutable_data.get()[i] = data[i] ? 1 : 0;\n+  bool* array = reinterpret_cast<bool*>(mutable_data.get());\n+  return SummarizeArrayInternal<bool>(limit, num_elts, tensor_shape, array,\n+                                      print_v2);\n+}\n }  // namespace\n \n string Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\ndiff --git a/tensorflow/core/grappler/utils/functions.cc b/tensorflow/core/grappler/utils/functions.cc\nindex 8868465352f15..4620886868cf9 100644\n--- a/tensorflow/core/grappler/utils/functions.cc\n+++ b/tensorflow/core/grappler/utils/functions.cc\n@@ -291,6 +291,11 @@ Status MakeGrapplerFunctionItem(const FunctionDef& func,\n \n   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);\n   for (const auto& attr : func.arg_attr()) {\n+    if (attr.first >= inputs.size()) {\n+      return errors::InvalidArgument(""Invalid attribute index, got "",\n+                                     attr.first, "" but expected less than "",\n+                                     inputs.size());\n+    }\n     arg_attr.at(attr.first) = &attr.second;\n   }\n \ndiff --git a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc\nindex c97e9a521080d..9484c03b82eac 100644\n--- a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc\n+++ b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc\n@@ -130,51 +130,44 @@ static constexpr char kGraphTypeName[] = ""graph"";\n static constexpr char kShortTxtTypeName[] = ""short_txt"";\n static constexpr char kLongTxtTypeName[] = ""long_txt"";\n static constexpr char kDefaultFormatString[] = ""url"";\n-static constexpr int kDefaultWidth = 3;\n-static constexpr int kDefaultShowMetadata = 0;\n-static constexpr int kDefaultMergeFusion = 0;\n \n }  // namespace\n \n-StatusOr<GraphViewerParams> ParseGraphViewerParams(const ToolOptions& options) {\n+StatusOr<GraphViewerParams> ParseGraphViewerParams(\n+    const HloToolOptions& options) {\n   GraphViewerParams params;\n-  std::optional<std::string> type = GetParam<std::string>(options, ""type"");\n-  if (!type.has_value()) {\n+  if (!options.type.has_value()) {\n     return errors::InvalidArgument(""Graph viewer must provide a type option."");\n   }\n \n   // For graph type.\n-  if (type == kGraphTypeName) {\n-    params.type = type.value();\n-    if (std::optional<std::string> node_name =\n-            GetParam<std::string>(options, ""node_name"")) {\n-      params.node_name = node_name.value();\n+  if (options.type == kGraphTypeName) {\n+    params.type = options.type.value();\n+    if (options.node_name.has_value()) {\n+      params.node_name = options.node_name.value();\n     }\n \n-    params.graph_width =\n-        GetParamWithDefault<int>(options, ""graph_width"", kDefaultWidth);\n-    params.render_options.show_backend_config = GetParamWithDefault<int>(\n-        options, ""show_metadata"", kDefaultShowMetadata);\n-    params.render_options.show_fusion_subcomputations =\n-        !GetParamWithDefault<int>(options, ""merge_fusion"", kDefaultMergeFusion);\n-    params.format = GetRenderFormat(GetParamWithDefault<std::string>(\n-        options, ""format"", kDefaultFormatString));\n+    params.graph_width = options.graph_width;\n+    params.render_options.show_backend_config = options.show_metadata;\n+    params.render_options.show_fusion_subcomputations = !options.merge_fusion;\n+    params.format =\n+        GetRenderFormat(options.format.has_value() ? options.format.value()\n+                                                   : kDefaultFormatString);\n \n     return params;\n   }\n \n   // For txt type.\n-  if (type == kShortTxtTypeName || type == kLongTxtTypeName) {\n-    params.type = type.value();\n-    params.verbose = (type == kLongTxtTypeName);\n-    params.show_metadata =\n-        GetParamWithDefault(options, ""show_metadata"", kDefaultShowMetadata);\n+  if (options.type == kShortTxtTypeName || options.type == kLongTxtTypeName) {\n+    params.type = options.type.value();\n+    params.verbose = (options.type == kLongTxtTypeName);\n+    params.show_metadata = options.show_metadata;\n     return params;\n   }\n \n   // Unknown type.\n   return errors::InvalidArgument(""Unknown graph viewer type option: "",\n-                                 type.value());\n+                                 options.type.value());\n }\n \n xla::RenderedGraphFormat GetRenderFormat(const std::string& format_string) {\ndiff --git a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h\nindex e37e5de38719c..1b33d7de0e4a5 100644\n--- a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h\n+++ b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h\n@@ -43,7 +43,8 @@ struct GraphViewerParams {\n };\n \n // Parse tool options to get the parameters for graph viewer.\n-StatusOr<GraphViewerParams> ParseGraphViewerParams(const ToolOptions& options);\n+StatusOr<GraphViewerParams> ParseGraphViewerParams(\n+    const HloToolOptions& options);\n \n // Get graph render format.\n xla::RenderedGraphFormat GetRenderFormat(const std::string& format_string);\ndiff --git a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc\nindex ecba6d7f71b97..1a7e14968de27 100644\n--- a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc\n+++ b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc\n@@ -35,8 +35,9 @@ TEST(GraphViewerParamsTest, GraphType) {\n   // Default for graph type.\n   ToolOptions options1;\n   options1[""type""] = ""graph"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params1,\n-                          ParseGraphViewerParams(options1));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params1,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)));\n   EXPECT_EQ(params1.type, ""graph"");\n   EXPECT_EQ(params1.node_name, """");\n   EXPECT_EQ(params1.graph_width, 3);\n@@ -52,8 +53,9 @@ TEST(GraphViewerParamsTest, GraphType) {\n   options2[""show_metadata""] = 1;\n   options2[""merge_fusion""] = 1;\n   options2[""format""] = ""html"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params2,\n-                          ParseGraphViewerParams(options2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params2,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)));\n   EXPECT_EQ(params2.type, ""graph"");\n   EXPECT_EQ(params2.node_name, ""fusion.111"");\n   EXPECT_EQ(params2.graph_width, 10);\n@@ -66,8 +68,9 @@ TEST(GraphViewerParamsTest, ShortTxtType) {\n   // Default for short txt type.\n   ToolOptions options1;\n   options1[""type""] = ""short_txt"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params1,\n-                          ParseGraphViewerParams(options1));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params1,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)));\n   EXPECT_EQ(params1.type, ""short_txt"");\n   EXPECT_EQ(params1.verbose, false);\n   EXPECT_EQ(params1.show_metadata, false);\n@@ -76,8 +79,9 @@ TEST(GraphViewerParamsTest, ShortTxtType) {\n   ToolOptions options2;\n   options2[""type""] = ""short_txt"";\n   options2[""show_metadata""] = 1;\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params2,\n-                          ParseGraphViewerParams(options2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params2,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)));\n   EXPECT_EQ(params2.type, ""short_txt"");\n   EXPECT_EQ(params2.verbose, false);\n   EXPECT_EQ(params2.show_metadata, true);\n@@ -87,8 +91,9 @@ TEST(GraphViewerParamsTest, LongTxtType) {\n   // Default for long txt type.\n   ToolOptions options1;\n   options1[""type""] = ""long_txt"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params1,\n-                          ParseGraphViewerParams(options1));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params1,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)));\n   EXPECT_EQ(params1.type, ""long_txt"");\n   EXPECT_EQ(params1.verbose, true);\n   EXPECT_EQ(params1.show_metadata, false);\n@@ -97,8 +102,9 @@ TEST(GraphViewerParamsTest, LongTxtType) {\n   ToolOptions options2;\n   options2[""type""] = ""long_txt"";\n   options2[""show_metadata""] = 1;\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params2,\n-                          ParseGraphViewerParams(options2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params2,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)));\n   EXPECT_EQ(params2.type, ""long_txt"");\n   EXPECT_EQ(params2.verbose, true);\n   EXPECT_EQ(params2.show_metadata, true);\n@@ -106,13 +112,13 @@ TEST(GraphViewerParamsTest, LongTxtType) {\n \n TEST(GraphViewerParamsTest, OtherTypes) {\n   ToolOptions options1;\n-  EXPECT_THAT(ParseGraphViewerParams(options1),\n+  EXPECT_THAT(ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)),\n               StatusIs(error::INVALID_ARGUMENT,\n                        HasSubstr(""Graph viewer must provide a type option"")));\n \n   ToolOptions options2;\n   options2[""type""] = ""abcd"";\n-  EXPECT_THAT(ParseGraphViewerParams(options2),\n+  EXPECT_THAT(ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)),\n               StatusIs(error::INVALID_ARGUMENT,\n                        HasSubstr(""Unknown graph viewer type option: abcd"")));\n }\ndiff --git a/tensorflow/core/profiler/convert/hlo_to_tools_data.cc b/tensorflow/core/profiler/convert/hlo_to_tools_data.cc\nindex 51bb2bdf17ecc..96d726e3a46ac 100644\n--- a/tensorflow/core/profiler/convert/hlo_to_tools_data.cc\n+++ b/tensorflow/core/profiler/convert/hlo_to_tools_data.cc\n@@ -66,7 +66,7 @@ StatusOr<std::string> ConvertHloProtoToMemoryViewer(\n }\n \n StatusOr<std::string> ConvertHloProtoToGraphViewer(\n-    const xla::HloProto& hlo_proto, const ToolOptions& options) {\n+    const xla::HloProto& hlo_proto, const HloToolOptions& options) {\n   TF_ASSIGN_OR_RETURN(GraphViewerParams params,\n                       ParseGraphViewerParams(options));\n   if (params.type == ""graph"") {\n@@ -83,10 +83,9 @@ StatusOr<std::string> ConvertHloProtoToGraphViewer(\n \n StatusOr<std::string> ConvertHloProtoToToolData(\n     const SessionSnapshot& session_snapshot, const absl::string_view tool_name,\n-    const ToolOptions& options) {\n+    const HloToolOptions& options) {\n   // <options> must provide a hlo module_name field to identify the HLO module.\n-  std::optional<std::string> hlo_module_name =\n-      GetParam<std::string>(options, ""module_name"");\n+  std::optional<std::string> hlo_module_name = options.module_name;\n   if (!hlo_module_name.has_value() || hlo_module_name->empty()) {\n     return errors::InvalidArgument(\n         ""Can not find HLO module name from options."");\ndiff --git a/tensorflow/core/profiler/convert/hlo_to_tools_data.h b/tensorflow/core/profiler/convert/hlo_to_tools_data.h\nindex 7f43c2df30c83..bede2f8a31604 100644\n--- a/tensorflow/core/profiler/convert/hlo_to_tools_data.h\n+++ b/tensorflow/core/profiler/convert/hlo_to_tools_data.h\n@@ -33,7 +33,7 @@ namespace profiler {\n // successful, else return an error status.\n StatusOr<std::string> ConvertHloProtoToToolData(\n     const SessionSnapshot& session_snapshot, const absl::string_view tool_name,\n-    const ToolOptions& options);\n+    const HloToolOptions& options);\n \n }  // namespace profiler\n }  // namespace tensorflow\ndiff --git a/tensorflow/core/profiler/convert/tool_options.h b/tensorflow/core/profiler/convert/tool_options.h\nindex c83491859063f..942e53779e37f 100644\n--- a/tensorflow/core/profiler/convert/tool_options.h\n+++ b/tensorflow/core/profiler/convert/tool_options.h\n@@ -25,6 +25,17 @@ limitations under the License.\n namespace tensorflow {\n namespace profiler {\n \n+// Tool options for HloProtoToToolData conversion.\n+struct HloToolOptions {\n+  std::optional<std::string> module_name;\n+  std::optional<std::string> type;\n+  std::optional<std::string> node_name;\n+  std::optional<std::string> format;\n+  int graph_width;\n+  bool show_metadata;\n+  bool merge_fusion;\n+};\n+\n using ToolOptions =\n     absl::flat_hash_map<std::string, std::variant<int, std::string>>;\n \n@@ -53,6 +64,20 @@ T GetParamWithDefault(const ToolOptions& options, const std::string& key,\n   return default_param;\n }\n \n+inline HloToolOptions ToolOptionsToHloToolOptions(const ToolOptions& options) {\n+  HloToolOptions hlo_options;\n+  hlo_options.module_name = GetParam<std::string>(options, ""module_name"");\n+  hlo_options.type = GetParam<std::string>(options, ""type"");\n+  hlo_options.node_name = GetParam<std::string>(options, ""node_name"");\n+  hlo_options.format = GetParam<std::string>(options, ""format"");\n+  hlo_options.graph_width = GetParamWithDefault<int>(options, ""graph_width"", 3);\n+  hlo_options.show_metadata =\n+      GetParamWithDefault<int>(options, ""show_metadata"", 0);\n+  hlo_options.merge_fusion =\n+      GetParamWithDefault<int>(options, ""merge_fusion"", 0);\n+  return hlo_options;\n+}\n+\n }  // namespace profiler\n }  // namespace tensorflow\n \ndiff --git a/tensorflow/core/profiler/convert/xplane_to_tools_data.cc b/tensorflow/core/profiler/convert/xplane_to_tools_data.cc\nindex 787287d010734..f5e6f78928602 100644\n--- a/tensorflow/core/profiler/convert/xplane_to_tools_data.cc\n+++ b/tensorflow/core/profiler/convert/xplane_to_tools_data.cc\n@@ -252,7 +252,8 @@ StatusOr<std::string> ConvertMultiXSpacesToToolData(\n   } else if (tool_name == ""op_profile"") {\n     return ConvertMultiXSpacesToOpProfileViewer(session_snapshot);\n   } else if (tool_name == ""memory_viewer"" || tool_name == ""graph_viewer"") {\n-    return ConvertHloProtoToToolData(session_snapshot, tool_name, options);\n+    return ConvertHloProtoToToolData(session_snapshot, tool_name,\n+                                     ToolOptionsToHloToolOptions(options));\n   } else if (tool_name == ""tool_names"") {\n     return GetAvailableToolNames(session_snapshot);\n   } else if (tool_name == ""_xplane.pb"") {  // internal test only.\ndiff --git a/tensorflow/core/public/version.h b/tensorflow/core/public/version.h\nindex 2a94515d20d14..43935b17fb80d 100644\n--- a/tensorflow/core/public/version.h\n+++ b/tensorflow/core/public/version.h\n@@ -26,7 +26,7 @@ limitations under the License.\n \n // TF_VERSION_SUFFIX is non-empty for pre-releases (e.g. ""-alpha"", ""-alpha.1"",\n // ""-beta"", ""-rc"", ""-rc.1"")\n-#define TF_VERSION_SUFFIX """"\n+#define TF_VERSION_SUFFIX ""-rc1""\n \n #define TF_STR_HELPER(x) #x\n #define TF_STR(x) TF_STR_HELPER(x)\ndiff --git a/tensorflow/tools/pip_package/setup.py b/tensorflow/tools/pip_package/setup.py\nindex cc23caac4cb8b..62a1bdb7e7b1d 100644\n--- a/tensorflow/tools/pip_package/setup.py\n+++ b/tensorflow/tools/pip_package/setup.py\n@@ -46,7 +46,7 @@\n # result for pip.\n # Also update tensorflow/tensorflow.bzl and\n # tensorflow/core/public/version.h\n-_VERSION = \'2.11.0\'\n+_VERSION = \'2.11.0-rc1\'\n \n \n # We use the same setup.py for all tensorflow_* packages and for the nightly\n@@ -120,10 +120,10 @@ def standard_or_nightly(standard, nightly):\n     # These are all updated during the TF release process.\n     standard_or_nightly(\'tensorboard >= 2.10, < 2.11\',\n                         \'tb-nightly ~= 2.11.0.a\'),\n-    standard_or_nightly(\'tensorflow_estimator >= 2.10.0rc0, < 2.11\',\n-                        \'tf-estimator-nightly ~= 2.11.0.dev\'),\n-    standard_or_nightly(\'keras >= 2.10.0rc0, < 2.11\',\n-                        \'keras-nightly ~= 2.11.0.dev\'),\n+    standard_or_nightly(\'tensorflow_estimator >= 2.11.0rc0, < 2.12\',\n+                        \'tf-estimator-nightly ~= 2.12.0.dev\'),\n+    standard_or_nightly(\'keras >= 2.11.0rc1, < 2.12\',\n+                        \'keras-nightly ~= 2.12.0.dev\'),\n ]\n REQUIRED_PACKAGES = [p for p in REQUIRED_PACKAGES if p is not None]\n \ndiff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex aee820d6e4025..5b230d194b286 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -186,9 +186,9 @@ def _tf_repositories():\n     tf_http_archive(\n         name = ""mkl_dnn_v1"",\n         build_file = ""//third_party/mkl_dnn:mkldnn_v1.BUILD"",\n-        sha256 = ""fc2b617ec8dbe907bb10853ea47c46f7acd8817bc4012748623d911aca43afbb"",\n-        strip_prefix = ""oneDNN-2.7"",\n-        urls = tf_mirror_urls(""https://github.com/oneapi-src/oneDNN/archive/refs/tags/v2.7.tar.gz""),\n+        sha256 = ""dc2b9bc851cd8d5a6c4622f7dc215bdb6b32349962875f8bf55cceed45a4c449"",\n+        strip_prefix = ""oneDNN-2.7.1"",\n+        urls = tf_mirror_urls(""https://github.com/oneapi-src/oneDNN/archive/refs/tags/v2.7.1.tar.gz""),\n     )\n \n     tf_http_archive(\ndiff --git a/third_party/mkl_dnn/mkldnn_v1.BUILD b/third_party/mkl_dnn/mkldnn_v1.BUILD\nindex 3c1c9d85d0a23..a60fe78a57ad1 100644\n--- a/third_party/mkl_dnn/mkldnn_v1.BUILD\n+++ b/third_party/mkl_dnn/mkldnn_v1.BUILD\n@@ -104,7 +104,7 @@ template_rule(\n     substitutions = {\n         ""@DNNL_VERSION_MAJOR@"": ""2"",\n         ""@DNNL_VERSION_MINOR@"": ""7"",\n-        ""@DNNL_VERSION_PATCH@"": ""0"",\n+        ""@DNNL_VERSION_PATCH@"": ""1"",\n         ""@DNNL_VERSION_HASH@"": ""N/A"",\n     },\n )\n@@ -116,7 +116,6 @@ _COPTS_LIST = select({\n     ""-UUSE_MKL"",\n     ""-UUSE_CBLAS"",\n     ""-DDNNL_ENABLE_MAX_CPU_ISA"",\n-    ""-DDNNL_DISABLE_PRIMITIVE_CACHE"",\n ] + tf_openmp_copts()\n \n _INCLUDES_LIST = [\n'","['Insert release notes place-fill', 'Update release notes for TensorFlow 2.11.0\n\nUpdate release notes for TensorFlow 2.11.0', 'Merge pull request #58128 from tensorflow-jenkins/relnotes-2.11.0rc0-9386\n\nUpdate release notes for TensorFlow 2.11.0', 'Update version numbers to 2.11.0-rc0', 'Merge pull request #58129 from tensorflow-jenkins/version-numbers-2.11.0rc0-5477\n\nUpdate version numbers for TensorFlow 2.11.0-rc0', 'Fix minor typos in release notes', 'Refactor/update TensorFlow 2.11 RELEASE.md (#58132)', 'Merge pull request #58130 from tensorflow/fix-relnotes\n\nFix minor typos in release notes', 'Added info about Windows CPU build destination\n\nAdded info about Windows CPU build destination', 'Update setup.py', 'Update tensorflow/tools/pip_package/setup.py', 'Merge pull request #58152 from tensorflow/learning-to-play-patch-1\n\nUpdate Keras and Estimator dependency versions in setup.py', 'Update version numbers to 2.11.0-rc1', 'Merge pull request #58158 from tensorflow-jenkins/version-numbers-2.11.0rc1-1549\n\nUpdate version numbers for TensorFlow 2.11.0-rc1', 'Notice of deletion of legacy keras code.', 'Merge pull request #58169 from tensorflow/qlzh727-patch-1\n\nNotice of deletion of legacy keras code.', 'Fix the relnotes\n\nFixes one typo and removes lines breaks which cause relnotes in the GitHub release page to show up in the wrong place.', 'Merge pull request #58170 from tensorflow/Fix-rel-notes\n\nFix-rel-notes', 'Pass HloToolOptions instead of ToolOptions to ConvertHloProtoToToolData\n\nPiperOrigin-RevId: 482033483', 'Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391', ""Resolve a sanitizer issue with invalid char -> bool conversion.\n\nWhen printing a tensor, we get it's data as a `const char*` array (since that's the underlying storage) and then we typecast it to the element type. However, conversions from `char` to `bool` are undefined if the `char` is not `0` or `1`, so sanitizers/fuzzers will crash.\n\nTo fix, we're creating a mutable `char` array to convert the chars to 0/1, according to bool rules.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482297563"", 'Merge pull request #58200 from tensorflow/r2.11-1be74370327\n\nr2.11 cherry-pick: 1be74370327 ""Resolve a sanitizer issue with invalid char -> bool conversion.""', 'Merge pull request #58198 from tensorflow/r2.11-a65411a1d69\n\nr2.11 cherry-pick: a65411a1d69 ""Fix OOB write in grappler.""', 'Merge pull request #58193 from tensorflow/r2.11-34dadfa8b09\n\nr2.11 cherry-pick: 34dadfa8b09 ""Pass HloToolOptions instead of ToolOptions to ConvertHloProtoToToolData""', 'Upgrade to the latest oneDNN 2.7.1']",[],2022-10-23 23:21:13
58266,Fix zlib download URL,"Using `zlib.net/zlib-${version}.tar.gz` only works if `${version}` is the last released version. So we would need to keep updating this file in a rush each time a new release of `zlib` occurs.

However, all previous releases are at https://zlib.net/fossils/ so we won't need to do changes in a crunch (though it would still be good to bump dependencies as needed).",mihaimaruseac,[],[],[],[],['mihaimaruseac'],"b'diff --git a/tensorflow/workspace2.bzl b/tensorflow/workspace2.bzl\nindex 2384952580e9d..925e9566563ce 100644\n--- a/tensorflow/workspace2.bzl\n+++ b/tensorflow/workspace2.bzl\n@@ -574,7 +574,7 @@ def _tf_repositories():\n         sha256 = ""b3a24de97a8fdbc835b9833169501030b8977031bcb54b3b3ac13740f846ab30"",\n         strip_prefix = ""zlib-1.2.13"",\n         system_build_file = ""//third_party/systemlibs:zlib.BUILD"",\n-        urls = tf_mirror_urls(""https://zlib.net/zlib-1.2.13.tar.gz""),\n+        urls = tf_mirror_urls(""https://zlib.net/fossils/zlib-1.2.13.tar.gz""),\n     )\n \n     # LINT.IfChange\n'","[""Fix zlib download URL\n\nUsing `zlib.net/zlib-${version}.tar.gz` only works if `${version}` is the last released version. So we would need to keep updating this file in a rush each time a new release of `zlib` occurs.\n\nHowever, all previous releases are at https://zlib.net/fossils/ so we won't need to do changes in a crunch (though it would still be good to bump dependencies as needed).""]",[],2022-10-23 14:51:14
58260,Update libjpeg_turbo,"Update libjpeg-turbo from 2.1.0 to 2.1.4

- Refactoring: Switching from `template_rule` to `expand_template` (from Skylib) - in the long term all occurrences should be replaced
- In 2.1.4 there is a new template file ""jversion.h.in"" that needs to be ""configured""",Vertexwahn,[],[],['mihaimaruseac'],['mihaimaruseac'],['gbaned'],"b'diff --git a/third_party/jpeg/jpeg.BUILD b/third_party/jpeg/jpeg.BUILD\nindex cc17e06ff1774..747b643cdfffa 100644\n--- a/third_party/jpeg/jpeg.BUILD\n+++ b/third_party/jpeg/jpeg.BUILD\n@@ -1,7 +1,7 @@\n # Description:\n #   libjpeg-turbo is a drop in replacement for jpeglib optimized with SIMD.\n \n-load(""@org_tensorflow//third_party:common.bzl"", ""template_rule"")\n+load(""@bazel_skylib//rules:expand_template.bzl"", ""expand_template"")\n \n licenses([""notice""])  # custom notice-style license, see LICENSE.md\n \n@@ -312,9 +312,9 @@ genrule(\n     tools = [""@nasm""],\n )\n \n-template_rule(\n+expand_template(\n     name = ""neon-compat_gen"",\n-    src = ""simd/arm/neon-compat.h.in"",\n+    template = ""simd/arm/neon-compat.h.in"",\n     out = ""simd/arm/neon-compat.h"",\n     substitutions = {\n         ""#cmakedefine HAVE_VLD1_S16_X3"": ""#define HAVE_VLD1_S16_X3"",\n@@ -526,18 +526,28 @@ cc_library(\n         ""jsimd.h"",\n         ""jsimd_none.c"",\n         ""jsimddct.h"",\n+        ""jconfigint.h"",\n     ],\n     copts = libjpegturbo_copts,\n )\n \n-template_rule(\n+expand_template(\n+    name = ""jversion"",\n+    template = ""jversion.h.in"",\n+    out = ""jversion.h"",\n+    substitutions = {\n+        ""@COPYRIGHT_YEAR@"": ""1991-2022"",\n+    },\n+)\n+\n+expand_template(\n     name = ""jconfig_win"",\n-    src = ""win/jconfig.h.in"",\n+    template = ""win/jconfig.h.in"",\n     out = ""jconfig_win.h"",\n     substitutions = {\n         ""@JPEG_LIB_VERSION@"": ""62"",\n-        ""@VERSION@"": ""2.0.0"",\n-        ""@LIBJPEG_TURBO_VERSION_NUMBER@"": ""2000000"",\n+        ""@VERSION@"": ""2.1.4"",\n+        ""@LIBJPEG_TURBO_VERSION_NUMBER@"": ""2001004"",\n         ""@BITS_IN_JSAMPLE@"": ""8"",\n         ""#cmakedefine C_ARITH_CODING_SUPPORTED"": ""#define C_ARITH_CODING_SUPPORTED"",\n         ""#cmakedefine D_ARITH_CODING_SUPPORTED"": ""#define D_ARITH_CODING_SUPPORTED"",\n@@ -548,8 +558,8 @@ template_rule(\n \n JCONFIG_NOWIN_COMMON_SUBSTITUTIONS = {\n     ""@JPEG_LIB_VERSION@"": ""62"",\n-    ""@VERSION@"": ""2.0.0"",\n-    ""@LIBJPEG_TURBO_VERSION_NUMBER@"": ""2000000"",\n+    ""@VERSION@"": ""2.1.4"",\n+    ""@LIBJPEG_TURBO_VERSION_NUMBER@"": ""2001004"",\n     ""#cmakedefine C_ARITH_CODING_SUPPORTED 1"": ""#define C_ARITH_CODING_SUPPORTED 1"",\n     ""#cmakedefine D_ARITH_CODING_SUPPORTED 1"": ""#define D_ARITH_CODING_SUPPORTED 1"",\n     ""#cmakedefine MEM_SRCDST_SUPPORTED 1"": ""#define MEM_SRCDST_SUPPORTED 1"",\n@@ -580,23 +590,23 @@ JCONFIG_NOWIN_SIMD_SUBSTITUTIONS.update(JCONFIG_NOWIN_COMMON_SUBSTITUTIONS)\n \n JCONFIG_NOWIN_NOSIMD_SUBSTITUTIONS.update(JCONFIG_NOWIN_COMMON_SUBSTITUTIONS)\n \n-template_rule(\n+expand_template(\n     name = ""jconfig_nowin_nosimd"",\n-    src = ""jconfig.h.in"",\n+    template  = ""jconfig.h.in"",\n     out = ""jconfig_nowin_nosimd.h"",\n     substitutions = JCONFIG_NOWIN_NOSIMD_SUBSTITUTIONS,\n )\n \n-template_rule(\n+expand_template(\n     name = ""jconfig_nowin_simd"",\n-    src = ""jconfig.h.in"",\n+    template  = ""jconfig.h.in"",\n     out = ""jconfig_nowin_simd.h"",\n     substitutions = JCONFIG_NOWIN_SIMD_SUBSTITUTIONS,\n )\n \n JCONFIGINT_COMMON_SUBSTITUTIONS = {\n-    ""@BUILD@"": ""20210424"",\n-    ""@VERSION@"": ""2.1.0"",\n+    ""@BUILD@"": ""20221022"",\n+    ""@VERSION@"": ""2.1.4"",\n     ""@CMAKE_PROJECT_NAME@"": ""libjpeg-turbo"",\n     ""#undef inline"": """",\n     ""#cmakedefine HAVE_INTRIN_H"": """",\n@@ -632,16 +642,16 @@ JCONFIGINT_NOWIN_SUBSTITUTIONS.update(JCONFIGINT_COMMON_SUBSTITUTIONS)\n \n JCONFIGINT_WIN_SUBSTITUTIONS.update(JCONFIGINT_COMMON_SUBSTITUTIONS)\n \n-template_rule(\n+expand_template(\n     name = ""jconfigint_nowin"",\n-    src = ""jconfigint.h.in"",\n+    template = ""jconfigint.h.in"",\n     out = ""jconfigint_nowin.h"",\n     substitutions = JCONFIGINT_NOWIN_SUBSTITUTIONS,\n )\n \n-template_rule(\n+expand_template(\n     name = ""jconfigint_win"",\n-    src = ""jconfigint.h.in"",\n+    template = ""jconfigint.h.in"",\n     out = ""jconfigint_win.h"",\n     substitutions = JCONFIGINT_WIN_SUBSTITUTIONS,\n )\ndiff --git a/third_party/jpeg/workspace.bzl b/third_party/jpeg/workspace.bzl\nindex cf87cbdd8bbcf..631cc933bc60d 100644\n--- a/third_party/jpeg/workspace.bzl\n+++ b/third_party/jpeg/workspace.bzl\n@@ -5,9 +5,9 @@ load(""//third_party:repo.bzl"", ""tf_http_archive"", ""tf_mirror_urls"")\n def repo():\n     tf_http_archive(\n         name = ""libjpeg_turbo"",\n-        urls = tf_mirror_urls(""https://github.com/libjpeg-turbo/libjpeg-turbo/archive/2.1.0.tar.gz""),\n-        sha256 = ""d6b7790927d658108dfd3bee2f0c66a2924c51ee7f9dc930f62c452f4a638c52"",\n-        strip_prefix = ""libjpeg-turbo-2.1.0"",\n+        urls = tf_mirror_urls(""https://github.com/libjpeg-turbo/libjpeg-turbo/archive/refs/tags/2.1.4.tar.gz""),\n+        sha256 = ""a78b05c0d8427a90eb5b4eb08af25309770c8379592bb0b8a863373128e6143f"",\n+        strip_prefix = ""libjpeg-turbo-2.1.4"",\n         build_file = ""//third_party/jpeg:jpeg.BUILD"",\n         system_build_file = ""//third_party/jpeg:BUILD.system"",\n     )\n'",['Update libjpeg_tubo'],[],2022-10-22 11:53:30
58259,Range kenrel: align CPU and GPU impl,Fixes https://github.com/tensorflow/tensorflow/issues/58133,bhack,['bhack'],['https://github.com/tensorflow/tensorflow/blob/ce4f713b287e591f5a04002eccca90c26f741af7/tensorflow/core/kernels/sequence_ops_gpu.cu.cc#L34-L36'],"['bhack', 'cantonios']","['bhack', 'cantonios']",['gbaned'],"b'diff --git a/tensorflow/core/kernels/sequence_ops.cc b/tensorflow/core/kernels/sequence_ops.cc\nindex 9175c42841ab1..2cd47f15df499 100644\n--- a/tensorflow/core/kernels/sequence_ops.cc\n+++ b/tensorflow/core/kernels/sequence_ops.cc\n@@ -38,10 +38,8 @@ struct RangeFunctor<CPUDevice, T> {\n   void operator()(OpKernelContext* context, int64_t size, T start, T delta,\n                   typename TTypes<T>::Flat output) const {\n     (void)context;\n-    T val = start;\n     for (int64_t i = 0; i < size; ++i) {\n-      output(i) = T(val);\n-      val += delta;\n+      output(i) = start + static_cast<T>(i) * delta;\n     }\n   }\n };\n'",['Align CPU and GPU impl'],[],2022-10-22 08:47:04
58256,Improving converters for Select/SelectV2 operations.,The converters for `Select/SelectV2` operations have been improved to cover some additional `DynamicShape` mode test cases. ,drivanov,['bixia1'],"['Please add a period to the end of a comment.', 'Add a period to the end of the comment.']",['bixia1'],['bixia1'],['gbaned'],b'',[],[],2022-10-22 03:37:24
58254,[NVIDIA TF] Unit tests for bf16 random ops on GPU,"Follow-up to https://github.com/tensorflow/tensorflow/pull/58203
Tests are currently gated to only run on Ampere GPUs or newer.

cc @reedwm ",trevor-m,"['reedwm', 'trevor-m']","['Why change the seed?', ""Thanks @reedwm for the review!\r\n\r\nThe [comments](https://github.com/tensorflow/tensorflow/blob/8627ff994e2c79f1ab10598566fbabaf9687952a/tensorflow/python/kernel_tests/random/stateful_random_ops_test.py#L558-L561) on the test stated this: \r\n```\r\n# Tests that the values are distributed amongst 10 bins with equal\r\n# probability. 16.92 is the Chi^2 value for 9 degrees of freedom with\r\n# p=0.05. This test is probabilistic and would be flaky if the random\r\n# seed were not fixed.\r\n```\r\n\r\nWith the original seed, the bf16 test didn't pass. I tried a few other seeds and some would cause fp16 to fail and bf16 to pass, but `123` worked for both. Not sure if there is a better way like adjusting the threshold, but it kinda seemed like the seed was already cherry-picked for FP16 so it felt like it was okay to adjust it for bf16 too."", 'Unfortunately, calling `is_gpu_available` before `test.main()` is not allowed in the internal version of TF. Note `test.main()` is called at the bottom of the file to run all the tests.\r\n\r\nTo fix, I would create a function that returns these floating-point types, maybe called `get_float_types`, and call it everywhere you currently use `FLOATS`.\r\n\r\n', 'Got it, that sounds good to me.', 'I think this still has the issue where `is_gpu_available` is called before `test.main`, since decorator arguments are called are called as soon as the function is defined, I think. Sorry for not catching this before, I only read the first file when making the comment and mistakenly assumed this file was the same.\r\n\r\nThis is annoying to fix. Probably the best way would be bring back the `FLOATS` argument but unconditionally include `bfloat16`. Then at the start of each test using `FLOATS`, add:\r\n\r\n```\r\nif dtype == dtypes.bfloat16 and not test_util.is_gpu_available(cuda_only=True, min_cuda_compute_capability=(8, 0)):\r\n  self.skipTest(""Bfloat16 requires compute capability 8.0"")\r\n```\r\n\r\nIt might also be possible to create a decorator to skip bf16 that only calls `is_gpu_available` when the test method is run, not defined. But I\'m not sure sure how to do this, so if you don\'t know either, I would just go with thef irst approach. \r\n  ', 'Ah, I had the same worry about the decorators. Your skip approach looks good.']","['cheshire', 'reedwm', 'trevor-m', 'reedwm', 'reedwm', 'trevor-m', 'reedwm', 'trevor-m', 'reedwm']","['cheshire', 'reedwm', 'trevor-m', 'reedwm', 'reedwm', 'trevor-m', 'reedwm', 'trevor-m', 'reedwm']","['rohan100jain', 'cheshire', 'reedwm', 'bfontain', 'chsigg', 'gbaned', 'gcforster']","b'diff --git a/tensorflow/python/kernel_tests/random/random_ops_test.py b/tensorflow/python/kernel_tests/random/random_ops_test.py\nindex 84ecf46d748e4..c9a1afbc74865 100644\n--- a/tensorflow/python/kernel_tests/random/random_ops_test.py\n+++ b/tensorflow/python/kernel_tests/random/random_ops_test.py\n@@ -29,6 +29,12 @@\n from tensorflow.python.ops import variables\n from tensorflow.python.platform import test\n \n+def get_float_types():\n+  float_types = [dtypes.float16, dtypes.float32, dtypes.float64]\n+  if test_util.is_gpu_available(\n+        cuda_only=True, min_cuda_compute_capability=(8, 0)):\n+    float_types += [dtypes.bfloat16]\n+  return float_types\n \n class RandomOpTestCommon(test.TestCase):\n \n@@ -77,7 +83,7 @@ def func():\n   # to see the same sequence of values. Will catch buggy\n   # implementations which uses the same random number seed.\n   def testDistinct(self):\n-    for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+    for dt in get_float_types():\n       sampler = self._Sampler(1000, 0.0, 1.0, dt, use_gpu=True)\n       x = sampler()\n       y = sampler()\n@@ -93,20 +99,22 @@ def testDistinct(self):\n   # given the same random seed\n   @test_util.run_deprecated_v1\n   def testCPUGPUMatch(self):\n-    for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+    for dt in get_float_types():\n       results = {}\n       for use_gpu in [False, True]:\n         sampler = self._Sampler(\n             1000000, 0.0, 1.0, dt, use_gpu=use_gpu, seed=12345)\n         results[use_gpu] = sampler()\n+      rtol = atol = 1e-6\n       if dt == dtypes.float16:\n-        self.assertAllClose(results[False], results[True], rtol=1e-3, atol=1e-3)\n-      else:\n-        self.assertAllClose(results[False], results[True], rtol=1e-6, atol=1e-6)\n+        rtol = atol = 1e-3\n+      elif  dt == dtypes.bfloat16:\n+        rtol = atol = 1e-1\n+      self.assertAllClose(results[False], results[True], rtol=rtol, atol=atol)\n \n   @test_util.run_deprecated_v1\n   def testSeed(self):\n-    for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+    for dt in get_float_types():\n       sx = self._Sampler(1000, 0.0, 1.0, dt, use_gpu=True, seed=345)\n       sy = self._Sampler(1000, 0.0, 1.0, dt, use_gpu=True, seed=345)\n       self.assertAllEqual(sx(), sy())\n@@ -124,14 +132,14 @@ def testNoCSE(self):\n   @test_util.run_deprecated_v1\n   def testSingleSessionNotConstant(self):\n     for use_gpu in [False, True]:\n-      for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+      for dt in get_float_types():\n         self._testSingleSessionNotConstant(\n             random_ops.random_normal, 100, dt, 0.0, 1.0, use_gpu=use_gpu)\n \n   @test_util.run_deprecated_v1\n   def testSingleSessionOpSeedNotConstant(self):\n     for use_gpu in [False, True]:\n-      for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+      for dt in get_float_types():\n         self._testSingleSessionNotConstant(\n             random_ops.random_normal,\n             100,\n@@ -144,7 +152,7 @@ def testSingleSessionOpSeedNotConstant(self):\n   @test_util.run_deprecated_v1\n   def testSingleSessionGraphSeedNotConstant(self):\n     for use_gpu in [False, True]:\n-      for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+      for dt in get_float_types():\n         self._testSingleSessionNotConstant(\n             random_ops.random_normal,\n             100,\n@@ -177,7 +185,7 @@ def func():\n   def testDistinct(self):\n     # NOTE: TruncatedNormal on GPU is not supported.\n     if not test.is_gpu_available():\n-      for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+      for dt in get_float_types():\n         sampler = self._Sampler(1000, 0.0, 1.0, dt, use_gpu=False)\n         x = sampler()\n         y = sampler()\n@@ -197,7 +205,7 @@ def testCPUGPUMatch(self):\n     if not test.is_gpu_available():\n       return\n \n-    for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+    for dt in get_float_types():\n       results = {}\n       for use_gpu in [False, True]:\n         # We need a particular larger number of samples to test multiple rounds\n@@ -205,14 +213,16 @@ def testCPUGPUMatch(self):\n         sampler = self._Sampler(\n             1000000, 0.0, 1.0, dt, use_gpu=use_gpu, seed=12345)\n         results[use_gpu] = sampler()\n+      atol = rtol = 1e-6\n       if dt == dtypes.float16:\n-        self.assertAllClose(results[False], results[True], rtol=1e-3, atol=1e-3)\n-      else:\n-        self.assertAllClose(results[False], results[True], rtol=1e-6, atol=1e-6)\n+        atol = rtol = 1e-3\n+      if dt == dtypes.bfloat16:\n+        atol = rtol = 1e-1\n+      self.assertAllClose(results[False], results[True], rtol=rtol, atol=atol)\n \n   @test_util.run_deprecated_v1\n   def testSeed(self):\n-    for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+    for dt in get_float_types():\n       sx = self._Sampler(1000, 0.0, 1.0, dt, use_gpu=True, seed=345)\n       sy = self._Sampler(1000, 0.0, 1.0, dt, use_gpu=True, seed=345)\n       self.assertAllEqual(sx(), sy())\n@@ -220,7 +230,7 @@ def testSeed(self):\n   # The effective standard deviation of truncated normal is 85% of the\n   # requested one.\n   def testStdDev(self):\n-    for dt in dtypes.float16, dtypes.float32, dtypes.float64:\n+    for dt in get_float_types():\n       stddev = 3.0\n       sampler = self._Sampler(100000, 0.0, stddev, dt, use_gpu=True)\n       x = sampler()\n@@ -287,8 +297,7 @@ def func():\n     return func\n \n   def testRange(self):\n-    for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-               dtypes.int64):\n+    for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n       sampler = self._Sampler(1000, minv=-2, maxv=8, dtype=dt, use_gpu=True)\n       x = sampler()\n       self.assertTrue(-2 <= np.min(x))\n@@ -298,14 +307,17 @@ def testRange(self):\n   # to see the same sequence of values. Will catch buggy\n   # implementations which uses the same random number seed.\n   def testDistinct(self):\n-    for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-               dtypes.int64):\n+    for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n       maxv = 1.0 if dt.is_floating else 1 << 30\n       sampler = self._Sampler(1000, minv=0, maxv=maxv, dtype=dt, use_gpu=True)\n       x = sampler()\n       y = sampler()\n       count = (x == y).sum()\n-      count_limit = 50 if dt == dtypes.float16 else 10\n+      count_limit = 10\n+      if dt == dtypes.float16:\n+        count_limit = 50\n+      elif dt == dtypes.bfloat16:\n+        count_limit = 90\n       if count >= count_limit:\n         print(""x = "", x)\n         print(""y = "", y)\n@@ -360,8 +372,7 @@ def sample(n):\n   # given the same random seed\n   @test_util.run_deprecated_v1\n   def testCPUGPUMatch(self):\n-    for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-               dtypes.int64):\n+    for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n       maxv = 1.0 if dt.is_floating else 17\n       results = {}\n       for use_gpu in False, True:\n@@ -372,8 +383,7 @@ def testCPUGPUMatch(self):\n \n   @test_util.run_deprecated_v1\n   def testSeed(self):\n-    for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-               dtypes.int64):\n+    for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n       for seed in [345, 2**100, -2**100]:\n         sx = self._Sampler(1000, 0, 17, dtype=dt, use_gpu=True, seed=seed)\n         sy = self._Sampler(1000, 0, 17, dtype=dt, use_gpu=True, seed=seed)\n@@ -392,16 +402,14 @@ def testNoCSE(self):\n   @test_util.run_deprecated_v1\n   def testSingleSessionNotConstant(self):\n     for use_gpu in [False, True]:\n-      for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-                 dtypes.int64):\n+      for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n         self._testSingleSessionNotConstant(\n             random_ops.random_uniform, 100, dt, 0, 17, use_gpu=use_gpu)\n \n   @test_util.run_deprecated_v1\n   def testSingleSessionOpSeedNotConstant(self):\n     for use_gpu in [False, True]:\n-      for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-                 dtypes.int64):\n+      for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n         self._testSingleSessionNotConstant(\n             random_ops.random_uniform,\n             100,\n@@ -414,8 +422,7 @@ def testSingleSessionOpSeedNotConstant(self):\n   @test_util.run_deprecated_v1\n   def testSingleSessionGraphSeedNotConstant(self):\n     for use_gpu in [False, True]:\n-      for dt in (dtypes.float16, dtypes.float32, dtypes.float64, dtypes.int32,\n-                 dtypes.int64):\n+      for dt in get_float_types() + [dtypes.int32, dtypes.int64]:\n         self._testSingleSessionNotConstant(\n             random_ops.random_uniform,\n             100,\ndiff --git a/tensorflow/python/kernel_tests/random/stateful_random_ops_test.py b/tensorflow/python/kernel_tests/random/stateful_random_ops_test.py\nindex 27db7570bd167..c8629b0f32648 100644\n--- a/tensorflow/python/kernel_tests/random/stateful_random_ops_test.py\n+++ b/tensorflow/python/kernel_tests/random/stateful_random_ops_test.py\n@@ -41,10 +41,7 @@\n g_seeded = None\n g_unseeded = None\n \n-\n-GPU_FLOATS = [dtypes.float16, dtypes.float32, dtypes.float64]\n-CPU_FLOATS = GPU_FLOATS + [dtypes.bfloat16]\n-FLOATS = GPU_FLOATS\n+FLOATS = [dtypes.bfloat16, dtypes.float16, dtypes.float32, dtypes.float64]\n INTS = [dtypes.int32, dtypes.int64]\n \n \n@@ -493,7 +490,7 @@ def testSameAsOldRandomOpsCPU(self):\n \n     The CPU version.\n     """"""\n-    self._sameAsOldRandomOps(""/device:CPU:0"", CPU_FLOATS)\n+    self._sameAsOldRandomOps(""/device:CPU:0"", FLOATS)\n \n   @test_util.run_v2_only\n   @test_util.run_cuda_only\n@@ -502,7 +499,11 @@ def testSameAsOldRandomOpsGPU(self):\n \n     The GPU version.\n     """"""\n-    self._sameAsOldRandomOps(test_util.gpu_device_name(), GPU_FLOATS)\n+    floats = [dtypes.float16, dtypes.float32, dtypes.float64]\n+    if test_util.is_gpu_available(\n+          cuda_only=True, min_cuda_compute_capability=(8, 0)):\n+      floats += [dtypes.bfloat16]\n+    self._sameAsOldRandomOps(test_util.gpu_device_name(), floats)\n \n   @parameterized.parameters(INTS + [dtypes.uint32, dtypes.uint64])\n   @test_util.run_v2_only\n@@ -522,6 +523,9 @@ def testGPUEqualsCPU(self, dtype):\n   @parameterized.parameters(FLOATS + INTS)\n   @test_util.run_v2_only\n   def testUniformIsInRange(self, dtype):\n+    if dtype == dtypes.bfloat16 and not test_util.is_gpu_available(\n+          cuda_only=True, min_cuda_compute_capability=(8, 0)):\n+      self.skipTest(""Bfloat16 requires compute capability 8.0"")\n     minval = 2\n     maxval = 33\n     size = 1000\n@@ -534,6 +538,9 @@ def testUniformIsInRange(self, dtype):\n   @parameterized.parameters(FLOATS)\n   @test_util.run_v2_only\n   def testNormalIsFinite(self, dtype):\n+    if dtype == dtypes.bfloat16 and not test_util.is_gpu_available(\n+          cuda_only=True, min_cuda_compute_capability=(8, 0)):\n+      self.skipTest(""Bfloat16 requires compute capability 8.0"")\n     gen = random.Generator.from_seed(1234)\n     x = gen.normal(shape=[10000], dtype=dtype).numpy()\n     self.assertTrue(np.all(np.isfinite(x)))\n@@ -542,8 +549,11 @@ def testNormalIsFinite(self, dtype):\n   @test_util.run_v2_only\n   def testDistributionOfUniform(self, dtype):\n     """"""Use Pearson\'s Chi-squared test to test for uniformity.""""""\n+    if dtype == dtypes.bfloat16 and not test_util.is_gpu_available(\n+          cuda_only=True, min_cuda_compute_capability=(8, 0)):\n+      self.skipTest(""Bfloat16 requires compute capability 8.0"")\n     n = 1000\n-    seed = 12\n+    seed = 123\n     gen = random.Generator.from_seed(seed)\n     maxval = 1\n     if dtype.is_integer:\n@@ -563,6 +573,9 @@ def testDistributionOfUniform(self, dtype):\n   @test_util.run_v2_only\n   def testDistributionOfNormal(self, dtype):\n     """"""Use Anderson-Darling test to test distribution appears normal.""""""\n+    if dtype == dtypes.bfloat16 and not test_util.is_gpu_available(\n+          cuda_only=True, min_cuda_compute_capability=(8, 0)):\n+      self.skipTest(""Bfloat16 requires compute capability 8.0"")\n     n = 1000\n     gen = random.Generator.from_seed(1234)\n     x = gen.normal(shape=[n], dtype=dtype).numpy()\ndiff --git a/tensorflow/python/kernel_tests/random/stateless_random_ops_test.py b/tensorflow/python/kernel_tests/random/stateless_random_ops_test.py\nindex 27d39762fed7a..6bd4a5b9b0035 100644\n--- a/tensorflow/python/kernel_tests/random/stateless_random_ops_test.py\n+++ b/tensorflow/python/kernel_tests/random/stateless_random_ops_test.py\n@@ -105,7 +105,9 @@ def wrap(op, dtype, shape, shape_dtype, seed, **kwargs):\n     device_type = get_device().device_type\n     # Some dtypes are not supported on some devices\n     if (dtype == dtypes.float16 and device_type in (\'XLA_GPU\', \'XLA_CPU\') or\n-        dtype == dtypes.bfloat16 and device_type == \'GPU\'):\n+        dtype == dtypes.bfloat16 and device_type == \'GPU\' and \n+        not test_util.is_gpu_available(\n+            cuda_only=True, min_cuda_compute_capability=(8, 0))):\n       dtype = dtypes.float32\n     shape_ = (constant_op.constant(shape, dtype=shape_dtype)\n               if shape_dtype is not None else shape)\n'","['Unit tests for bf16 random ops on GPU', 'Fix pylint', 'Use function to get gpu float types', 'Fix decorators']",[],2022-10-22 00:12:16
58250,"r2.10 cherry-pick: c5b30379ba8 ""Fix cwise dimension overflow issue again.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/c5b30379ba87cbe774b08ac50c1f6d36df4ebb7c,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/cwise_ops_common.h b/tensorflow/core/kernels/cwise_ops_common.h\nindex cdeb62cbeddbc..9bdc107f9f580 100644\n--- a/tensorflow/core/kernels/cwise_ops_common.h\n+++ b/tensorflow/core/kernels/cwise_ops_common.h\n@@ -450,13 +450,15 @@ struct BinaryFunctor<CPUDevice, Functor, 2, false> {\n     Assign(d, out, in.unaryExpr(Unary(scalar.data())));\n   }\n \n-  inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {\n-    Eigen::IndexList<int, Eigen::type2index<1>> ret;\n+  inline Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> NByOne(\n+      Eigen::DenseIndex n) {\n+    Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> ret;\n     ret.set(0, n);\n     return ret;\n   }\n-  inline Eigen::IndexList<Eigen::type2index<1>, int> OneByM(int m) {\n-    Eigen::IndexList<Eigen::type2index<1>, int> ret;\n+  inline Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> OneByM(\n+      Eigen::DenseIndex m) {\n+    Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> ret;\n     ret.set(1, m);\n     return ret;\n   }\n@@ -487,10 +489,10 @@ struct BinaryFunctor<CPUDevice, Functor, 2, false> {\n       // use_broadcast_optimization<T> are compile-time constant, gcc\n       // does a decent job avoiding generating code when conditions\n       // are not met.\n-      const int a = in0.dimension(0);  // in0 is shape [a, b]\n-      const int b = in0.dimension(1);\n-      const int c = in1.dimension(0);  // in1 is shape [c, d]\n-      const int d = in1.dimension(1);\n+      const Eigen::DenseIndex a = in0.dimension(0);  // in0 is shape [a, b]\n+      const Eigen::DenseIndex b = in0.dimension(1);\n+      const Eigen::DenseIndex c = in1.dimension(0);  // in1 is shape [c, d]\n+      const Eigen::DenseIndex d = in1.dimension(1);\n       if ((a == 1) && (d == 1)) {\n         auto lhs = in0.reshape(OneByM(b)).broadcast(NByOne(c));\n         auto rhs = in1.reshape(NByOne(c)).broadcast(OneByM(b));\n'","['Fix cwise dimension overflow issue again.\n\nIf resulting dimensions overflow an int32, we were seeing an overflow and\ncrash due to size mismatch during broadcast assignment.  The cause is a simple\ndimension type mismatch.\n\nNote that actual tests for this are currently impractical, since successful\noperations require more than 2^32 elements and OOM on most machines.\n\nPiperOrigin-RevId: 479336566']",[],2022-10-21 22:40:54
58249,"r2.9 cherry-pick: c5b30379ba8 ""Fix cwise dimension overflow issue again.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/c5b30379ba87cbe774b08ac50c1f6d36df4ebb7c,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/cwise_ops_common.h b/tensorflow/core/kernels/cwise_ops_common.h\nindex cdeb62cbeddbc..9bdc107f9f580 100644\n--- a/tensorflow/core/kernels/cwise_ops_common.h\n+++ b/tensorflow/core/kernels/cwise_ops_common.h\n@@ -450,13 +450,15 @@ struct BinaryFunctor<CPUDevice, Functor, 2, false> {\n     Assign(d, out, in.unaryExpr(Unary(scalar.data())));\n   }\n \n-  inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {\n-    Eigen::IndexList<int, Eigen::type2index<1>> ret;\n+  inline Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> NByOne(\n+      Eigen::DenseIndex n) {\n+    Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> ret;\n     ret.set(0, n);\n     return ret;\n   }\n-  inline Eigen::IndexList<Eigen::type2index<1>, int> OneByM(int m) {\n-    Eigen::IndexList<Eigen::type2index<1>, int> ret;\n+  inline Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> OneByM(\n+      Eigen::DenseIndex m) {\n+    Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> ret;\n     ret.set(1, m);\n     return ret;\n   }\n@@ -487,10 +489,10 @@ struct BinaryFunctor<CPUDevice, Functor, 2, false> {\n       // use_broadcast_optimization<T> are compile-time constant, gcc\n       // does a decent job avoiding generating code when conditions\n       // are not met.\n-      const int a = in0.dimension(0);  // in0 is shape [a, b]\n-      const int b = in0.dimension(1);\n-      const int c = in1.dimension(0);  // in1 is shape [c, d]\n-      const int d = in1.dimension(1);\n+      const Eigen::DenseIndex a = in0.dimension(0);  // in0 is shape [a, b]\n+      const Eigen::DenseIndex b = in0.dimension(1);\n+      const Eigen::DenseIndex c = in1.dimension(0);  // in1 is shape [c, d]\n+      const Eigen::DenseIndex d = in1.dimension(1);\n       if ((a == 1) && (d == 1)) {\n         auto lhs = in0.reshape(OneByM(b)).broadcast(NByOne(c));\n         auto rhs = in1.reshape(NByOne(c)).broadcast(OneByM(b));\n'","['Fix cwise dimension overflow issue again.\n\nIf resulting dimensions overflow an int32, we were seeing an overflow and\ncrash due to size mismatch during broadcast assignment.  The cause is a simple\ndimension type mismatch.\n\nNote that actual tests for this are currently impractical, since successful\noperations require more than 2^32 elements and OOM on most machines.\n\nPiperOrigin-RevId: 479336566']",[],2022-10-21 22:38:55
58245,"r2.8 cherry-pick: d71090c3e5c ""Fix security vulnerability with FractionalMaxPoolGrad""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/d71090c3e5ca325bdf4b02eb236cfb3ee823e927,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/fractional_max_pool_op.cc b/tensorflow/core/kernels/fractional_max_pool_op.cc\nindex 375786615ebe6..3ea45277bb5a4 100644\n--- a/tensorflow/core/kernels/fractional_max_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_max_pool_op.cc\n@@ -258,6 +258,18 @@ class FractionalMaxPoolGradOp : public OpKernel {\n     OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                 errors::InvalidArgument(""orig_output must not be empty, got "",\n                                         tensor_out.DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        height_seq_tensor.NumElements() * width_seq_tensor.NumElements() <=\n+            tensor_in.NumElements(),\n+        errors::InvalidArgument(\n+            ""Pooling region has more elements than the input tensor. ""\n+            ""row_pooling_sequence: "",\n+            height_seq_tensor.DebugString(),\n+            ""col_pooling_sequence: "", width_seq_tensor.DebugString(),\n+            ""orig_input: "", tensor_in.DebugString()));\n+\n+    //\n     std::vector<int64_t> input_size(tensor_in_and_out_dims);\n     std::vector<int64_t> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\nindex 1594844ab49e7..79b2c799d58e3 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n@@ -632,7 +632,7 @@ def testWhenRepeatedMaxValueInPoolingRegion(self):\n \n   def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n     with self.assertRaises(errors.InvalidArgumentError):\n-      with self.cached_session() as _:\n+      with self.cached_session():\n         overlapping = True\n         orig_input = constant_op.constant(\n             .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n@@ -653,6 +653,24 @@ def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n             overlapping=overlapping)\n         self.evaluate(t)\n \n+  def testOverLargeSeqRaiseErrorForFractionalMaxPoolGrad(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with self.cached_session():\n+        overlapping = False\n+        orig_input = [[[[1, 1, 1, 1, 1]]]]\n+        orig_output = [[[[1, 1, 1]]]]\n+        out_backprop = [[[[3], [3], [6]]]]\n+        row_pooling_sequence = [-0x4000000, 1, 1]\n+        col_pooling_sequence = [-0x4000000, 1, 1]\n+        t = gen_nn_ops.FractionalMaxPoolGrad(\n+            orig_input=orig_input,\n+            orig_output=orig_output,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == ""__main__"":\n   test.main()\n'",['Fix security vulnerability with FractionalMaxPoolGrad\n\nPiperOrigin-RevId: 477500477'],[],2022-10-21 18:33:53
58244,"r2.10 cherry-pick: d71090c3e5c ""Fix security vulnerability with FractionalMaxPoolGrad""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/d71090c3e5ca325bdf4b02eb236cfb3ee823e927,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/fractional_max_pool_op.cc b/tensorflow/core/kernels/fractional_max_pool_op.cc\nindex 375786615ebe6..3ea45277bb5a4 100644\n--- a/tensorflow/core/kernels/fractional_max_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_max_pool_op.cc\n@@ -258,6 +258,18 @@ class FractionalMaxPoolGradOp : public OpKernel {\n     OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                 errors::InvalidArgument(""orig_output must not be empty, got "",\n                                         tensor_out.DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        height_seq_tensor.NumElements() * width_seq_tensor.NumElements() <=\n+            tensor_in.NumElements(),\n+        errors::InvalidArgument(\n+            ""Pooling region has more elements than the input tensor. ""\n+            ""row_pooling_sequence: "",\n+            height_seq_tensor.DebugString(),\n+            ""col_pooling_sequence: "", width_seq_tensor.DebugString(),\n+            ""orig_input: "", tensor_in.DebugString()));\n+\n+    //\n     std::vector<int64_t> input_size(tensor_in_and_out_dims);\n     std::vector<int64_t> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\nindex 1594844ab49e7..79b2c799d58e3 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n@@ -632,7 +632,7 @@ def testWhenRepeatedMaxValueInPoolingRegion(self):\n \n   def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n     with self.assertRaises(errors.InvalidArgumentError):\n-      with self.cached_session() as _:\n+      with self.cached_session():\n         overlapping = True\n         orig_input = constant_op.constant(\n             .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n@@ -653,6 +653,24 @@ def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n             overlapping=overlapping)\n         self.evaluate(t)\n \n+  def testOverLargeSeqRaiseErrorForFractionalMaxPoolGrad(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with self.cached_session():\n+        overlapping = False\n+        orig_input = [[[[1, 1, 1, 1, 1]]]]\n+        orig_output = [[[[1, 1, 1]]]]\n+        out_backprop = [[[[3], [3], [6]]]]\n+        row_pooling_sequence = [-0x4000000, 1, 1]\n+        col_pooling_sequence = [-0x4000000, 1, 1]\n+        t = gen_nn_ops.FractionalMaxPoolGrad(\n+            orig_input=orig_input,\n+            orig_output=orig_output,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == ""__main__"":\n   test.main()\n'",['Fix security vulnerability with FractionalMaxPoolGrad\n\nPiperOrigin-RevId: 477500477'],[],2022-10-21 18:33:19
58243,"r2.10 cherry-pick: 660ce5a89eb ""[Security] Add a check for empty variant tensor input to CompositeTensorVariantToComponents.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/660ce5a89eb6766834bdc303d2ab3902aef99d3d,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/composite_tensor_ops.cc b/tensorflow/core/kernels/composite_tensor_ops.cc\nindex f41b02991bba4..bc4f96e6bb2fe 100644\n--- a/tensorflow/core/kernels/composite_tensor_ops.cc\n+++ b/tensorflow/core/kernels/composite_tensor_ops.cc\n@@ -15,6 +15,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/op.h""\n #include ""tensorflow/core/framework/op_kernel.h""\n+#include ""tensorflow/core/framework/op_requires.h""\n #include ""tensorflow/core/framework/variant.h""\n #include ""tensorflow/core/framework/variant_encode_decode.h""\n #include ""tensorflow/core/kernels/composite_tensor_variant.h""\n@@ -66,6 +67,11 @@ class CompositeTensorVariantToComponents : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     Tensor encoded_t = context->input(0);\n+    OP_REQUIRES(\n+        context, encoded_t.flat<Variant>().size() > 0,\n+        errors::InvalidArgument(""Input `encoded` must not be an empty variant ""\n+                                ""tensor, but got "",\n+                                encoded_t.DebugString()));\n     auto* encoded = encoded_t.flat<Variant>()(0).get<CompositeTensorVariant>();\n \n     // Check that the encoded TypeSpec is compatible with the expected TypeSpec.\ndiff --git a/tensorflow/python/kernel_tests/composite_tensor_ops_test.py b/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\nindex e5e9d1ef9bf6d..7a10cae3ebc10 100644\n--- a/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\n+++ b/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\n@@ -18,11 +18,13 @@\n \n from tensorflow.python.eager import backprop\n from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import sparse_tensor\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import composite_tensor_ops\n+from tensorflow.python.ops import gen_composite_tensor_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import parsing_ops\n@@ -83,6 +85,18 @@ def testEncodingErrors(self, value, spec, message):\n     with self.assertRaisesRegex(ValueError, message):\n       composite_tensor_ops.composite_tensor_to_variants(value(), spec)\n \n+  def testDecodingEmptyNonScalarTensorError(self):\n+    if not context.executing_eagerly():\n+      # Creating a variant tensor of an empty list is not allowed in eager mode.\n+      return\n+\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \'must not be an empty variant tensor\'):\n+      gen_composite_tensor_ops.CompositeTensorVariantToComponents(\n+          encoded=constant_op.constant([], dtype=dtypes.variant),\n+          metadata=\'\',\n+          Tcomponents=[dtypes.int32])\n+\n   def testRoundTripThroughTensorProto(self):\n     value = ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])\n     encoded = composite_tensor_ops.composite_tensor_to_variants(value)\n'",['[Security] Add a check for empty variant tensor input to CompositeTensorVariantToComponents.\n\nSo an exception will be raised instead of segfault.\n\nPiperOrigin-RevId: 474397914'],[],2022-10-21 18:31:24
58242,"r2.9 cherry-pick: d66e1d56827 ""Fix tensor shape overflow in FusedResizeAndPadConv2D.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/d66e1d568275e6a2947de97dca7a102a211e01ce,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/conv_ops_fused_image_transform.cc b/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\nindex 2d8feb313a30f..dc5fd97103cc3 100644\n--- a/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\n+++ b/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\n@@ -667,8 +667,11 @@ class FusedResizeConv2DUsingGemmOp : public OpKernel {\n       st.height_scale = 1.0f;\n       st.width_scale = 1.0f;\n     }\n-    TensorShape resized_shape(\n-        {input.dim_size(0), st.out_height, st.out_width, input.dim_size(3)});\n+    TensorShape resized_shape;\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(\n+                                {input.dim_size(0), st.out_height, st.out_width,\n+                                 input.dim_size(3)},\n+                                &resized_shape));\n     int paddings_index;\n     int filter_index;\n     if (DoResize) {\ndiff --git a/tensorflow/core/ops/nn_ops.cc b/tensorflow/core/ops/nn_ops.cc\nindex e117fc0f41e96..ee62330d158de 100644\n--- a/tensorflow/core/ops/nn_ops.cc\n+++ b/tensorflow/core/ops/nn_ops.cc\n@@ -574,7 +574,7 @@ REGISTER_OP(""FusedResizeAndPadConv2D"")\n     .Attr(""strides: list(int)"")\n     .Attr(GetPaddingAttrString())\n     .SetShapeFn([](InferenceContext* c) {\n-      return CommonFusedConvCalculations(c, true /* has_resize */);\n+      return CommonFusedConvCalculations(c, /*has_resize=*/true);\n     });\n \n REGISTER_OP(""FusedPadConv2D"")\n@@ -587,7 +587,7 @@ REGISTER_OP(""FusedPadConv2D"")\n     .Attr(""strides: list(int)"")\n     .Attr(GetPaddingAttrString())\n     .SetShapeFn([](InferenceContext* c) {\n-      return CommonFusedConvCalculations(c, false /* has_resize */);\n+      return CommonFusedConvCalculations(c, /*has_resize=*/false);\n     });\n \n // --------------------------------------------------------------------------\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py b/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\nindex 2392944fc4170..265d146279349 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\n@@ -3431,6 +3431,33 @@ def testAddWithSameSrcAndAddTensorBuffer(self):\n         np.rint(expected_output),\n         self.evaluate(add).reshape(-1))\n \n+  # Fused resize and pad conv.\n+  @test_util.run_in_graph_and_eager_modes()\n+  def testResizeAndPadLargeResize(self):\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                ""Encountered overflow""):\n+      mode = ""REFLECT""\n+      strides = [1, 1, 1, 1]\n+      padding = ""SAME""\n+      resize_align_corners = False\n+      tensor = constant_op.constant(\n+          147, shape=[3, 3, 1, 4], dtype=dtypes.float32)\n+      size = constant_op.constant([1879048192, 1879048192], dtype=dtypes.int32)\n+      paddings = constant_op.constant([[0, 0], [0, 0], [0, 0], [0, 0]],\n+                                      dtype=dtypes.int32)\n+      kernel = constant_op.constant(\n+          123, shape=[1, 3, 4, 1], dtype=dtypes.float32)\n+      self.evaluate(\n+          gen_nn_ops.fused_resize_and_pad_conv2d(\n+              input=tensor,\n+              size=size,\n+              paddings=paddings,\n+              filter=kernel,\n+              mode=mode,\n+              strides=strides,\n+              padding=padding,\n+              resize_align_corners=resize_align_corners))\n+\n \n if __name__ == ""__main__"":\n   for index, (input_size_, filter_size_, output_size_, stride_,\n'",['Fix tensor shape overflow in FusedResizeAndPadConv2D.\n\nReplaced TensorShape constructor by Factory method with status.\n\nPiperOrigin-RevId: 477742686'],[],2022-10-21 18:29:01
58241,"r2.10 cherry-pick: d66e1d56827 ""Fix tensor shape overflow in FusedResizeAndPadConv2D.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/d66e1d568275e6a2947de97dca7a102a211e01ce,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/conv_ops_fused_image_transform.cc b/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\nindex ac76cef5bb8c8..dd2db39fbd127 100644\n--- a/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\n+++ b/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\n@@ -667,8 +667,11 @@ class FusedResizeConv2DUsingGemmOp : public OpKernel {\n       st.height_scale = 1.0f;\n       st.width_scale = 1.0f;\n     }\n-    TensorShape resized_shape(\n-        {input.dim_size(0), st.out_height, st.out_width, input.dim_size(3)});\n+    TensorShape resized_shape;\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(\n+                                {input.dim_size(0), st.out_height, st.out_width,\n+                                 input.dim_size(3)},\n+                                &resized_shape));\n     int paddings_index;\n     int filter_index;\n     if (DoResize) {\ndiff --git a/tensorflow/core/ops/nn_ops.cc b/tensorflow/core/ops/nn_ops.cc\nindex fb1c7bb7d3676..61734bb9abd40 100644\n--- a/tensorflow/core/ops/nn_ops.cc\n+++ b/tensorflow/core/ops/nn_ops.cc\n@@ -577,7 +577,7 @@ REGISTER_OP(""FusedResizeAndPadConv2D"")\n     .Attr(""strides: list(int)"")\n     .Attr(GetPaddingAttrString())\n     .SetShapeFn([](InferenceContext* c) {\n-      return CommonFusedConvCalculations(c, true /* has_resize */);\n+      return CommonFusedConvCalculations(c, /*has_resize=*/true);\n     });\n \n REGISTER_OP(""FusedPadConv2D"")\n@@ -590,7 +590,7 @@ REGISTER_OP(""FusedPadConv2D"")\n     .Attr(""strides: list(int)"")\n     .Attr(GetPaddingAttrString())\n     .SetShapeFn([](InferenceContext* c) {\n-      return CommonFusedConvCalculations(c, false /* has_resize */);\n+      return CommonFusedConvCalculations(c, /*has_resize=*/false);\n     });\n \n // --------------------------------------------------------------------------\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py b/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\nindex 2392944fc4170..265d146279349 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\n@@ -3431,6 +3431,33 @@ def testAddWithSameSrcAndAddTensorBuffer(self):\n         np.rint(expected_output),\n         self.evaluate(add).reshape(-1))\n \n+  # Fused resize and pad conv.\n+  @test_util.run_in_graph_and_eager_modes()\n+  def testResizeAndPadLargeResize(self):\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                ""Encountered overflow""):\n+      mode = ""REFLECT""\n+      strides = [1, 1, 1, 1]\n+      padding = ""SAME""\n+      resize_align_corners = False\n+      tensor = constant_op.constant(\n+          147, shape=[3, 3, 1, 4], dtype=dtypes.float32)\n+      size = constant_op.constant([1879048192, 1879048192], dtype=dtypes.int32)\n+      paddings = constant_op.constant([[0, 0], [0, 0], [0, 0], [0, 0]],\n+                                      dtype=dtypes.int32)\n+      kernel = constant_op.constant(\n+          123, shape=[1, 3, 4, 1], dtype=dtypes.float32)\n+      self.evaluate(\n+          gen_nn_ops.fused_resize_and_pad_conv2d(\n+              input=tensor,\n+              size=size,\n+              paddings=paddings,\n+              filter=kernel,\n+              mode=mode,\n+              strides=strides,\n+              padding=padding,\n+              resize_align_corners=resize_align_corners))\n+\n \n if __name__ == ""__main__"":\n   for index, (input_size_, filter_size_, output_size_, stride_,\n'",['Fix tensor shape overflow in FusedResizeAndPadConv2D.\n\nReplaced TensorShape constructor by Factory method with status.\n\nPiperOrigin-RevId: 477742686'],[],2022-10-21 18:28:47
58240,"r2.8 cherry-pick: d66e1d56827 ""Fix tensor shape overflow in FusedResizeAndPadConv2D.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/d66e1d568275e6a2947de97dca7a102a211e01ce,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/conv_ops_fused_image_transform.cc b/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\nindex 2d8feb313a30f..dc5fd97103cc3 100644\n--- a/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\n+++ b/tensorflow/core/kernels/conv_ops_fused_image_transform.cc\n@@ -667,8 +667,11 @@ class FusedResizeConv2DUsingGemmOp : public OpKernel {\n       st.height_scale = 1.0f;\n       st.width_scale = 1.0f;\n     }\n-    TensorShape resized_shape(\n-        {input.dim_size(0), st.out_height, st.out_width, input.dim_size(3)});\n+    TensorShape resized_shape;\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(\n+                                {input.dim_size(0), st.out_height, st.out_width,\n+                                 input.dim_size(3)},\n+                                &resized_shape));\n     int paddings_index;\n     int filter_index;\n     if (DoResize) {\ndiff --git a/tensorflow/core/ops/nn_ops.cc b/tensorflow/core/ops/nn_ops.cc\nindex 5041fd80750ff..2f8cf05d4d728 100644\n--- a/tensorflow/core/ops/nn_ops.cc\n+++ b/tensorflow/core/ops/nn_ops.cc\n@@ -574,7 +574,7 @@ REGISTER_OP(""FusedResizeAndPadConv2D"")\n     .Attr(""strides: list(int)"")\n     .Attr(GetPaddingAttrString())\n     .SetShapeFn([](InferenceContext* c) {\n-      return CommonFusedConvCalculations(c, true /* has_resize */);\n+      return CommonFusedConvCalculations(c, /*has_resize=*/true);\n     });\n \n REGISTER_OP(""FusedPadConv2D"")\n@@ -587,7 +587,7 @@ REGISTER_OP(""FusedPadConv2D"")\n     .Attr(""strides: list(int)"")\n     .Attr(GetPaddingAttrString())\n     .SetShapeFn([](InferenceContext* c) {\n-      return CommonFusedConvCalculations(c, false /* has_resize */);\n+      return CommonFusedConvCalculations(c, /*has_resize=*/false);\n     });\n \n // --------------------------------------------------------------------------\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py b/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\nindex 2392944fc4170..265d146279349 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py\n@@ -3431,6 +3431,33 @@ def testAddWithSameSrcAndAddTensorBuffer(self):\n         np.rint(expected_output),\n         self.evaluate(add).reshape(-1))\n \n+  # Fused resize and pad conv.\n+  @test_util.run_in_graph_and_eager_modes()\n+  def testResizeAndPadLargeResize(self):\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                ""Encountered overflow""):\n+      mode = ""REFLECT""\n+      strides = [1, 1, 1, 1]\n+      padding = ""SAME""\n+      resize_align_corners = False\n+      tensor = constant_op.constant(\n+          147, shape=[3, 3, 1, 4], dtype=dtypes.float32)\n+      size = constant_op.constant([1879048192, 1879048192], dtype=dtypes.int32)\n+      paddings = constant_op.constant([[0, 0], [0, 0], [0, 0], [0, 0]],\n+                                      dtype=dtypes.int32)\n+      kernel = constant_op.constant(\n+          123, shape=[1, 3, 4, 1], dtype=dtypes.float32)\n+      self.evaluate(\n+          gen_nn_ops.fused_resize_and_pad_conv2d(\n+              input=tensor,\n+              size=size,\n+              paddings=paddings,\n+              filter=kernel,\n+              mode=mode,\n+              strides=strides,\n+              padding=padding,\n+              resize_align_corners=resize_align_corners))\n+\n \n if __name__ == ""__main__"":\n   for index, (input_size_, filter_size_, output_size_, stride_,\n'",['Fix tensor shape overflow in FusedResizeAndPadConv2D.\n\nReplaced TensorShape constructor by Factory method with status.\n\nPiperOrigin-RevId: 477742686'],[],2022-10-21 18:28:34
58239,"r2.9 cherry-pick: 660ce5a89eb ""[Security] Add a check for empty variant tensor input to CompositeTensorVariantToComponents.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/660ce5a89eb6766834bdc303d2ab3902aef99d3d,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/composite_tensor_ops.cc b/tensorflow/core/kernels/composite_tensor_ops.cc\nindex f41b02991bba4..bc4f96e6bb2fe 100644\n--- a/tensorflow/core/kernels/composite_tensor_ops.cc\n+++ b/tensorflow/core/kernels/composite_tensor_ops.cc\n@@ -15,6 +15,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/op.h""\n #include ""tensorflow/core/framework/op_kernel.h""\n+#include ""tensorflow/core/framework/op_requires.h""\n #include ""tensorflow/core/framework/variant.h""\n #include ""tensorflow/core/framework/variant_encode_decode.h""\n #include ""tensorflow/core/kernels/composite_tensor_variant.h""\n@@ -66,6 +67,11 @@ class CompositeTensorVariantToComponents : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     Tensor encoded_t = context->input(0);\n+    OP_REQUIRES(\n+        context, encoded_t.flat<Variant>().size() > 0,\n+        errors::InvalidArgument(""Input `encoded` must not be an empty variant ""\n+                                ""tensor, but got "",\n+                                encoded_t.DebugString()));\n     auto* encoded = encoded_t.flat<Variant>()(0).get<CompositeTensorVariant>();\n \n     // Check that the encoded TypeSpec is compatible with the expected TypeSpec.\ndiff --git a/tensorflow/python/kernel_tests/composite_tensor_ops_test.py b/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\nindex e5e9d1ef9bf6d..7a10cae3ebc10 100644\n--- a/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\n+++ b/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\n@@ -18,11 +18,13 @@\n \n from tensorflow.python.eager import backprop\n from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import sparse_tensor\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import composite_tensor_ops\n+from tensorflow.python.ops import gen_composite_tensor_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import parsing_ops\n@@ -83,6 +85,18 @@ def testEncodingErrors(self, value, spec, message):\n     with self.assertRaisesRegex(ValueError, message):\n       composite_tensor_ops.composite_tensor_to_variants(value(), spec)\n \n+  def testDecodingEmptyNonScalarTensorError(self):\n+    if not context.executing_eagerly():\n+      # Creating a variant tensor of an empty list is not allowed in eager mode.\n+      return\n+\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \'must not be an empty variant tensor\'):\n+      gen_composite_tensor_ops.CompositeTensorVariantToComponents(\n+          encoded=constant_op.constant([], dtype=dtypes.variant),\n+          metadata=\'\',\n+          Tcomponents=[dtypes.int32])\n+\n   def testRoundTripThroughTensorProto(self):\n     value = ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])\n     encoded = composite_tensor_ops.composite_tensor_to_variants(value)\n'",['[Security] Add a check for empty variant tensor input to CompositeTensorVariantToComponents.\n\nSo an exception will be raised instead of segfault.\n\nPiperOrigin-RevId: 474397914'],[],2022-10-21 18:28:23
58238,"r2.8 cherry-pick: 660ce5a89eb ""[Security] Add a check for empty variant tensor input to CompositeTensorVariantToComponents.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/660ce5a89eb6766834bdc303d2ab3902aef99d3d,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/composite_tensor_ops.cc b/tensorflow/core/kernels/composite_tensor_ops.cc\nindex f41b02991bba4..bc4f96e6bb2fe 100644\n--- a/tensorflow/core/kernels/composite_tensor_ops.cc\n+++ b/tensorflow/core/kernels/composite_tensor_ops.cc\n@@ -15,6 +15,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/op.h""\n #include ""tensorflow/core/framework/op_kernel.h""\n+#include ""tensorflow/core/framework/op_requires.h""\n #include ""tensorflow/core/framework/variant.h""\n #include ""tensorflow/core/framework/variant_encode_decode.h""\n #include ""tensorflow/core/kernels/composite_tensor_variant.h""\n@@ -66,6 +67,11 @@ class CompositeTensorVariantToComponents : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     Tensor encoded_t = context->input(0);\n+    OP_REQUIRES(\n+        context, encoded_t.flat<Variant>().size() > 0,\n+        errors::InvalidArgument(""Input `encoded` must not be an empty variant ""\n+                                ""tensor, but got "",\n+                                encoded_t.DebugString()));\n     auto* encoded = encoded_t.flat<Variant>()(0).get<CompositeTensorVariant>();\n \n     // Check that the encoded TypeSpec is compatible with the expected TypeSpec.\ndiff --git a/tensorflow/python/kernel_tests/composite_tensor_ops_test.py b/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\nindex e5e9d1ef9bf6d..7a10cae3ebc10 100644\n--- a/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\n+++ b/tensorflow/python/kernel_tests/composite_tensor_ops_test.py\n@@ -18,11 +18,13 @@\n \n from tensorflow.python.eager import backprop\n from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import sparse_tensor\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import composite_tensor_ops\n+from tensorflow.python.ops import gen_composite_tensor_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import parsing_ops\n@@ -83,6 +85,18 @@ def testEncodingErrors(self, value, spec, message):\n     with self.assertRaisesRegex(ValueError, message):\n       composite_tensor_ops.composite_tensor_to_variants(value(), spec)\n \n+  def testDecodingEmptyNonScalarTensorError(self):\n+    if not context.executing_eagerly():\n+      # Creating a variant tensor of an empty list is not allowed in eager mode.\n+      return\n+\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \'must not be an empty variant tensor\'):\n+      gen_composite_tensor_ops.CompositeTensorVariantToComponents(\n+          encoded=constant_op.constant([], dtype=dtypes.variant),\n+          metadata=\'\',\n+          Tcomponents=[dtypes.int32])\n+\n   def testRoundTripThroughTensorProto(self):\n     value = ragged_factory_ops.constant([[1, 2], [3], [4, 5, 6]])\n     encoded = composite_tensor_ops.composite_tensor_to_variants(value)\n'",['[Security] Add a check for empty variant tensor input to CompositeTensorVariantToComponents.\n\nSo an exception will be raised instead of segfault.\n\nPiperOrigin-RevId: 474397914'],[],2022-10-21 18:27:51
58237,"r2.9 cherry-pick: d71090c3e5c ""Fix security vulnerability with FractionalMaxPoolGrad""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/d71090c3e5ca325bdf4b02eb236cfb3ee823e927,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/fractional_max_pool_op.cc b/tensorflow/core/kernels/fractional_max_pool_op.cc\nindex 375786615ebe6..3ea45277bb5a4 100644\n--- a/tensorflow/core/kernels/fractional_max_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_max_pool_op.cc\n@@ -258,6 +258,18 @@ class FractionalMaxPoolGradOp : public OpKernel {\n     OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                 errors::InvalidArgument(""orig_output must not be empty, got "",\n                                         tensor_out.DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        height_seq_tensor.NumElements() * width_seq_tensor.NumElements() <=\n+            tensor_in.NumElements(),\n+        errors::InvalidArgument(\n+            ""Pooling region has more elements than the input tensor. ""\n+            ""row_pooling_sequence: "",\n+            height_seq_tensor.DebugString(),\n+            ""col_pooling_sequence: "", width_seq_tensor.DebugString(),\n+            ""orig_input: "", tensor_in.DebugString()));\n+\n+    //\n     std::vector<int64_t> input_size(tensor_in_and_out_dims);\n     std::vector<int64_t> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\nindex 1594844ab49e7..79b2c799d58e3 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n@@ -632,7 +632,7 @@ def testWhenRepeatedMaxValueInPoolingRegion(self):\n \n   def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n     with self.assertRaises(errors.InvalidArgumentError):\n-      with self.cached_session() as _:\n+      with self.cached_session():\n         overlapping = True\n         orig_input = constant_op.constant(\n             .453409232, shape=[1, 7, 13, 1], dtype=dtypes.float32)\n@@ -653,6 +653,24 @@ def testInvalidSeqRaiseErrorForFractionalMaxPoolGrad(self):\n             overlapping=overlapping)\n         self.evaluate(t)\n \n+  def testOverLargeSeqRaiseErrorForFractionalMaxPoolGrad(self):\n+    with self.assertRaises(errors.InvalidArgumentError):\n+      with self.cached_session():\n+        overlapping = False\n+        orig_input = [[[[1, 1, 1, 1, 1]]]]\n+        orig_output = [[[[1, 1, 1]]]]\n+        out_backprop = [[[[3], [3], [6]]]]\n+        row_pooling_sequence = [-0x4000000, 1, 1]\n+        col_pooling_sequence = [-0x4000000, 1, 1]\n+        t = gen_nn_ops.FractionalMaxPoolGrad(\n+            orig_input=orig_input,\n+            orig_output=orig_output,\n+            out_backprop=out_backprop,\n+            row_pooling_sequence=row_pooling_sequence,\n+            col_pooling_sequence=col_pooling_sequence,\n+            overlapping=overlapping)\n+        self.evaluate(t)\n+\n \n if __name__ == ""__main__"":\n   test.main()\n'",['Fix security vulnerability with FractionalMaxPoolGrad\n\nPiperOrigin-RevId: 477500477'],[],2022-10-21 18:26:27
58236,"r2.10 cherry-pick: 80ff197d03d ""Fix SDCA optimizer crash.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/80ff197d03db2a70c6a111f97dcdacad1b0babfa,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/sdca_internal.cc b/tensorflow/core/kernels/sdca_internal.cc\nindex 5572cb934e40c..79dc01baa4a03 100644\n--- a/tensorflow/core/kernels/sdca_internal.cc\n+++ b/tensorflow/core/kernels/sdca_internal.cc\n@@ -389,6 +389,13 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(""dense_features"", &dense_features_inputs));\n+  for (int i = 0; i < dense_features_inputs.size(); ++i) {\n+    if (!TensorShapeUtils::IsMatrix(dense_features_inputs[i].shape())) {\n+      return errors::InvalidArgument(""Dense features at index "", i,\n+                                     "" must be rank 2 but is rank "",\n+                                     dense_features_inputs[i].dims());\n+    }\n+  }\n \n   examples_.clear();\n   examples_.resize(num_examples);\ndiff --git a/tensorflow/core/kernels/sdca_ops.cc b/tensorflow/core/kernels/sdca_ops.cc\nindex 98b4fd1c82b23..d279eda86e741 100644\n--- a/tensorflow/core/kernels/sdca_ops.cc\n+++ b/tensorflow/core/kernels/sdca_ops.cc\n@@ -49,6 +49,7 @@ limitations under the License.\n #include ""tensorflow/core/lib/core/status.h""\n #include ""tensorflow/core/lib/core/stringpiece.h""\n #include ""tensorflow/core/lib/gtl/inlined_vector.h""\n+#include ""tensorflow/core/platform/errors.h""\n #include ""tensorflow/core/platform/fingerprint.h""\n #include ""tensorflow/core/platform/macros.h""\n #include ""tensorflow/core/platform/mutex.h""\n@@ -142,6 +143,10 @@ void DoCompute(const ComputeOptions& options, OpKernelContext* const context) {\n   const Tensor* example_state_data_t;\n   OP_REQUIRES_OK(context,\n                  context->input(""example_state_data"", &example_state_data_t));\n+  OP_REQUIRES(\n+      context, TensorShapeUtils::IsMatrix(example_state_data_t->shape()),\n+      errors::InvalidArgument(""example_state_data must be rank 2 but is rank "",\n+                              example_state_data_t->dims()));\n   TensorShape expected_example_state_shape({examples.num_examples(), 4});\n   OP_REQUIRES(context,\n               example_state_data_t->shape() == expected_example_state_shape,\n'","[""Fix SDCA optimizer crash.\n\nValidates size of the dense_features and example state_data_inputs.\nOther validation already verifies that sizes are otherwise consistent.\n\nThis looks to be a v1-only op that isn't used internally at all outside\nof `contrib`, and no tests.\n\nPiperOrigin-RevId: 478073762""]",[],2022-10-21 18:26:05
58235,"r2.8 cherry-pick: 80ff197d03d ""Fix SDCA optimizer crash.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/80ff197d03db2a70c6a111f97dcdacad1b0babfa,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/sdca_internal.cc b/tensorflow/core/kernels/sdca_internal.cc\nindex 58d83f6936a8a..b2a9bc630af6e 100644\n--- a/tensorflow/core/kernels/sdca_internal.cc\n+++ b/tensorflow/core/kernels/sdca_internal.cc\n@@ -389,6 +389,13 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(""dense_features"", &dense_features_inputs));\n+  for (int i = 0; i < dense_features_inputs.size(); ++i) {\n+    if (!TensorShapeUtils::IsMatrix(dense_features_inputs[i].shape())) {\n+      return errors::InvalidArgument(""Dense features at index "", i,\n+                                     "" must be rank 2 but is rank "",\n+                                     dense_features_inputs[i].dims());\n+    }\n+  }\n \n   examples_.clear();\n   examples_.resize(num_examples);\ndiff --git a/tensorflow/core/kernels/sdca_ops.cc b/tensorflow/core/kernels/sdca_ops.cc\nindex 98b4fd1c82b23..d279eda86e741 100644\n--- a/tensorflow/core/kernels/sdca_ops.cc\n+++ b/tensorflow/core/kernels/sdca_ops.cc\n@@ -49,6 +49,7 @@ limitations under the License.\n #include ""tensorflow/core/lib/core/status.h""\n #include ""tensorflow/core/lib/core/stringpiece.h""\n #include ""tensorflow/core/lib/gtl/inlined_vector.h""\n+#include ""tensorflow/core/platform/errors.h""\n #include ""tensorflow/core/platform/fingerprint.h""\n #include ""tensorflow/core/platform/macros.h""\n #include ""tensorflow/core/platform/mutex.h""\n@@ -142,6 +143,10 @@ void DoCompute(const ComputeOptions& options, OpKernelContext* const context) {\n   const Tensor* example_state_data_t;\n   OP_REQUIRES_OK(context,\n                  context->input(""example_state_data"", &example_state_data_t));\n+  OP_REQUIRES(\n+      context, TensorShapeUtils::IsMatrix(example_state_data_t->shape()),\n+      errors::InvalidArgument(""example_state_data must be rank 2 but is rank "",\n+                              example_state_data_t->dims()));\n   TensorShape expected_example_state_shape({examples.num_examples(), 4});\n   OP_REQUIRES(context,\n               example_state_data_t->shape() == expected_example_state_shape,\n'","[""Fix SDCA optimizer crash.\n\nValidates size of the dense_features and example state_data_inputs.\nOther validation already verifies that sizes are otherwise consistent.\n\nThis looks to be a v1-only op that isn't used internally at all outside\nof `contrib`, and no tests.\n\nPiperOrigin-RevId: 478073762""]",[],2022-10-21 18:26:01
58234,"r2.10 cherry-pick: 39ec7eaf142 ""Make MfccMelFilterbank fail initialization if num_channels is > max int value.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/39ec7eaf1428e90c37787e5b3fbd68ebd3c48860,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/mfcc.cc b/tensorflow/core/kernels/mfcc.cc\nindex 8c755e0df8754..cb4416f7bd309 100644\n--- a/tensorflow/core/kernels/mfcc.cc\n+++ b/tensorflow/core/kernels/mfcc.cc\n@@ -38,8 +38,10 @@ bool Mfcc::Initialize(int input_length, double input_sample_rate) {\n   bool initialized = mel_filterbank_.Initialize(\n       input_length, input_sample_rate, filterbank_channel_count_,\n       lower_frequency_limit_, upper_frequency_limit_);\n-  initialized &=\n-      dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  if (initialized) {\n+    initialized =\n+        dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  }\n   initialized_ = initialized;\n   return initialized;\n }\ndiff --git a/tensorflow/core/kernels/mfcc_mel_filterbank.cc b/tensorflow/core/kernels/mfcc_mel_filterbank.cc\nindex 8eb2d9d8309f5..c5c2d29d37b99 100644\n--- a/tensorflow/core/kernels/mfcc_mel_filterbank.cc\n+++ b/tensorflow/core/kernels/mfcc_mel_filterbank.cc\n@@ -32,6 +32,8 @@ limitations under the License.\n \n #include <math.h>\n \n+#include <limits>\n+\n #include ""tensorflow/core/platform/logging.h""\n \n namespace tensorflow {\n@@ -74,7 +76,17 @@ bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,\n \n   // An extra center frequency is computed at the top to get the upper\n   // limit on the high side of the final triangular filter.\n-  center_frequencies_.resize(num_channels_ + 1);\n+  std::size_t center_frequencies_size = std::size_t(num_channels_) + 1;\n+  if (center_frequencies_size >= std::numeric_limits<int>::max() ||\n+      center_frequencies_size > center_frequencies_.max_size()) {\n+    LOG(ERROR) << ""Number of filterbank channels must be less than ""\n+               << std::numeric_limits<int>::max()\n+               << "" and less than or equal to ""\n+               << center_frequencies_.max_size();\n+    return false;\n+  }\n+  center_frequencies_.resize(center_frequencies_size);\n+\n   const double mel_low = FreqToMel(lower_frequency_limit);\n   const double mel_hi = FreqToMel(upper_frequency_limit);\n   const double mel_span = mel_hi - mel_low;\ndiff --git a/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc b/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\nindex 54f31e1699ef1..26b5afed13505 100644\n--- a/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\n+++ b/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\n@@ -15,6 +15,7 @@ limitations under the License.\n \n #include ""tensorflow/core/kernels/mfcc_mel_filterbank.h""\n \n+#include <limits>\n #include <vector>\n \n #include ""tensorflow/core/platform/test.h""\n@@ -85,4 +86,37 @@ TEST(MfccMelFilterbankTest, IgnoresExistingContentOfOutputVector) {\n   }\n }\n \n+TEST(MfccMelFilterbankTest, FailsWhenChannelsGreaterThanMaxIntValue) {\n+  // Test for bug where vector throws a length_error when it suspects the size\n+  // to be more than it\'s max_size. For now, we fail initialization when the\n+  // number of requested channels is >= the maximum value int can take (since\n+  // num_channels_ is an int).\n+  MfccMelFilterbank filterbank;\n+\n+  const int kSampleCount = 513;\n+  std::size_t num_channels = std::numeric_limits<int>::max();\n+  bool initialized = filterbank.Initialize(\n+      kSampleCount, 2 /* sample rate */, num_channels /* channels */,\n+      1.0 /*  lower frequency limit */, 5.0 /* upper frequency limit */);\n+\n+  EXPECT_FALSE(initialized);\n+}\n+\n+TEST(MfccMelFilterbankTest, FailsWhenChannelsGreaterThanMaxSize) {\n+  // Test for bug where vector throws a length_error when it suspects the size\n+  // to be more than it\'s max_size. For now, we fail initialization when the\n+  // number of requested channels is > than std::vector<double>::max_size().\n+  MfccMelFilterbank filterbank;\n+\n+  const int kSampleCount = 513;\n+  // Set num_channels to exceed the max_size a double vector can\n+  // theoretically take.\n+  std::size_t num_channels = std::vector<double>().max_size() + 1;\n+  bool initialized = filterbank.Initialize(\n+      kSampleCount, 2 /* sample rate */, num_channels /* channels */,\n+      1.0 /*  lower frequency limit */, 5.0 /* upper frequency limit */);\n+\n+  EXPECT_FALSE(initialized);\n+}\n+\n }  // namespace tensorflow\ndiff --git a/tensorflow/core/kernels/mfcc_op.cc b/tensorflow/core/kernels/mfcc_op.cc\nindex 358a420c1606a..2c5f9560aaa31 100644\n--- a/tensorflow/core/kernels/mfcc_op.cc\n+++ b/tensorflow/core/kernels/mfcc_op.cc\n@@ -25,7 +25,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-// Create a speech fingerpring from spectrogram data.\n+// Create a speech fingerprint from spectrogram data.\n class MfccOp : public OpKernel {\n  public:\n   explicit MfccOp(OpKernelConstruction* context) : OpKernel(context) {\n@@ -60,10 +60,12 @@ class MfccOp : public OpKernel {\n     mfcc.set_lower_frequency_limit(lower_frequency_limit_);\n     mfcc.set_filterbank_channel_count(filterbank_channel_count_);\n     mfcc.set_dct_coefficient_count(dct_coefficient_count_);\n-    OP_REQUIRES(context, mfcc.Initialize(spectrogram_channels, sample_rate),\n-                errors::InvalidArgument(\n-                    ""Mfcc initialization failed for channel count "",\n-                    spectrogram_channels, "" and sample rate "", sample_rate));\n+    OP_REQUIRES(\n+        context, mfcc.Initialize(spectrogram_channels, sample_rate),\n+        errors::InvalidArgument(""Mfcc initialization failed for channel count "",\n+                                spectrogram_channels, "", sample rate "",\n+                                sample_rate, "" and filterbank_channel_count "",\n+                                filterbank_channel_count_));\n \n     Tensor* output_tensor = nullptr;\n     OP_REQUIRES_OK(context,\n'",['Make MfccMelFilterbank fail initialization if num_channels is > max int value.\n\nAlso initialize MfccDct only if MfccMelFilterbank initialization was successful.\n\nPiperOrigin-RevId: 477844246'],[],2022-10-21 18:22:02
58233,"r2.9 cherry-pick: 80ff197d03d ""Fix SDCA optimizer crash.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/80ff197d03db2a70c6a111f97dcdacad1b0babfa,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/sdca_internal.cc b/tensorflow/core/kernels/sdca_internal.cc\nindex 58d83f6936a8a..b2a9bc630af6e 100644\n--- a/tensorflow/core/kernels/sdca_internal.cc\n+++ b/tensorflow/core/kernels/sdca_internal.cc\n@@ -389,6 +389,13 @@ Status Examples::Initialize(OpKernelContext* const context,\n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(""dense_features"", &dense_features_inputs));\n+  for (int i = 0; i < dense_features_inputs.size(); ++i) {\n+    if (!TensorShapeUtils::IsMatrix(dense_features_inputs[i].shape())) {\n+      return errors::InvalidArgument(""Dense features at index "", i,\n+                                     "" must be rank 2 but is rank "",\n+                                     dense_features_inputs[i].dims());\n+    }\n+  }\n \n   examples_.clear();\n   examples_.resize(num_examples);\ndiff --git a/tensorflow/core/kernels/sdca_ops.cc b/tensorflow/core/kernels/sdca_ops.cc\nindex 98b4fd1c82b23..d279eda86e741 100644\n--- a/tensorflow/core/kernels/sdca_ops.cc\n+++ b/tensorflow/core/kernels/sdca_ops.cc\n@@ -49,6 +49,7 @@ limitations under the License.\n #include ""tensorflow/core/lib/core/status.h""\n #include ""tensorflow/core/lib/core/stringpiece.h""\n #include ""tensorflow/core/lib/gtl/inlined_vector.h""\n+#include ""tensorflow/core/platform/errors.h""\n #include ""tensorflow/core/platform/fingerprint.h""\n #include ""tensorflow/core/platform/macros.h""\n #include ""tensorflow/core/platform/mutex.h""\n@@ -142,6 +143,10 @@ void DoCompute(const ComputeOptions& options, OpKernelContext* const context) {\n   const Tensor* example_state_data_t;\n   OP_REQUIRES_OK(context,\n                  context->input(""example_state_data"", &example_state_data_t));\n+  OP_REQUIRES(\n+      context, TensorShapeUtils::IsMatrix(example_state_data_t->shape()),\n+      errors::InvalidArgument(""example_state_data must be rank 2 but is rank "",\n+                              example_state_data_t->dims()));\n   TensorShape expected_example_state_shape({examples.num_examples(), 4});\n   OP_REQUIRES(context,\n               example_state_data_t->shape() == expected_example_state_shape,\n'","[""Fix SDCA optimizer crash.\n\nValidates size of the dense_features and example state_data_inputs.\nOther validation already verifies that sizes are otherwise consistent.\n\nThis looks to be a v1-only op that isn't used internally at all outside\nof `contrib`, and no tests.\n\nPiperOrigin-RevId: 478073762""]",[],2022-10-21 18:17:12
58232,"r2.8 cherry-pick: 39ec7eaf142 ""Make MfccMelFilterbank fail initialization if num_channels is > max int value.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/39ec7eaf1428e90c37787e5b3fbd68ebd3c48860,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/mfcc.cc b/tensorflow/core/kernels/mfcc.cc\nindex 8c755e0df8754..cb4416f7bd309 100644\n--- a/tensorflow/core/kernels/mfcc.cc\n+++ b/tensorflow/core/kernels/mfcc.cc\n@@ -38,8 +38,10 @@ bool Mfcc::Initialize(int input_length, double input_sample_rate) {\n   bool initialized = mel_filterbank_.Initialize(\n       input_length, input_sample_rate, filterbank_channel_count_,\n       lower_frequency_limit_, upper_frequency_limit_);\n-  initialized &=\n-      dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  if (initialized) {\n+    initialized =\n+        dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  }\n   initialized_ = initialized;\n   return initialized;\n }\ndiff --git a/tensorflow/core/kernels/mfcc_mel_filterbank.cc b/tensorflow/core/kernels/mfcc_mel_filterbank.cc\nindex 8eb2d9d8309f5..c5c2d29d37b99 100644\n--- a/tensorflow/core/kernels/mfcc_mel_filterbank.cc\n+++ b/tensorflow/core/kernels/mfcc_mel_filterbank.cc\n@@ -32,6 +32,8 @@ limitations under the License.\n \n #include <math.h>\n \n+#include <limits>\n+\n #include ""tensorflow/core/platform/logging.h""\n \n namespace tensorflow {\n@@ -74,7 +76,17 @@ bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,\n \n   // An extra center frequency is computed at the top to get the upper\n   // limit on the high side of the final triangular filter.\n-  center_frequencies_.resize(num_channels_ + 1);\n+  std::size_t center_frequencies_size = std::size_t(num_channels_) + 1;\n+  if (center_frequencies_size >= std::numeric_limits<int>::max() ||\n+      center_frequencies_size > center_frequencies_.max_size()) {\n+    LOG(ERROR) << ""Number of filterbank channels must be less than ""\n+               << std::numeric_limits<int>::max()\n+               << "" and less than or equal to ""\n+               << center_frequencies_.max_size();\n+    return false;\n+  }\n+  center_frequencies_.resize(center_frequencies_size);\n+\n   const double mel_low = FreqToMel(lower_frequency_limit);\n   const double mel_hi = FreqToMel(upper_frequency_limit);\n   const double mel_span = mel_hi - mel_low;\ndiff --git a/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc b/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\nindex 54f31e1699ef1..26b5afed13505 100644\n--- a/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\n+++ b/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\n@@ -15,6 +15,7 @@ limitations under the License.\n \n #include ""tensorflow/core/kernels/mfcc_mel_filterbank.h""\n \n+#include <limits>\n #include <vector>\n \n #include ""tensorflow/core/platform/test.h""\n@@ -85,4 +86,37 @@ TEST(MfccMelFilterbankTest, IgnoresExistingContentOfOutputVector) {\n   }\n }\n \n+TEST(MfccMelFilterbankTest, FailsWhenChannelsGreaterThanMaxIntValue) {\n+  // Test for bug where vector throws a length_error when it suspects the size\n+  // to be more than it\'s max_size. For now, we fail initialization when the\n+  // number of requested channels is >= the maximum value int can take (since\n+  // num_channels_ is an int).\n+  MfccMelFilterbank filterbank;\n+\n+  const int kSampleCount = 513;\n+  std::size_t num_channels = std::numeric_limits<int>::max();\n+  bool initialized = filterbank.Initialize(\n+      kSampleCount, 2 /* sample rate */, num_channels /* channels */,\n+      1.0 /*  lower frequency limit */, 5.0 /* upper frequency limit */);\n+\n+  EXPECT_FALSE(initialized);\n+}\n+\n+TEST(MfccMelFilterbankTest, FailsWhenChannelsGreaterThanMaxSize) {\n+  // Test for bug where vector throws a length_error when it suspects the size\n+  // to be more than it\'s max_size. For now, we fail initialization when the\n+  // number of requested channels is > than std::vector<double>::max_size().\n+  MfccMelFilterbank filterbank;\n+\n+  const int kSampleCount = 513;\n+  // Set num_channels to exceed the max_size a double vector can\n+  // theoretically take.\n+  std::size_t num_channels = std::vector<double>().max_size() + 1;\n+  bool initialized = filterbank.Initialize(\n+      kSampleCount, 2 /* sample rate */, num_channels /* channels */,\n+      1.0 /*  lower frequency limit */, 5.0 /* upper frequency limit */);\n+\n+  EXPECT_FALSE(initialized);\n+}\n+\n }  // namespace tensorflow\ndiff --git a/tensorflow/core/kernels/mfcc_op.cc b/tensorflow/core/kernels/mfcc_op.cc\nindex 358a420c1606a..2c5f9560aaa31 100644\n--- a/tensorflow/core/kernels/mfcc_op.cc\n+++ b/tensorflow/core/kernels/mfcc_op.cc\n@@ -25,7 +25,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-// Create a speech fingerpring from spectrogram data.\n+// Create a speech fingerprint from spectrogram data.\n class MfccOp : public OpKernel {\n  public:\n   explicit MfccOp(OpKernelConstruction* context) : OpKernel(context) {\n@@ -60,10 +60,12 @@ class MfccOp : public OpKernel {\n     mfcc.set_lower_frequency_limit(lower_frequency_limit_);\n     mfcc.set_filterbank_channel_count(filterbank_channel_count_);\n     mfcc.set_dct_coefficient_count(dct_coefficient_count_);\n-    OP_REQUIRES(context, mfcc.Initialize(spectrogram_channels, sample_rate),\n-                errors::InvalidArgument(\n-                    ""Mfcc initialization failed for channel count "",\n-                    spectrogram_channels, "" and sample rate "", sample_rate));\n+    OP_REQUIRES(\n+        context, mfcc.Initialize(spectrogram_channels, sample_rate),\n+        errors::InvalidArgument(""Mfcc initialization failed for channel count "",\n+                                spectrogram_channels, "", sample rate "",\n+                                sample_rate, "" and filterbank_channel_count "",\n+                                filterbank_channel_count_));\n \n     Tensor* output_tensor = nullptr;\n     OP_REQUIRES_OK(context,\n'",['Make MfccMelFilterbank fail initialization if num_channels is > max int value.\n\nAlso initialize MfccDct only if MfccMelFilterbank initialization was successful.\n\nPiperOrigin-RevId: 477844246'],[],2022-10-21 18:13:26
58231,"r2.9 cherry-pick: 39ec7eaf142 ""Make MfccMelFilterbank fail initialization if num_channels is > max int value.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/39ec7eaf1428e90c37787e5b3fbd68ebd3c48860,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/mfcc.cc b/tensorflow/core/kernels/mfcc.cc\nindex 8c755e0df8754..cb4416f7bd309 100644\n--- a/tensorflow/core/kernels/mfcc.cc\n+++ b/tensorflow/core/kernels/mfcc.cc\n@@ -38,8 +38,10 @@ bool Mfcc::Initialize(int input_length, double input_sample_rate) {\n   bool initialized = mel_filterbank_.Initialize(\n       input_length, input_sample_rate, filterbank_channel_count_,\n       lower_frequency_limit_, upper_frequency_limit_);\n-  initialized &=\n-      dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  if (initialized) {\n+    initialized =\n+        dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  }\n   initialized_ = initialized;\n   return initialized;\n }\ndiff --git a/tensorflow/core/kernels/mfcc_mel_filterbank.cc b/tensorflow/core/kernels/mfcc_mel_filterbank.cc\nindex 8eb2d9d8309f5..c5c2d29d37b99 100644\n--- a/tensorflow/core/kernels/mfcc_mel_filterbank.cc\n+++ b/tensorflow/core/kernels/mfcc_mel_filterbank.cc\n@@ -32,6 +32,8 @@ limitations under the License.\n \n #include <math.h>\n \n+#include <limits>\n+\n #include ""tensorflow/core/platform/logging.h""\n \n namespace tensorflow {\n@@ -74,7 +76,17 @@ bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,\n \n   // An extra center frequency is computed at the top to get the upper\n   // limit on the high side of the final triangular filter.\n-  center_frequencies_.resize(num_channels_ + 1);\n+  std::size_t center_frequencies_size = std::size_t(num_channels_) + 1;\n+  if (center_frequencies_size >= std::numeric_limits<int>::max() ||\n+      center_frequencies_size > center_frequencies_.max_size()) {\n+    LOG(ERROR) << ""Number of filterbank channels must be less than ""\n+               << std::numeric_limits<int>::max()\n+               << "" and less than or equal to ""\n+               << center_frequencies_.max_size();\n+    return false;\n+  }\n+  center_frequencies_.resize(center_frequencies_size);\n+\n   const double mel_low = FreqToMel(lower_frequency_limit);\n   const double mel_hi = FreqToMel(upper_frequency_limit);\n   const double mel_span = mel_hi - mel_low;\ndiff --git a/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc b/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\nindex 54f31e1699ef1..26b5afed13505 100644\n--- a/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\n+++ b/tensorflow/core/kernels/mfcc_mel_filterbank_test.cc\n@@ -15,6 +15,7 @@ limitations under the License.\n \n #include ""tensorflow/core/kernels/mfcc_mel_filterbank.h""\n \n+#include <limits>\n #include <vector>\n \n #include ""tensorflow/core/platform/test.h""\n@@ -85,4 +86,37 @@ TEST(MfccMelFilterbankTest, IgnoresExistingContentOfOutputVector) {\n   }\n }\n \n+TEST(MfccMelFilterbankTest, FailsWhenChannelsGreaterThanMaxIntValue) {\n+  // Test for bug where vector throws a length_error when it suspects the size\n+  // to be more than it\'s max_size. For now, we fail initialization when the\n+  // number of requested channels is >= the maximum value int can take (since\n+  // num_channels_ is an int).\n+  MfccMelFilterbank filterbank;\n+\n+  const int kSampleCount = 513;\n+  std::size_t num_channels = std::numeric_limits<int>::max();\n+  bool initialized = filterbank.Initialize(\n+      kSampleCount, 2 /* sample rate */, num_channels /* channels */,\n+      1.0 /*  lower frequency limit */, 5.0 /* upper frequency limit */);\n+\n+  EXPECT_FALSE(initialized);\n+}\n+\n+TEST(MfccMelFilterbankTest, FailsWhenChannelsGreaterThanMaxSize) {\n+  // Test for bug where vector throws a length_error when it suspects the size\n+  // to be more than it\'s max_size. For now, we fail initialization when the\n+  // number of requested channels is > than std::vector<double>::max_size().\n+  MfccMelFilterbank filterbank;\n+\n+  const int kSampleCount = 513;\n+  // Set num_channels to exceed the max_size a double vector can\n+  // theoretically take.\n+  std::size_t num_channels = std::vector<double>().max_size() + 1;\n+  bool initialized = filterbank.Initialize(\n+      kSampleCount, 2 /* sample rate */, num_channels /* channels */,\n+      1.0 /*  lower frequency limit */, 5.0 /* upper frequency limit */);\n+\n+  EXPECT_FALSE(initialized);\n+}\n+\n }  // namespace tensorflow\ndiff --git a/tensorflow/core/kernels/mfcc_op.cc b/tensorflow/core/kernels/mfcc_op.cc\nindex 358a420c1606a..2c5f9560aaa31 100644\n--- a/tensorflow/core/kernels/mfcc_op.cc\n+++ b/tensorflow/core/kernels/mfcc_op.cc\n@@ -25,7 +25,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-// Create a speech fingerpring from spectrogram data.\n+// Create a speech fingerprint from spectrogram data.\n class MfccOp : public OpKernel {\n  public:\n   explicit MfccOp(OpKernelConstruction* context) : OpKernel(context) {\n@@ -60,10 +60,12 @@ class MfccOp : public OpKernel {\n     mfcc.set_lower_frequency_limit(lower_frequency_limit_);\n     mfcc.set_filterbank_channel_count(filterbank_channel_count_);\n     mfcc.set_dct_coefficient_count(dct_coefficient_count_);\n-    OP_REQUIRES(context, mfcc.Initialize(spectrogram_channels, sample_rate),\n-                errors::InvalidArgument(\n-                    ""Mfcc initialization failed for channel count "",\n-                    spectrogram_channels, "" and sample rate "", sample_rate));\n+    OP_REQUIRES(\n+        context, mfcc.Initialize(spectrogram_channels, sample_rate),\n+        errors::InvalidArgument(""Mfcc initialization failed for channel count "",\n+                                spectrogram_channels, "", sample rate "",\n+                                sample_rate, "" and filterbank_channel_count "",\n+                                filterbank_channel_count_));\n \n     Tensor* output_tensor = nullptr;\n     OP_REQUIRES_OK(context,\n'",['Make MfccMelFilterbank fail initialization if num_channels is > max int value.\n\nAlso initialize MfccDct only if MfccMelFilterbank initialization was successful.\n\nPiperOrigin-RevId: 477844246'],[],2022-10-21 18:12:48
58230,"r2.10 cherry-pick: cf35502463a ""Add rank checks to GenerateBoundingBoxProposals.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/cf35502463a88ca7185a99daa7031df60b3c1c98,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc b/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\nindex a12cd3e6601fc..80dc57377be1a 100644\n--- a/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\n+++ b/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\n@@ -312,6 +312,22 @@ class GenerateBoundingBoxProposals : public tensorflow::OpKernel {\n     const auto bbox_deltas = context->input(1);\n     const auto image_info = context->input(2);\n     const auto anchors = context->input(3);\n+\n+    OP_REQUIRES(context, scores.dims() == 4,\n+                errors::InvalidArgument(""`scores` must be rank 4 but is rank "",\n+                                        scores.dims()));\n+    OP_REQUIRES(\n+        context, bbox_deltas.dims() == 4,\n+        errors::InvalidArgument(""`bbox_deltas` must be rank 4 but is rank "",\n+                                bbox_deltas.dims()));\n+    OP_REQUIRES(\n+        context, image_info.dims() == 2,\n+        errors::InvalidArgument(""`image_info` must be rank 2 but is rank "",\n+                                image_info.dims()));\n+    OP_REQUIRES(context, anchors.dims() == 3,\n+                errors::InvalidArgument(""`anchors` must be rank 3 but is rank "",\n+                                        anchors.dims()));\n+\n     const auto num_images = scores.dim_size(0);\n     const auto num_anchors = scores.dim_size(3);\n     const auto height = scores.dim_size(1);\ndiff --git a/tensorflow/python/kernel_tests/image_ops/BUILD b/tensorflow/python/kernel_tests/image_ops/BUILD\nindex e1d38c5efe296..15be989ec57d0 100644\n--- a/tensorflow/python/kernel_tests/image_ops/BUILD\n+++ b/tensorflow/python/kernel_tests/image_ops/BUILD\n@@ -102,7 +102,7 @@ tf_py_test(\n     ],\n )\n \n-tf_py_test(\n+cuda_py_test(\n     name = ""draw_bounding_box_op_test"",\n     size = ""small"",\n     srcs = [""draw_bounding_box_op_test.py""],\ndiff --git a/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py b/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\nindex 91fcd9351680a..a66d8d8a9a2a1 100644\n--- a/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\n+++ b/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\n@@ -16,8 +16,11 @@\n \n import numpy as np\n \n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n+from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import image_ops\n from tensorflow.python.ops import image_ops_impl\n@@ -131,6 +134,22 @@ def testDrawBoundingBoxHalf(self):\n     self._testDrawBoundingBoxColorCycling(\n         image, dtype=dtypes.half, colors=colors)\n \n+  # generate_bound_box_proposals is only available on GPU.\n+  @test_util.run_gpu_only()\n+  def testGenerateBoundingBoxProposals(self):\n+    # Op only exists on GPU.\n+    with self.cached_session(use_gpu=True):\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  ""must be rank 4""):\n+        scores = constant_op.constant(\n+            value=[[[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]]])\n+        self.evaluate(\n+            image_ops.generate_bounding_box_proposals(\n+                scores=scores,\n+                bbox_deltas=[],\n+                image_info=[],\n+                anchors=[],\n+                pre_nms_topn=1))\n \n if __name__ == ""__main__"":\n   test.main()\n'",['Add rank checks to GenerateBoundingBoxProposals.\n\nPiperOrigin-RevId: 479681553'],[],2022-10-21 18:07:56
58229,"r2.8 cherry-pick: cf35502463a ""Add rank checks to GenerateBoundingBoxProposals.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/cf35502463a88ca7185a99daa7031df60b3c1c98,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc b/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\nindex a12cd3e6601fc..80dc57377be1a 100644\n--- a/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\n+++ b/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\n@@ -312,6 +312,22 @@ class GenerateBoundingBoxProposals : public tensorflow::OpKernel {\n     const auto bbox_deltas = context->input(1);\n     const auto image_info = context->input(2);\n     const auto anchors = context->input(3);\n+\n+    OP_REQUIRES(context, scores.dims() == 4,\n+                errors::InvalidArgument(""`scores` must be rank 4 but is rank "",\n+                                        scores.dims()));\n+    OP_REQUIRES(\n+        context, bbox_deltas.dims() == 4,\n+        errors::InvalidArgument(""`bbox_deltas` must be rank 4 but is rank "",\n+                                bbox_deltas.dims()));\n+    OP_REQUIRES(\n+        context, image_info.dims() == 2,\n+        errors::InvalidArgument(""`image_info` must be rank 2 but is rank "",\n+                                image_info.dims()));\n+    OP_REQUIRES(context, anchors.dims() == 3,\n+                errors::InvalidArgument(""`anchors` must be rank 3 but is rank "",\n+                                        anchors.dims()));\n+\n     const auto num_images = scores.dim_size(0);\n     const auto num_anchors = scores.dim_size(3);\n     const auto height = scores.dim_size(1);\ndiff --git a/tensorflow/python/kernel_tests/image_ops/BUILD b/tensorflow/python/kernel_tests/image_ops/BUILD\nindex 96de1e11c8efe..4d46cf8b5a1dc 100644\n--- a/tensorflow/python/kernel_tests/image_ops/BUILD\n+++ b/tensorflow/python/kernel_tests/image_ops/BUILD\n@@ -102,7 +102,7 @@ tf_py_test(\n     ],\n )\n \n-tf_py_test(\n+cuda_py_test(\n     name = ""draw_bounding_box_op_test"",\n     size = ""small"",\n     srcs = [""draw_bounding_box_op_test.py""],\ndiff --git a/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py b/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\nindex 91fcd9351680a..a66d8d8a9a2a1 100644\n--- a/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\n+++ b/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\n@@ -16,8 +16,11 @@\n \n import numpy as np\n \n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n+from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import image_ops\n from tensorflow.python.ops import image_ops_impl\n@@ -131,6 +134,22 @@ def testDrawBoundingBoxHalf(self):\n     self._testDrawBoundingBoxColorCycling(\n         image, dtype=dtypes.half, colors=colors)\n \n+  # generate_bound_box_proposals is only available on GPU.\n+  @test_util.run_gpu_only()\n+  def testGenerateBoundingBoxProposals(self):\n+    # Op only exists on GPU.\n+    with self.cached_session(use_gpu=True):\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  ""must be rank 4""):\n+        scores = constant_op.constant(\n+            value=[[[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]]])\n+        self.evaluate(\n+            image_ops.generate_bounding_box_proposals(\n+                scores=scores,\n+                bbox_deltas=[],\n+                image_info=[],\n+                anchors=[],\n+                pre_nms_topn=1))\n \n if __name__ == ""__main__"":\n   test.main()\n'",['Add rank checks to GenerateBoundingBoxProposals.\n\nPiperOrigin-RevId: 479681553'],[],2022-10-21 18:07:52
58228,"r2.9 cherry-pick: cf35502463a ""Add rank checks to GenerateBoundingBoxProposals.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/cf35502463a88ca7185a99daa7031df60b3c1c98,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc b/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\nindex a12cd3e6601fc..80dc57377be1a 100644\n--- a/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\n+++ b/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc\n@@ -312,6 +312,22 @@ class GenerateBoundingBoxProposals : public tensorflow::OpKernel {\n     const auto bbox_deltas = context->input(1);\n     const auto image_info = context->input(2);\n     const auto anchors = context->input(3);\n+\n+    OP_REQUIRES(context, scores.dims() == 4,\n+                errors::InvalidArgument(""`scores` must be rank 4 but is rank "",\n+                                        scores.dims()));\n+    OP_REQUIRES(\n+        context, bbox_deltas.dims() == 4,\n+        errors::InvalidArgument(""`bbox_deltas` must be rank 4 but is rank "",\n+                                bbox_deltas.dims()));\n+    OP_REQUIRES(\n+        context, image_info.dims() == 2,\n+        errors::InvalidArgument(""`image_info` must be rank 2 but is rank "",\n+                                image_info.dims()));\n+    OP_REQUIRES(context, anchors.dims() == 3,\n+                errors::InvalidArgument(""`anchors` must be rank 3 but is rank "",\n+                                        anchors.dims()));\n+\n     const auto num_images = scores.dim_size(0);\n     const auto num_anchors = scores.dim_size(3);\n     const auto height = scores.dim_size(1);\ndiff --git a/tensorflow/python/kernel_tests/image_ops/BUILD b/tensorflow/python/kernel_tests/image_ops/BUILD\nindex 96de1e11c8efe..4d46cf8b5a1dc 100644\n--- a/tensorflow/python/kernel_tests/image_ops/BUILD\n+++ b/tensorflow/python/kernel_tests/image_ops/BUILD\n@@ -102,7 +102,7 @@ tf_py_test(\n     ],\n )\n \n-tf_py_test(\n+cuda_py_test(\n     name = ""draw_bounding_box_op_test"",\n     size = ""small"",\n     srcs = [""draw_bounding_box_op_test.py""],\ndiff --git a/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py b/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\nindex 91fcd9351680a..a66d8d8a9a2a1 100644\n--- a/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\n+++ b/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py\n@@ -16,8 +16,11 @@\n \n import numpy as np\n \n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n+from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import image_ops\n from tensorflow.python.ops import image_ops_impl\n@@ -131,6 +134,22 @@ def testDrawBoundingBoxHalf(self):\n     self._testDrawBoundingBoxColorCycling(\n         image, dtype=dtypes.half, colors=colors)\n \n+  # generate_bound_box_proposals is only available on GPU.\n+  @test_util.run_gpu_only()\n+  def testGenerateBoundingBoxProposals(self):\n+    # Op only exists on GPU.\n+    with self.cached_session(use_gpu=True):\n+      with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                  ""must be rank 4""):\n+        scores = constant_op.constant(\n+            value=[[[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]]])\n+        self.evaluate(\n+            image_ops.generate_bounding_box_proposals(\n+                scores=scores,\n+                bbox_deltas=[],\n+                image_info=[],\n+                anchors=[],\n+                pre_nms_topn=1))\n \n if __name__ == ""__main__"":\n   test.main()\n'",['Add rank checks to GenerateBoundingBoxProposals.\n\nPiperOrigin-RevId: 479681553'],[],2022-10-21 18:07:27
58227,"r2.8 cherry-pick: eaf30105b04 ""Fix security vulnerability with calling ParseInt64Value with an invalid py_value.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/eaf30105b048833e58b6b4def707e789583144ed,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc\nindex 74bc7cd7b7644..be7205bb63e01 100644\n--- a/tensorflow/python/eager/pywrap_tfe_src.cc\n+++ b/tensorflow/python/eager/pywrap_tfe_src.cc\n@@ -256,6 +256,13 @@ PARSE_VALUE(ParseFloatValue, float, PyFloat_Check, PyFloat_AsDouble)\n #if PY_MAJOR_VERSION < 3\n bool ParseInt64Value(const string& key, PyObject* py_value, TF_Status* status,\n                      int64_t* value) {\n+  if (py_value == nullptr) {\n+    TF_SetStatus(status, TF_INVALID_ARGUMENT,\n+                 tensorflow::strings::StrCat(\n+                     ""Expecting int or long value for attr "", key, "".""))\n+        .c_str();\n+    return false;\n+  }\n   if (PyInt_Check(py_value)) {\n     *value = static_cast<int64_t>(PyInt_AsLong(py_value));\n     return true;\n'",['Fix security vulnerability with calling ParseInt64Value with an invalid py_value.\n\nPiperOrigin-RevId: 477281263'],[],2022-10-21 18:01:28
58226,"r2.10 cherry-pick: eaf30105b04 ""Fix security vulnerability with calling ParseInt64Value with an invalid py_value.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/eaf30105b048833e58b6b4def707e789583144ed,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc\nindex 7b3a8048c154b..f4b8809fef851 100644\n--- a/tensorflow/python/eager/pywrap_tfe_src.cc\n+++ b/tensorflow/python/eager/pywrap_tfe_src.cc\n@@ -256,6 +256,13 @@ PARSE_VALUE(ParseFloatValue, float, PyFloat_Check, PyFloat_AsDouble)\n #if PY_MAJOR_VERSION < 3\n bool ParseInt64Value(const string& key, PyObject* py_value, TF_Status* status,\n                      int64_t* value) {\n+  if (py_value == nullptr) {\n+    TF_SetStatus(status, TF_INVALID_ARGUMENT,\n+                 tensorflow::strings::StrCat(\n+                     ""Expecting int or long value for attr "", key, "".""))\n+        .c_str();\n+    return false;\n+  }\n   if (PyInt_Check(py_value)) {\n     *value = static_cast<int64_t>(PyInt_AsLong(py_value));\n     return true;\n'",['Fix security vulnerability with calling ParseInt64Value with an invalid py_value.\n\nPiperOrigin-RevId: 477281263'],[],2022-10-21 18:01:23
58225,"r2.9 cherry-pick: eaf30105b04 ""Fix security vulnerability with calling ParseInt64Value with an invalid py_value.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/eaf30105b048833e58b6b4def707e789583144ed,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc\nindex 73c4764a07522..46cf8c619b786 100644\n--- a/tensorflow/python/eager/pywrap_tfe_src.cc\n+++ b/tensorflow/python/eager/pywrap_tfe_src.cc\n@@ -256,6 +256,13 @@ PARSE_VALUE(ParseFloatValue, float, PyFloat_Check, PyFloat_AsDouble)\n #if PY_MAJOR_VERSION < 3\n bool ParseInt64Value(const string& key, PyObject* py_value, TF_Status* status,\n                      int64_t* value) {\n+  if (py_value == nullptr) {\n+    TF_SetStatus(status, TF_INVALID_ARGUMENT,\n+                 tensorflow::strings::StrCat(\n+                     ""Expecting int or long value for attr "", key, "".""))\n+        .c_str();\n+    return false;\n+  }\n   if (PyInt_Check(py_value)) {\n     *value = static_cast<int64_t>(PyInt_AsLong(py_value));\n     return true;\n'",['Fix security vulnerability with calling ParseInt64Value with an invalid py_value.\n\nPiperOrigin-RevId: 477281263'],[],2022-10-21 18:01:04
58224,"r2.9 cherry-pick: a513a45dba3 ""Check for null input in pywrap_tfe_src.cc SetOpAttrList() function, to avoid program crash.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a513a45dba3221f99e45cceac93fbb18ccc0de24,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc\nindex 73c4764a07522..13b8f1be076d9 100644\n--- a/tensorflow/python/eager/pywrap_tfe_src.cc\n+++ b/tensorflow/python/eager/pywrap_tfe_src.cc\n@@ -397,20 +397,24 @@ bool SetOpAttrList(TFE_Context* ctx, TFE_Op* op, const char* key,\n   const int num_values = PySequence_Size(py_list);\n   if (attr_list_sizes != nullptr) (*attr_list_sizes)[key] = num_values;\n \n-#define PARSE_LIST(c_type, parse_fn)                                       \\\n-  std::unique_ptr<c_type[]> values(new c_type[num_values]);                \\\n-  for (int i = 0; i < num_values; ++i) {                                   \\\n-    tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i));    \\\n-    if (py_value == nullptr) {                                             \\\n-      TF_SetStatus(status, TF_INVALID_ARGUMENT,                            \\\n-                   tensorflow::strings::StrCat(                            \\\n-                       ""Expecting sequence of "" #c_type "" for attr "", key, \\\n-                       "", got "", py_list->ob_type->tp_name)                \\\n-                       .c_str());                                          \\\n-      return false;                                                        \\\n-    } else if (!parse_fn(key, py_value.get(), status, &values[i])) {       \\\n-      return false;                                                        \\\n-    }                                                                      \\\n+#define SEQUENCE_ITEM_NULL_CHECK(c_type, item)                           \\\n+  if (!item) {                                                           \\\n+    TF_SetStatus(status, TF_INVALID_ARGUMENT,                            \\\n+                 tensorflow::strings::StrCat(                            \\\n+                     ""Expecting sequence of "" #c_type "" for attr "", key, \\\n+                     "", got "", py_list->ob_type->tp_name)                \\\n+                     .c_str());                                          \\\n+    return false;                                                        \\\n+  }\n+\n+#define PARSE_LIST(c_type, parse_fn)                                    \\\n+  std::unique_ptr<c_type[]> values(new c_type[num_values]);             \\\n+  for (int i = 0; i < num_values; ++i) {                                \\\n+    tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i)); \\\n+    SEQUENCE_ITEM_NULL_CHECK(c_type, py_value);                         \\\n+    if (!parse_fn(key, py_value.get(), status, &values[i])) {           \\\n+      return false;                                                     \\\n+    }                                                                   \\\n   }\n \n   if (type == TF_ATTR_STRING) {\n@@ -419,6 +423,7 @@ bool SetOpAttrList(TFE_Context* ctx, TFE_Op* op, const char* key,\n     for (int i = 0; i < num_values; ++i) {\n       tensorflow::StringPiece value;\n       tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i));\n+      SEQUENCE_ITEM_NULL_CHECK(string, py_value);\n       if (!ParseStringValue(key, py_value.get(), status, &value)) return false;\n       values[i] = value.data();\n       lengths[i] = value.size();\n'","['Check for null input in pywrap_tfe_src.cc SetOpAttrList() function, to avoid program crash.\n\nPiperOrigin-RevId: 479642942']",[],2022-10-21 17:57:37
58223,"r2.10 cherry-pick: a513a45dba3 ""Check for null input in pywrap_tfe_src.cc SetOpAttrList() function, to avoid program crash.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a513a45dba3221f99e45cceac93fbb18ccc0de24,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc\nindex 7b3a8048c154b..402ff38eeef54 100644\n--- a/tensorflow/python/eager/pywrap_tfe_src.cc\n+++ b/tensorflow/python/eager/pywrap_tfe_src.cc\n@@ -397,20 +397,24 @@ bool SetOpAttrList(TFE_Context* ctx, TFE_Op* op, const char* key,\n   const int num_values = PySequence_Size(py_list);\n   if (attr_list_sizes != nullptr) (*attr_list_sizes)[key] = num_values;\n \n-#define PARSE_LIST(c_type, parse_fn)                                       \\\n-  std::unique_ptr<c_type[]> values(new c_type[num_values]);                \\\n-  for (int i = 0; i < num_values; ++i) {                                   \\\n-    tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i));    \\\n-    if (py_value == nullptr) {                                             \\\n-      TF_SetStatus(status, TF_INVALID_ARGUMENT,                            \\\n-                   tensorflow::strings::StrCat(                            \\\n-                       ""Expecting sequence of "" #c_type "" for attr "", key, \\\n-                       "", got "", py_list->ob_type->tp_name)                \\\n-                       .c_str());                                          \\\n-      return false;                                                        \\\n-    } else if (!parse_fn(key, py_value.get(), status, &values[i])) {       \\\n-      return false;                                                        \\\n-    }                                                                      \\\n+#define SEQUENCE_ITEM_NULL_CHECK(c_type, item)                           \\\n+  if (!item) {                                                           \\\n+    TF_SetStatus(status, TF_INVALID_ARGUMENT,                            \\\n+                 tensorflow::strings::StrCat(                            \\\n+                     ""Expecting sequence of "" #c_type "" for attr "", key, \\\n+                     "", got "", py_list->ob_type->tp_name)                \\\n+                     .c_str());                                          \\\n+    return false;                                                        \\\n+  }\n+\n+#define PARSE_LIST(c_type, parse_fn)                                    \\\n+  std::unique_ptr<c_type[]> values(new c_type[num_values]);             \\\n+  for (int i = 0; i < num_values; ++i) {                                \\\n+    tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i)); \\\n+    SEQUENCE_ITEM_NULL_CHECK(c_type, py_value);                         \\\n+    if (!parse_fn(key, py_value.get(), status, &values[i])) {           \\\n+      return false;                                                     \\\n+    }                                                                   \\\n   }\n \n   if (type == TF_ATTR_STRING) {\n@@ -419,6 +423,7 @@ bool SetOpAttrList(TFE_Context* ctx, TFE_Op* op, const char* key,\n     for (int i = 0; i < num_values; ++i) {\n       tensorflow::StringPiece value;\n       tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i));\n+      SEQUENCE_ITEM_NULL_CHECK(string, py_value);\n       if (!ParseStringValue(key, py_value.get(), status, &value)) return false;\n       values[i] = value.data();\n       lengths[i] = value.size();\n'","['Check for null input in pywrap_tfe_src.cc SetOpAttrList() function, to avoid program crash.\n\nPiperOrigin-RevId: 479642942']",[],2022-10-21 17:51:33
58222,"r2.8 cherry-pick: a513a45dba3 ""Check for null input in pywrap_tfe_src.cc SetOpAttrList() function, to avoid program crash.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a513a45dba3221f99e45cceac93fbb18ccc0de24,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/python/eager/pywrap_tfe_src.cc b/tensorflow/python/eager/pywrap_tfe_src.cc\nindex 74bc7cd7b7644..6850957bc5e4b 100644\n--- a/tensorflow/python/eager/pywrap_tfe_src.cc\n+++ b/tensorflow/python/eager/pywrap_tfe_src.cc\n@@ -389,20 +389,24 @@ bool SetOpAttrList(TFE_Context* ctx, TFE_Op* op, const char* key,\n   const int num_values = PySequence_Size(py_list);\n   if (attr_list_sizes != nullptr) (*attr_list_sizes)[key] = num_values;\n \n-#define PARSE_LIST(c_type, parse_fn)                                       \\\n-  std::unique_ptr<c_type[]> values(new c_type[num_values]);                \\\n-  for (int i = 0; i < num_values; ++i) {                                   \\\n-    tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i));    \\\n-    if (py_value == nullptr) {                                             \\\n-      TF_SetStatus(status, TF_INVALID_ARGUMENT,                            \\\n-                   tensorflow::strings::StrCat(                            \\\n-                       ""Expecting sequence of "" #c_type "" for attr "", key, \\\n-                       "", got "", py_list->ob_type->tp_name)                \\\n-                       .c_str());                                          \\\n-      return false;                                                        \\\n-    } else if (!parse_fn(key, py_value.get(), status, &values[i])) {       \\\n-      return false;                                                        \\\n-    }                                                                      \\\n+#define SEQUENCE_ITEM_NULL_CHECK(c_type, item)                           \\\n+  if (!item) {                                                           \\\n+    TF_SetStatus(status, TF_INVALID_ARGUMENT,                            \\\n+                 tensorflow::strings::StrCat(                            \\\n+                     ""Expecting sequence of "" #c_type "" for attr "", key, \\\n+                     "", got "", py_list->ob_type->tp_name)                \\\n+                     .c_str());                                          \\\n+    return false;                                                        \\\n+  }\n+\n+#define PARSE_LIST(c_type, parse_fn)                                    \\\n+  std::unique_ptr<c_type[]> values(new c_type[num_values]);             \\\n+  for (int i = 0; i < num_values; ++i) {                                \\\n+    tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i)); \\\n+    SEQUENCE_ITEM_NULL_CHECK(c_type, py_value);                         \\\n+    if (!parse_fn(key, py_value.get(), status, &values[i])) {           \\\n+      return false;                                                     \\\n+    }                                                                   \\\n   }\n \n   if (type == TF_ATTR_STRING) {\n@@ -411,6 +415,7 @@ bool SetOpAttrList(TFE_Context* ctx, TFE_Op* op, const char* key,\n     for (int i = 0; i < num_values; ++i) {\n       tensorflow::StringPiece value;\n       tensorflow::Safe_PyObjectPtr py_value(PySequence_ITEM(py_list, i));\n+      SEQUENCE_ITEM_NULL_CHECK(string, py_value);\n       if (!ParseStringValue(key, py_value.get(), status, &value)) return false;\n       values[i] = value.data();\n       lengths[i] = value.size();\n'","['Check for null input in pywrap_tfe_src.cc SetOpAttrList() function, to avoid program crash.\n\nPiperOrigin-RevId: 479642942']",[],2022-10-21 17:49:20
58220,"r2.8 cherry-pick: 72c0bdcb253 ""Fix a potential buffer overflow issue in reference kernel of the CONV_3D_TRANSPOSE""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/72c0bdcb25305b0b36842d746cc61d72658d2941,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\nindex d0e2ef3026e4a..322b3c594555e 100644\n--- a/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\n+++ b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\n@@ -111,14 +111,13 @@ inline void Conv3DTranspose(\n   if (bias_data) {\n     const int outer_size =\n         batches * output_depth * output_height * output_width;\n-    const int num_channels = input_shape.Dims(4);\n     for (int n = 0; n < outer_size; ++n) {\n       for (int c = 0; c < output_num_channels; ++c) {\n         data_ptr[c] = ActivationFunctionWithMinMax(data_ptr[c] + bias_data[c],\n                                                    float_activation_min,\n                                                    float_activation_max);\n       }\n-      data_ptr += num_channels;\n+      data_ptr += output_num_channels;\n     }\n   } else {\n     const int flat_size = output_shape.FlatSize();\n'",['Fix a potential buffer overflow issue in reference kernel of the CONV_3D_TRANSPOSE\n\nPiperOrigin-RevId: 479074072'],[],2022-10-21 17:41:42
58219,"r2.10 cherry-pick: 72c0bdcb253 ""Fix a potential buffer overflow issue in reference kernel of the CONV_3D_TRANSPOSE""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/72c0bdcb25305b0b36842d746cc61d72658d2941,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\nindex d0e2ef3026e4a..322b3c594555e 100644\n--- a/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\n+++ b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\n@@ -111,14 +111,13 @@ inline void Conv3DTranspose(\n   if (bias_data) {\n     const int outer_size =\n         batches * output_depth * output_height * output_width;\n-    const int num_channels = input_shape.Dims(4);\n     for (int n = 0; n < outer_size; ++n) {\n       for (int c = 0; c < output_num_channels; ++c) {\n         data_ptr[c] = ActivationFunctionWithMinMax(data_ptr[c] + bias_data[c],\n                                                    float_activation_min,\n                                                    float_activation_max);\n       }\n-      data_ptr += num_channels;\n+      data_ptr += output_num_channels;\n     }\n   } else {\n     const int flat_size = output_shape.FlatSize();\n'",['Fix a potential buffer overflow issue in reference kernel of the CONV_3D_TRANSPOSE\n\nPiperOrigin-RevId: 479074072'],[],2022-10-21 17:38:13
58218,"r2.9 cherry-pick: 72c0bdcb253 ""Fix a potential buffer overflow issue in reference kernel of the CONV_3D_TRANSPOSE""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/72c0bdcb25305b0b36842d746cc61d72658d2941,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\nindex d0e2ef3026e4a..322b3c594555e 100644\n--- a/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\n+++ b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h\n@@ -111,14 +111,13 @@ inline void Conv3DTranspose(\n   if (bias_data) {\n     const int outer_size =\n         batches * output_depth * output_height * output_width;\n-    const int num_channels = input_shape.Dims(4);\n     for (int n = 0; n < outer_size; ++n) {\n       for (int c = 0; c < output_num_channels; ++c) {\n         data_ptr[c] = ActivationFunctionWithMinMax(data_ptr[c] + bias_data[c],\n                                                    float_activation_min,\n                                                    float_activation_max);\n       }\n-      data_ptr += num_channels;\n+      data_ptr += output_num_channels;\n     }\n   } else {\n     const int flat_size = output_shape.FlatSize();\n'",['Fix a potential buffer overflow issue in reference kernel of the CONV_3D_TRANSPOSE\n\nPiperOrigin-RevId: 479074072'],[],2022-10-21 17:35:12
58217,Updated Ops compatibility list with new api,"Replaced  old api 
 tf.check_numerics
with new api
 tf.debugging.check_numerics

in ops compatibility list.",mohantym,"['mihaimaruseac', 'mohantym']","[""Can you squash these commits please? It doesn't make sense to have 5 commits for a line change and one extra empty line"", 'Sorry @mihaimaruseac !\r\nActually, I was trying to follow spacing style suggested by editor. Closing this PR because of conflicts in merge.']",[],[],['gbaned'],"b'diff --git a/tensorflow/lite/g3doc/guide/ops_compatibility.md b/tensorflow/lite/g3doc/guide/ops_compatibility.md\nindex b307b2da0d67a..b023d52083185 100644\n--- a/tensorflow/lite/g3doc/guide/ops_compatibility.md\n+++ b/tensorflow/lite/g3doc/guide/ops_compatibility.md\n@@ -102,7 +102,7 @@ Here is a non-exhaustive list of TensorFlow operations that are usually removed\n from the graph:\n \n *   `tf.add`\n-*   `tf.check_numerics`\n+*   `tf.debugging.check_numerics`\n *   `tf.constant`\n *   `tf.div`\n *   `tf.divide`\n@@ -146,3 +146,4 @@ models:\n *   `LSH_PROJECTION`\n *   `SKIP_GRAM`\n *   `SVDF`\n+\n'","['Updated lite ops compatibility list \n\nReplaced depreciated api - \r\ntf.check_numerics\r\nwith\r\ntf.debugging.check_numerics', 'Rolled back changes at line 88\n\nRolled back changes at line 88.', 'Removed the details on restricted ops\n\nRemoved the details on restricted ops from latest commit', 'Rolled back format on extra spaces\n\nRolled back format on extra spaces', 'Rolled back extra spaces\n\nRolled back extra spaces according to previous document']",[],2022-10-21 15:42:50
58216,Do not pass 4th argument to _MklNativeFusedConv2D,"The recent change https://github.com/tensorflow/tensorflow/commit/0d5820c180613c0e292c1f3e99aa70162661b612 introduced 4th argument to _FusedConv2D, but _MklNativeFusedConv2D when running with TF_ENABLE_ONEDNN_OPTS=1 still accepting only 3 input arguemnts. This patch makes sure when building node with _MklNativeFsuedConv2D we only define it with 3 input arguments.",milpuz01,['milpuz01'],['CC: @penpornk '],['penpornk'],['penpornk'],['gbaned'],"b'diff --git a/tensorflow/core/kernels/conv_ops_benchmark_test.cc b/tensorflow/core/kernels/conv_ops_benchmark_test.cc\nindex 297a6c14102b9..1197fd7106d00 100644\n--- a/tensorflow/core/kernels/conv_ops_benchmark_test.cc\n+++ b/tensorflow/core/kernels/conv_ops_benchmark_test.cc\n@@ -250,16 +250,20 @@ static Graph* FusedConv2DWithBias(int batch, int height, int width,\n \n   Node* conv;\n   auto builder =\n-      IsMKLEnabled()\n-          ? NodeBuilder(graph->NewName(""conv""), ""_MklNativeFusedConv2D"")\n-                .Attr(""_kernel"", MKL_OP_LABEL)\n-          : NodeBuilder(graph->NewName(""conv""), ""_FusedConv2D"");\n-  TF_CHECK_OK(builder.Input(images)\n-                  .Input(filter)\n-                  .Attr(""num_args"", 1)\n-                  .Input(args)\n-                  .Input(host_args)\n-                  .Attr(""T"", DataTypeToEnum<T>::value)\n+      NodeBuilder(graph->NewName(""conv""),\n+                  IsMKLEnabled() ? ""_MklNativeFusedConv2D"" : ""_FusedConv2D"")\n+          .Input(images)\n+          .Input(filter)\n+          .Attr(""num_args"", 1)\n+          .Input(args);\n+\n+  if (IsMKLEnabled()) {\n+    builder.Attr(""_kernel"", MKL_OP_LABEL);\n+  } else {\n+    builder.Input(host_args);\n+  }\n+\n+  TF_CHECK_OK(builder.Attr(""T"", DataTypeToEnum<T>::value)\n                   .Attr(""strides"", {1, 1, 1, 1})\n                   .Attr(""padding"", ""SAME"")\n                   .Attr(""fused_ops"", fused_ops)\n@@ -301,16 +305,20 @@ static Graph* FusedConv2DWithBatchNorm(\n \n   Node* conv;\n   auto builder =\n-      IsMKLEnabled()\n-          ? NodeBuilder(graph->NewName(""conv""), ""_MklNativeFusedConv2D"")\n-                .Attr(""_kernel"", MKL_OP_LABEL)\n-          : NodeBuilder(graph->NewName(""conv""), ""_FusedConv2D"");\n-  TF_CHECK_OK(builder.Input(images)\n-                  .Input(filter)\n-                  .Attr(""num_args"", 4)\n-                  .Input(args)\n-                  .Input(host_args)\n-                  .Attr(""T"", DataTypeToEnum<T>::value)\n+      NodeBuilder(graph->NewName(""conv""),\n+                  IsMKLEnabled() ? ""_MklNativeFusedConv2D"" : ""_FusedConv2D"")\n+          .Input(images)\n+          .Input(filter)\n+          .Attr(""num_args"", 4)\n+          .Input(args);\n+\n+  if (IsMKLEnabled()) {\n+    builder.Attr(""_kernel"", MKL_OP_LABEL);\n+  } else {\n+    builder.Input(host_args);\n+  }\n+\n+  TF_CHECK_OK(builder.Attr(""T"", DataTypeToEnum<T>::value)\n                   .Attr(""strides"", {1, 1, 1, 1})\n                   .Attr(""padding"", ""SAME"")\n                   .Attr(""fused_ops"", fused_ops)\n'","['Do not pass 4th argument to _MklNativeFusedConv2D\n\nThe recent change https://github.com/tensorflow/tensorflow/commit/0d5820c180613c0e292c1f3e99aa70162661b612 introduced 4th argument to _FusedConv2D, but _MklNativeFusedConv2D when running with TF_ENABLE_ONEDNN_OPTS=1 still accepting only 3 input arguemnts. This patch makes sure when building node with _MklNativeFsuedConv2D we only define it with 3 input arguments.', ""Merge branch 'tensorflow:master' into convolution_microbenchmark_fixup""]",[],2022-10-21 15:10:04
58215,[ROCm] Enable RCCL in XLA pjrt,This enables ROCm RCCL support in XLA PJRT.,rahulbatra85,"['hawkinsp', 'rahulbatra85']","['Our linter is sad because this file is included twice. Can we hoist both this and the CUDA copy of the include out of the ifdef blocks?', 'I should have caught this in my own review. Missed it!\r\nAnyways, I was about to push a change, but this is now merged.\r\nShould I create another PR that moves the #include outside the #ifdef?']","['hawkinsp', 'hawkinsp', 'rahulbatra85']","['hawkinsp', 'hawkinsp', 'rahulbatra85']",['gbaned'],"b'diff --git a/tensorflow/compiler/xla/pjrt/gpu/BUILD b/tensorflow/compiler/xla/pjrt/gpu/BUILD\nindex 76d4eaa045042..c9c1be551e244 100644\n--- a/tensorflow/compiler/xla/pjrt/gpu/BUILD\n+++ b/tensorflow/compiler/xla/pjrt/gpu/BUILD\n@@ -37,6 +37,7 @@ cc_library(\n     visibility = [""//tensorflow/compiler/xla/pjrt:friends""],\n     deps = [\n         "":gpu_helpers"",\n+        "":nccl_id_store"",\n         ""//tensorflow/compiler/xla/pjrt:pjrt_stream_executor_client"",\n         ""@com_google_absl//absl/base:core_headers"",\n         ""@com_google_absl//absl/container:flat_hash_map"",\n@@ -54,7 +55,6 @@ cc_library(\n         ""//tensorflow/compiler/xla/stream_executor:device_memory"",\n         ""//tensorflow/compiler/xla/stream_executor:tf_allocator_adapter"",\n     ] + if_cuda([\n-        "":nccl_id_store"",\n         ""@local_config_cuda//cuda:cuda_headers"",\n         ""//tensorflow/core/common_runtime/gpu:gpu_cudamallocasync_allocator"",\n         ""//tensorflow/compiler/xla/stream_executor/cuda:cuda_activation_header"",\ndiff --git a/tensorflow/compiler/xla/pjrt/gpu/nccl_id_store.cc b/tensorflow/compiler/xla/pjrt/gpu/nccl_id_store.cc\nindex eaa594e2b1939..66e4b25fd1b0b 100644\n--- a/tensorflow/compiler/xla/pjrt/gpu/nccl_id_store.cc\n+++ b/tensorflow/compiler/xla/pjrt/gpu/nccl_id_store.cc\n@@ -19,7 +19,15 @@ limitations under the License.\n #include <utility>\n \n #ifdef NCCL_ENABLED\n+#if TENSORFLOW_USE_ROCM\n+#if (TF_ROCM_VERSION >= 50200)\n+#include ""rocm/include/rccl/rccl.h""\n+#else\n+#include ""rocm/include/rccl.h""\n+#endif\n+#else\n #include ""third_party/nccl/nccl.h""\n+#endif\n #endif  // NCCL_ENABLED\n \n #include ""tensorflow/compiler/xla/util.h""\ndiff --git a/tensorflow/compiler/xla/pjrt/gpu/se_gpu_pjrt_client.cc b/tensorflow/compiler/xla/pjrt/gpu/se_gpu_pjrt_client.cc\nindex 3e3b53f08d51b..b921e725cbc4c 100644\n--- a/tensorflow/compiler/xla/pjrt/gpu/se_gpu_pjrt_client.cc\n+++ b/tensorflow/compiler/xla/pjrt/gpu/se_gpu_pjrt_client.cc\n@@ -38,6 +38,7 @@ limitations under the License.\n \n #ifdef TENSORFLOW_USE_ROCM\n #include ""rocm/rocm_config.h""\n+#include ""tensorflow/compiler/xla/pjrt/gpu/nccl_id_store.h""\n #endif  // TENSORFLOW_USE_ROCM\n \n #include ""tensorflow/compiler/xla/client/client_library.h""\n@@ -282,7 +283,7 @@ Status BuildDistributedDevices(\n   }\n   gpu_executable_run_options->set_gpu_global_device_ids(\n       std::move(gpu_device_ids));\n-#ifdef GOOGLE_CUDA\n+#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n   auto nccl_id_store = std::make_shared<NcclIdStore>(\n       node_id, distributed_client, device_to_node);\n   gpu_executable_run_options->set_nccl_unique_id_callback(\n'",['[ROCm] Enable RCCL in XLA pjrt'],[],2022-10-21 13:59:42
58203,[NVIDIA TF] Enable bfloat16 on GPU for random ops,"Builds bfloat16 kernels for GPU for Random ops.
TODO: Add unit tests

cc @reedwm ",trevor-m,['trevor-m'],"[""> Since we want this change quickly due to an internal issue, I'll merge before unit tests are added. I think it's unlikely there is a bug in this PR.\r\n> \r\n> @trevor-m, can you add tests in a subsequent PR?\r\n\r\nThanks @reedwm, I'll add tests in a follow-up PR shortly.""]",['reedwm'],['reedwm'],"['rohan100jain', 'cheshire', 'reedwm', 'bfontain', 'chsigg', 'gbaned', 'gcforster']","b'diff --git a/tensorflow/core/kernels/random_op.cc b/tensorflow/core/kernels/random_op.cc\nindex b85c120eba9aa..7764e2d60ea92 100644\n--- a/tensorflow/core/kernels/random_op.cc\n+++ b/tensorflow/core/kernels/random_op.cc\n@@ -441,6 +441,7 @@ TF_CALL_uint64(REGISTER_FULL_INT);\n                           RandomUniformIntOp<GPUDevice, IntType>);\n \n TF_CALL_half(REGISTER);\n+TF_CALL_bfloat16(REGISTER);\n TF_CALL_float(REGISTER);\n TF_CALL_double(REGISTER);\n TF_CALL_int32(REGISTER_INT);\ndiff --git a/tensorflow/core/kernels/random_op_gpu.cu.cc b/tensorflow/core/kernels/random_op_gpu.cu.cc\nindex 9d7c56e331066..440971ac1081b 100644\n--- a/tensorflow/core/kernels/random_op_gpu.cu.cc\n+++ b/tensorflow/core/kernels/random_op_gpu.cu.cc\n@@ -40,6 +40,8 @@ typedef Eigen::GpuDevice GPUDevice;\n // NVCC cannot handle "">>"" properly\n template struct FillPhiloxRandom<\n     GPUDevice, random::UniformDistribution<random::PhiloxRandom, Eigen::half> >;\n+template struct FillPhiloxRandom<\n+    GPUDevice, random::UniformDistribution<random::PhiloxRandom, Eigen::bfloat16> >;\n template struct FillPhiloxRandom<\n     GPUDevice, random::UniformDistribution<random::PhiloxRandom, float> >;\n template struct FillPhiloxRandom<\n@@ -62,6 +64,8 @@ template struct FillPhiloxRandom<\n     random::UniformFullIntDistribution<random::PhiloxRandom, uint64> >;\n template struct FillPhiloxRandom<\n     GPUDevice, random::NormalDistribution<random::PhiloxRandom, Eigen::half> >;\n+template struct FillPhiloxRandom<\n+    GPUDevice, random::NormalDistribution<random::PhiloxRandom, Eigen::bfloat16> >;\n template struct FillPhiloxRandom<\n     GPUDevice, random::NormalDistribution<random::PhiloxRandom, float> >;\n template struct FillPhiloxRandom<\n@@ -69,6 +73,9 @@ template struct FillPhiloxRandom<\n template struct FillPhiloxRandom<\n     GPUDevice, random::TruncatedNormalDistribution<\n         random::SingleSampleAdapter<random::PhiloxRandom>, Eigen::half> >;\n+template struct FillPhiloxRandom<\n+    GPUDevice, random::TruncatedNormalDistribution<\n+        random::SingleSampleAdapter<random::PhiloxRandom>, Eigen::bfloat16> >;\n template struct FillPhiloxRandom<\n     GPUDevice, random::TruncatedNormalDistribution<\n                    random::SingleSampleAdapter<random::PhiloxRandom>, float> >;\ndiff --git a/tensorflow/core/kernels/stateful_random_ops.cc b/tensorflow/core/kernels/stateful_random_ops.cc\nindex 9df8ccfb7016a..80f2f9ae0805b 100644\n--- a/tensorflow/core/kernels/stateful_random_ops.cc\n+++ b/tensorflow/core/kernels/stateful_random_ops.cc\n@@ -491,6 +491,7 @@ REGISTER_RngSkip(CPU);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n \n TF_CALL_half(REGISTER_FloatOps_GPU);\n+TF_CALL_bfloat16(REGISTER_FloatOps_GPU);\n TF_CALL_float(REGISTER_FloatOps_GPU);\n TF_CALL_double(REGISTER_FloatOps_GPU);\n TF_CALL_int32(REGISTER_StatefulUniformInt_GPU);\ndiff --git a/tensorflow/core/kernels/stateful_random_ops_gpu.cu.cc b/tensorflow/core/kernels/stateful_random_ops_gpu.cu.cc\nindex d244577d2ab28..e72ab6ee5f45a 100644\n--- a/tensorflow/core/kernels/stateful_random_ops_gpu.cu.cc\n+++ b/tensorflow/core/kernels/stateful_random_ops_gpu.cu.cc\n@@ -120,6 +120,8 @@ void RngSkip_Philox<GPUDevice>::operator()(const GPUDevice& d,\n // NVCC cannot handle "">>"" properly\n template struct UpdateVariableAndFill_Philox<\n     GPUDevice, random::NormalDistribution<random::PhiloxRandom, Eigen::half> >;\n+template struct UpdateVariableAndFill_Philox<\n+    GPUDevice, random::NormalDistribution<random::PhiloxRandom, Eigen::bfloat16> >;\n template struct UpdateVariableAndFill_Philox<\n     GPUDevice, random::NormalDistribution<random::PhiloxRandom, float> >;\n template struct UpdateVariableAndFill_Philox<\n@@ -128,6 +130,10 @@ template struct UpdateVariableAndFill_Philox<\n     GPUDevice, random::TruncatedNormalDistribution<\n                  random::SingleSampleAdapter<random::PhiloxRandom>,\n                  Eigen::half> >;\n+template struct UpdateVariableAndFill_Philox<\n+    GPUDevice, random::TruncatedNormalDistribution<\n+                 random::SingleSampleAdapter<random::PhiloxRandom>,\n+                 Eigen::bfloat16> >;\n template struct UpdateVariableAndFill_Philox<\n     GPUDevice, random::TruncatedNormalDistribution<\n                  random::SingleSampleAdapter<random::PhiloxRandom>,\n@@ -138,6 +144,8 @@ template struct UpdateVariableAndFill_Philox<\n                  double> >;\n template struct UpdateVariableAndFill_Philox<\n     GPUDevice, random::UniformDistribution<random::PhiloxRandom, Eigen::half> >;\n+template struct UpdateVariableAndFill_Philox<\n+    GPUDevice, random::UniformDistribution<random::PhiloxRandom, Eigen::bfloat16> >;\n template struct UpdateVariableAndFill_Philox<\n     GPUDevice, random::UniformDistribution<random::PhiloxRandom, float> >;\n template struct UpdateVariableAndFill_Philox<\ndiff --git a/tensorflow/core/kernels/stateless_random_ops.cc b/tensorflow/core/kernels/stateless_random_ops.cc\nindex b7ed7ec8c88e4..aea2d7339c180 100644\n--- a/tensorflow/core/kernels/stateless_random_ops.cc\n+++ b/tensorflow/core/kernels/stateless_random_ops.cc\n@@ -294,6 +294,7 @@ TF_CALL_int64(REGISTER_ALL_POISSON);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n \n TF_CALL_half(REGISTER_GPU);\n+TF_CALL_bfloat16(REGISTER_GPU);\n TF_CALL_float(REGISTER_GPU);\n TF_CALL_double(REGISTER_GPU);\n TF_CALL_int32(REGISTER_INT_GPU);\ndiff --git a/tensorflow/core/kernels/stateless_random_ops_v2.cc b/tensorflow/core/kernels/stateless_random_ops_v2.cc\nindex 25da9190c1c82..0780182adab05 100644\n--- a/tensorflow/core/kernels/stateless_random_ops_v2.cc\n+++ b/tensorflow/core/kernels/stateless_random_ops_v2.cc\n@@ -327,6 +327,7 @@ REGISTER_GET_KCA(CPU);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n \n TF_CALL_half(REGISTER_GPU);\n+TF_CALL_bfloat16(REGISTER_GPU);\n TF_CALL_float(REGISTER_GPU);\n TF_CALL_double(REGISTER_GPU);\n TF_CALL_int32(REGISTER_INT_GPU);\n'",['Enable bfloat16 on GPU for random ops'],[],2022-10-20 21:25:42
58201,"r2.8 cherry-pick: a65411a1d69 ""Fix OOB write in grappler.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a65411a1d69edfb16b25907ffb8f73556ce36bb7,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/grappler/utils/functions.cc b/tensorflow/core/grappler/utils/functions.cc\nindex 4b647284f2955..2f9f53fb44cd5 100644\n--- a/tensorflow/core/grappler/utils/functions.cc\n+++ b/tensorflow/core/grappler/utils/functions.cc\n@@ -291,6 +291,11 @@ Status MakeGrapplerFunctionItem(const FunctionDef& func,\n \n   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);\n   for (const auto& attr : func.arg_attr()) {\n+    if (attr.first >= inputs.size()) {\n+      return errors::InvalidArgument(""Invalid attribute index, got "",\n+                                     attr.first, "" but expected less than "",\n+                                     inputs.size());\n+    }\n     arg_attr.at(attr.first) = &attr.second;\n   }\n \n'",['Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391'],[],2022-10-20 20:25:52
58200,"r2.11 cherry-pick: 1be74370327 ""Resolve a sanitizer issue with invalid char -> bool conversion.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/1be743703279782a357adbf9b77dcb994fe8b508,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 14c0d4a0e6ef4..74f1a1bd03e8a 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -29,6 +29,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/tensor.h""\n \n+#include <memory>\n #include <utility>\n \n #include ""absl/strings/escaping.h""\n@@ -1183,12 +1184,10 @@ void PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n }\n \n template <typename T>\n-string SummarizeArray(int64_t limit, int64_t num_elts,\n-                      const TensorShape& tensor_shape, const char* data,\n-                      const bool print_v2) {\n+string SummarizeArrayInternal(int64_t limit, int64_t num_elts,\n+                              const TensorShape& tensor_shape, const T* array,\n+                              const bool print_v2) {\n   string ret;\n-  const T* array = reinterpret_cast<const T*>(data);\n-\n   const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n   if (shape.empty()) {\n     for (int64_t i = 0; i < limit; ++i) {\n@@ -1211,6 +1210,29 @@ string SummarizeArray(int64_t limit, int64_t num_elts,\n \n   return ret;\n }\n+\n+template <typename T>\n+string SummarizeArray(int64_t limit, int64_t num_elts,\n+                      const TensorShape& tensor_shape, const char* data,\n+                      const bool print_v2) {\n+  const T* array = reinterpret_cast<const T*>(data);\n+  return SummarizeArrayInternal<T>(limit, num_elts, tensor_shape, array,\n+                                   print_v2);\n+}\n+\n+template <>\n+string SummarizeArray<bool>(int64_t limit, int64_t num_elts,\n+                            const TensorShape& tensor_shape, const char* data,\n+                            const bool print_v2) {\n+  // We first convert all chars to be 0/1 to not get InvalidEnumValue sanitizer\n+  // error\n+  auto mutable_data = std::unique_ptr<char[]>(new char[num_elts]);\n+  for (int64_t i = 0; i < num_elts; ++i)\n+    mutable_data.get()[i] = data[i] ? 1 : 0;\n+  bool* array = reinterpret_cast<bool*>(mutable_data.get());\n+  return SummarizeArrayInternal<bool>(limit, num_elts, tensor_shape, array,\n+                                      print_v2);\n+}\n }  // namespace\n \n string Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\n'","[""Resolve a sanitizer issue with invalid char -> bool conversion.\n\nWhen printing a tensor, we get it's data as a `const char*` array (since that's the underlying storage) and then we typecast it to the element type. However, conversions from `char` to `bool` are undefined if the `char` is not `0` or `1`, so sanitizers/fuzzers will crash.\n\nTo fix, we're creating a mutable `char` array to convert the chars to 0/1, according to bool rules.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482297563""]",[],2022-10-20 20:25:31
58199,"r2.9 cherry-pick: 1be74370327 ""Resolve a sanitizer issue with invalid char -> bool conversion.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/1be743703279782a357adbf9b77dcb994fe8b508,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 216df1799f288..ca3930e85ca90 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -29,6 +29,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/tensor.h""\n \n+#include <memory>\n #include <utility>\n \n #include ""absl/strings/escaping.h""\n@@ -1183,12 +1184,10 @@ void PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n }\n \n template <typename T>\n-string SummarizeArray(int64_t limit, int64_t num_elts,\n-                      const TensorShape& tensor_shape, const char* data,\n-                      const bool print_v2) {\n+string SummarizeArrayInternal(int64_t limit, int64_t num_elts,\n+                              const TensorShape& tensor_shape, const T* array,\n+                              const bool print_v2) {\n   string ret;\n-  const T* array = reinterpret_cast<const T*>(data);\n-\n   const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n   if (shape.empty()) {\n     for (int64_t i = 0; i < limit; ++i) {\n@@ -1211,6 +1210,29 @@ string SummarizeArray(int64_t limit, int64_t num_elts,\n \n   return ret;\n }\n+\n+template <typename T>\n+string SummarizeArray(int64_t limit, int64_t num_elts,\n+                      const TensorShape& tensor_shape, const char* data,\n+                      const bool print_v2) {\n+  const T* array = reinterpret_cast<const T*>(data);\n+  return SummarizeArrayInternal<T>(limit, num_elts, tensor_shape, array,\n+                                   print_v2);\n+}\n+\n+template <>\n+string SummarizeArray<bool>(int64_t limit, int64_t num_elts,\n+                            const TensorShape& tensor_shape, const char* data,\n+                            const bool print_v2) {\n+  // We first convert all chars to be 0/1 to not get InvalidEnumValue sanitizer\n+  // error\n+  auto mutable_data = std::unique_ptr<char[]>(new char[num_elts]);\n+  for (int64_t i = 0; i < num_elts; ++i)\n+    mutable_data.get()[i] = data[i] ? 1 : 0;\n+  bool* array = reinterpret_cast<bool*>(mutable_data.get());\n+  return SummarizeArrayInternal<bool>(limit, num_elts, tensor_shape, array,\n+                                      print_v2);\n+}\n }  // namespace\n \n string Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\n'","[""Resolve a sanitizer issue with invalid char -> bool conversion.\n\nWhen printing a tensor, we get it's data as a `const char*` array (since that's the underlying storage) and then we typecast it to the element type. However, conversions from `char` to `bool` are undefined if the `char` is not `0` or `1`, so sanitizers/fuzzers will crash.\n\nTo fix, we're creating a mutable `char` array to convert the chars to 0/1, according to bool rules.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482297563""]",[],2022-10-20 20:25:09
58198,"r2.11 cherry-pick: a65411a1d69 ""Fix OOB write in grappler.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a65411a1d69edfb16b25907ffb8f73556ce36bb7,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/grappler/utils/functions.cc b/tensorflow/core/grappler/utils/functions.cc\nindex 8868465352f15..4620886868cf9 100644\n--- a/tensorflow/core/grappler/utils/functions.cc\n+++ b/tensorflow/core/grappler/utils/functions.cc\n@@ -291,6 +291,11 @@ Status MakeGrapplerFunctionItem(const FunctionDef& func,\n \n   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);\n   for (const auto& attr : func.arg_attr()) {\n+    if (attr.first >= inputs.size()) {\n+      return errors::InvalidArgument(""Invalid attribute index, got "",\n+                                     attr.first, "" but expected less than "",\n+                                     inputs.size());\n+    }\n     arg_attr.at(attr.first) = &attr.second;\n   }\n \n'",['Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391'],[],2022-10-20 20:24:58
58197,"r2.10 cherry-pick: a65411a1d69 ""Fix OOB write in grappler.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a65411a1d69edfb16b25907ffb8f73556ce36bb7,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/grappler/utils/functions.cc b/tensorflow/core/grappler/utils/functions.cc\nindex 8868465352f15..4620886868cf9 100644\n--- a/tensorflow/core/grappler/utils/functions.cc\n+++ b/tensorflow/core/grappler/utils/functions.cc\n@@ -291,6 +291,11 @@ Status MakeGrapplerFunctionItem(const FunctionDef& func,\n \n   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);\n   for (const auto& attr : func.arg_attr()) {\n+    if (attr.first >= inputs.size()) {\n+      return errors::InvalidArgument(""Invalid attribute index, got "",\n+                                     attr.first, "" but expected less than "",\n+                                     inputs.size());\n+    }\n     arg_attr.at(attr.first) = &attr.second;\n   }\n \n'",['Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391'],[],2022-10-20 20:24:55
58196,"r2.9 cherry-pick: a65411a1d69 ""Fix OOB write in grappler.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a65411a1d69edfb16b25907ffb8f73556ce36bb7,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/grappler/utils/functions.cc b/tensorflow/core/grappler/utils/functions.cc\nindex 4b647284f2955..2f9f53fb44cd5 100644\n--- a/tensorflow/core/grappler/utils/functions.cc\n+++ b/tensorflow/core/grappler/utils/functions.cc\n@@ -291,6 +291,11 @@ Status MakeGrapplerFunctionItem(const FunctionDef& func,\n \n   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);\n   for (const auto& attr : func.arg_attr()) {\n+    if (attr.first >= inputs.size()) {\n+      return errors::InvalidArgument(""Invalid attribute index, got "",\n+                                     attr.first, "" but expected less than "",\n+                                     inputs.size());\n+    }\n     arg_attr.at(attr.first) = &attr.second;\n   }\n \n'",['Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391'],[],2022-10-20 20:24:46
58195,"r2.8 cherry-pick: 1be74370327 ""Resolve a sanitizer issue with invalid char -> bool conversion.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/1be743703279782a357adbf9b77dcb994fe8b508,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex c7a08ee080804..7400651425bbb 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -29,6 +29,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/tensor.h""\n \n+#include <memory>\n #include <utility>\n \n #include ""absl/strings/escaping.h""\n@@ -1176,12 +1177,10 @@ void PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n }\n \n template <typename T>\n-string SummarizeArray(int64_t limit, int64_t num_elts,\n-                      const TensorShape& tensor_shape, const char* data,\n-                      const bool print_v2) {\n+string SummarizeArrayInternal(int64_t limit, int64_t num_elts,\n+                              const TensorShape& tensor_shape, const T* array,\n+                              const bool print_v2) {\n   string ret;\n-  const T* array = reinterpret_cast<const T*>(data);\n-\n   const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n   if (shape.empty()) {\n     for (int64_t i = 0; i < limit; ++i) {\n@@ -1204,6 +1203,29 @@ string SummarizeArray(int64_t limit, int64_t num_elts,\n \n   return ret;\n }\n+\n+template <typename T>\n+string SummarizeArray(int64_t limit, int64_t num_elts,\n+                      const TensorShape& tensor_shape, const char* data,\n+                      const bool print_v2) {\n+  const T* array = reinterpret_cast<const T*>(data);\n+  return SummarizeArrayInternal<T>(limit, num_elts, tensor_shape, array,\n+                                   print_v2);\n+}\n+\n+template <>\n+string SummarizeArray<bool>(int64_t limit, int64_t num_elts,\n+                            const TensorShape& tensor_shape, const char* data,\n+                            const bool print_v2) {\n+  // We first convert all chars to be 0/1 to not get InvalidEnumValue sanitizer\n+  // error\n+  auto mutable_data = std::unique_ptr<char[]>(new char[num_elts]);\n+  for (int64_t i = 0; i < num_elts; ++i)\n+    mutable_data.get()[i] = data[i] ? 1 : 0;\n+  bool* array = reinterpret_cast<bool*>(mutable_data.get());\n+  return SummarizeArrayInternal<bool>(limit, num_elts, tensor_shape, array,\n+                                      print_v2);\n+}\n }  // namespace\n \n string Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\n'","[""Resolve a sanitizer issue with invalid char -> bool conversion.\n\nWhen printing a tensor, we get it's data as a `const char*` array (since that's the underlying storage) and then we typecast it to the element type. However, conversions from `char` to `bool` are undefined if the `char` is not `0` or `1`, so sanitizers/fuzzers will crash.\n\nTo fix, we're creating a mutable `char` array to convert the chars to 0/1, according to bool rules.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482297563""]",[],2022-10-20 20:24:43
58194,"r2.10 cherry-pick: 1be74370327 ""Resolve a sanitizer issue with invalid char -> bool conversion.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/1be743703279782a357adbf9b77dcb994fe8b508,tensorflow-jenkins,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex d57424a9a3a82..15b5ee842963d 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -29,6 +29,7 @@ limitations under the License.\n \n #include ""tensorflow/core/framework/tensor.h""\n \n+#include <memory>\n #include <utility>\n \n #include ""absl/strings/escaping.h""\n@@ -1183,12 +1184,10 @@ void PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n }\n \n template <typename T>\n-string SummarizeArray(int64_t limit, int64_t num_elts,\n-                      const TensorShape& tensor_shape, const char* data,\n-                      const bool print_v2) {\n+string SummarizeArrayInternal(int64_t limit, int64_t num_elts,\n+                              const TensorShape& tensor_shape, const T* array,\n+                              const bool print_v2) {\n   string ret;\n-  const T* array = reinterpret_cast<const T*>(data);\n-\n   const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n   if (shape.empty()) {\n     for (int64_t i = 0; i < limit; ++i) {\n@@ -1211,6 +1210,29 @@ string SummarizeArray(int64_t limit, int64_t num_elts,\n \n   return ret;\n }\n+\n+template <typename T>\n+string SummarizeArray(int64_t limit, int64_t num_elts,\n+                      const TensorShape& tensor_shape, const char* data,\n+                      const bool print_v2) {\n+  const T* array = reinterpret_cast<const T*>(data);\n+  return SummarizeArrayInternal<T>(limit, num_elts, tensor_shape, array,\n+                                   print_v2);\n+}\n+\n+template <>\n+string SummarizeArray<bool>(int64_t limit, int64_t num_elts,\n+                            const TensorShape& tensor_shape, const char* data,\n+                            const bool print_v2) {\n+  // We first convert all chars to be 0/1 to not get InvalidEnumValue sanitizer\n+  // error\n+  auto mutable_data = std::unique_ptr<char[]>(new char[num_elts]);\n+  for (int64_t i = 0; i < num_elts; ++i)\n+    mutable_data.get()[i] = data[i] ? 1 : 0;\n+  bool* array = reinterpret_cast<bool*>(mutable_data.get());\n+  return SummarizeArrayInternal<bool>(limit, num_elts, tensor_shape, array,\n+                                      print_v2);\n+}\n }  // namespace\n \n string Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\n'","[""Resolve a sanitizer issue with invalid char -> bool conversion.\n\nWhen printing a tensor, we get it's data as a `const char*` array (since that's the underlying storage) and then we typecast it to the element type. However, conversions from `char` to `bool` are undefined if the `char` is not `0` or `1`, so sanitizers/fuzzers will crash.\n\nTo fix, we're creating a mutable `char` array to convert the chars to 0/1, according to bool rules.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482297563""]",[],2022-10-20 20:24:35
58193,"r2.11 cherry-pick: 34dadfa8b09 ""Pass HloToolOptions instead of ToolOptions to ConvertHloProtoToToolData""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/34dadfa8b093197133b47beb30a50a5a2ddfedb2,tensorflow-jenkins,[],[],"['bvandermoon', 'learning-to-play']","['bvandermoon', 'learning-to-play']",[],"b'diff --git a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc\nindex c97e9a521080d..9484c03b82eac 100644\n--- a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc\n+++ b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.cc\n@@ -130,51 +130,44 @@ static constexpr char kGraphTypeName[] = ""graph"";\n static constexpr char kShortTxtTypeName[] = ""short_txt"";\n static constexpr char kLongTxtTypeName[] = ""long_txt"";\n static constexpr char kDefaultFormatString[] = ""url"";\n-static constexpr int kDefaultWidth = 3;\n-static constexpr int kDefaultShowMetadata = 0;\n-static constexpr int kDefaultMergeFusion = 0;\n \n }  // namespace\n \n-StatusOr<GraphViewerParams> ParseGraphViewerParams(const ToolOptions& options) {\n+StatusOr<GraphViewerParams> ParseGraphViewerParams(\n+    const HloToolOptions& options) {\n   GraphViewerParams params;\n-  std::optional<std::string> type = GetParam<std::string>(options, ""type"");\n-  if (!type.has_value()) {\n+  if (!options.type.has_value()) {\n     return errors::InvalidArgument(""Graph viewer must provide a type option."");\n   }\n \n   // For graph type.\n-  if (type == kGraphTypeName) {\n-    params.type = type.value();\n-    if (std::optional<std::string> node_name =\n-            GetParam<std::string>(options, ""node_name"")) {\n-      params.node_name = node_name.value();\n+  if (options.type == kGraphTypeName) {\n+    params.type = options.type.value();\n+    if (options.node_name.has_value()) {\n+      params.node_name = options.node_name.value();\n     }\n \n-    params.graph_width =\n-        GetParamWithDefault<int>(options, ""graph_width"", kDefaultWidth);\n-    params.render_options.show_backend_config = GetParamWithDefault<int>(\n-        options, ""show_metadata"", kDefaultShowMetadata);\n-    params.render_options.show_fusion_subcomputations =\n-        !GetParamWithDefault<int>(options, ""merge_fusion"", kDefaultMergeFusion);\n-    params.format = GetRenderFormat(GetParamWithDefault<std::string>(\n-        options, ""format"", kDefaultFormatString));\n+    params.graph_width = options.graph_width;\n+    params.render_options.show_backend_config = options.show_metadata;\n+    params.render_options.show_fusion_subcomputations = !options.merge_fusion;\n+    params.format =\n+        GetRenderFormat(options.format.has_value() ? options.format.value()\n+                                                   : kDefaultFormatString);\n \n     return params;\n   }\n \n   // For txt type.\n-  if (type == kShortTxtTypeName || type == kLongTxtTypeName) {\n-    params.type = type.value();\n-    params.verbose = (type == kLongTxtTypeName);\n-    params.show_metadata =\n-        GetParamWithDefault(options, ""show_metadata"", kDefaultShowMetadata);\n+  if (options.type == kShortTxtTypeName || options.type == kLongTxtTypeName) {\n+    params.type = options.type.value();\n+    params.verbose = (options.type == kLongTxtTypeName);\n+    params.show_metadata = options.show_metadata;\n     return params;\n   }\n \n   // Unknown type.\n   return errors::InvalidArgument(""Unknown graph viewer type option: "",\n-                                 type.value());\n+                                 options.type.value());\n }\n \n xla::RenderedGraphFormat GetRenderFormat(const std::string& format_string) {\ndiff --git a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h\nindex e37e5de38719c..1b33d7de0e4a5 100644\n--- a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h\n+++ b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view.h\n@@ -43,7 +43,8 @@ struct GraphViewerParams {\n };\n \n // Parse tool options to get the parameters for graph viewer.\n-StatusOr<GraphViewerParams> ParseGraphViewerParams(const ToolOptions& options);\n+StatusOr<GraphViewerParams> ParseGraphViewerParams(\n+    const HloToolOptions& options);\n \n // Get graph render format.\n xla::RenderedGraphFormat GetRenderFormat(const std::string& format_string);\ndiff --git a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc\nindex ecba6d7f71b97..1a7e14968de27 100644\n--- a/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc\n+++ b/tensorflow/core/profiler/convert/hlo_proto_to_graph_view_test.cc\n@@ -35,8 +35,9 @@ TEST(GraphViewerParamsTest, GraphType) {\n   // Default for graph type.\n   ToolOptions options1;\n   options1[""type""] = ""graph"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params1,\n-                          ParseGraphViewerParams(options1));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params1,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)));\n   EXPECT_EQ(params1.type, ""graph"");\n   EXPECT_EQ(params1.node_name, """");\n   EXPECT_EQ(params1.graph_width, 3);\n@@ -52,8 +53,9 @@ TEST(GraphViewerParamsTest, GraphType) {\n   options2[""show_metadata""] = 1;\n   options2[""merge_fusion""] = 1;\n   options2[""format""] = ""html"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params2,\n-                          ParseGraphViewerParams(options2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params2,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)));\n   EXPECT_EQ(params2.type, ""graph"");\n   EXPECT_EQ(params2.node_name, ""fusion.111"");\n   EXPECT_EQ(params2.graph_width, 10);\n@@ -66,8 +68,9 @@ TEST(GraphViewerParamsTest, ShortTxtType) {\n   // Default for short txt type.\n   ToolOptions options1;\n   options1[""type""] = ""short_txt"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params1,\n-                          ParseGraphViewerParams(options1));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params1,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)));\n   EXPECT_EQ(params1.type, ""short_txt"");\n   EXPECT_EQ(params1.verbose, false);\n   EXPECT_EQ(params1.show_metadata, false);\n@@ -76,8 +79,9 @@ TEST(GraphViewerParamsTest, ShortTxtType) {\n   ToolOptions options2;\n   options2[""type""] = ""short_txt"";\n   options2[""show_metadata""] = 1;\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params2,\n-                          ParseGraphViewerParams(options2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params2,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)));\n   EXPECT_EQ(params2.type, ""short_txt"");\n   EXPECT_EQ(params2.verbose, false);\n   EXPECT_EQ(params2.show_metadata, true);\n@@ -87,8 +91,9 @@ TEST(GraphViewerParamsTest, LongTxtType) {\n   // Default for long txt type.\n   ToolOptions options1;\n   options1[""type""] = ""long_txt"";\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params1,\n-                          ParseGraphViewerParams(options1));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params1,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)));\n   EXPECT_EQ(params1.type, ""long_txt"");\n   EXPECT_EQ(params1.verbose, true);\n   EXPECT_EQ(params1.show_metadata, false);\n@@ -97,8 +102,9 @@ TEST(GraphViewerParamsTest, LongTxtType) {\n   ToolOptions options2;\n   options2[""type""] = ""long_txt"";\n   options2[""show_metadata""] = 1;\n-  TF_ASSERT_OK_AND_ASSIGN(GraphViewerParams params2,\n-                          ParseGraphViewerParams(options2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      GraphViewerParams params2,\n+      ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)));\n   EXPECT_EQ(params2.type, ""long_txt"");\n   EXPECT_EQ(params2.verbose, true);\n   EXPECT_EQ(params2.show_metadata, true);\n@@ -106,13 +112,13 @@ TEST(GraphViewerParamsTest, LongTxtType) {\n \n TEST(GraphViewerParamsTest, OtherTypes) {\n   ToolOptions options1;\n-  EXPECT_THAT(ParseGraphViewerParams(options1),\n+  EXPECT_THAT(ParseGraphViewerParams(ToolOptionsToHloToolOptions(options1)),\n               StatusIs(error::INVALID_ARGUMENT,\n                        HasSubstr(""Graph viewer must provide a type option"")));\n \n   ToolOptions options2;\n   options2[""type""] = ""abcd"";\n-  EXPECT_THAT(ParseGraphViewerParams(options2),\n+  EXPECT_THAT(ParseGraphViewerParams(ToolOptionsToHloToolOptions(options2)),\n               StatusIs(error::INVALID_ARGUMENT,\n                        HasSubstr(""Unknown graph viewer type option: abcd"")));\n }\ndiff --git a/tensorflow/core/profiler/convert/hlo_to_tools_data.cc b/tensorflow/core/profiler/convert/hlo_to_tools_data.cc\nindex 51bb2bdf17ecc..96d726e3a46ac 100644\n--- a/tensorflow/core/profiler/convert/hlo_to_tools_data.cc\n+++ b/tensorflow/core/profiler/convert/hlo_to_tools_data.cc\n@@ -66,7 +66,7 @@ StatusOr<std::string> ConvertHloProtoToMemoryViewer(\n }\n \n StatusOr<std::string> ConvertHloProtoToGraphViewer(\n-    const xla::HloProto& hlo_proto, const ToolOptions& options) {\n+    const xla::HloProto& hlo_proto, const HloToolOptions& options) {\n   TF_ASSIGN_OR_RETURN(GraphViewerParams params,\n                       ParseGraphViewerParams(options));\n   if (params.type == ""graph"") {\n@@ -83,10 +83,9 @@ StatusOr<std::string> ConvertHloProtoToGraphViewer(\n \n StatusOr<std::string> ConvertHloProtoToToolData(\n     const SessionSnapshot& session_snapshot, const absl::string_view tool_name,\n-    const ToolOptions& options) {\n+    const HloToolOptions& options) {\n   // <options> must provide a hlo module_name field to identify the HLO module.\n-  std::optional<std::string> hlo_module_name =\n-      GetParam<std::string>(options, ""module_name"");\n+  std::optional<std::string> hlo_module_name = options.module_name;\n   if (!hlo_module_name.has_value() || hlo_module_name->empty()) {\n     return errors::InvalidArgument(\n         ""Can not find HLO module name from options."");\ndiff --git a/tensorflow/core/profiler/convert/hlo_to_tools_data.h b/tensorflow/core/profiler/convert/hlo_to_tools_data.h\nindex 7f43c2df30c83..bede2f8a31604 100644\n--- a/tensorflow/core/profiler/convert/hlo_to_tools_data.h\n+++ b/tensorflow/core/profiler/convert/hlo_to_tools_data.h\n@@ -33,7 +33,7 @@ namespace profiler {\n // successful, else return an error status.\n StatusOr<std::string> ConvertHloProtoToToolData(\n     const SessionSnapshot& session_snapshot, const absl::string_view tool_name,\n-    const ToolOptions& options);\n+    const HloToolOptions& options);\n \n }  // namespace profiler\n }  // namespace tensorflow\ndiff --git a/tensorflow/core/profiler/convert/tool_options.h b/tensorflow/core/profiler/convert/tool_options.h\nindex c83491859063f..942e53779e37f 100644\n--- a/tensorflow/core/profiler/convert/tool_options.h\n+++ b/tensorflow/core/profiler/convert/tool_options.h\n@@ -25,6 +25,17 @@ limitations under the License.\n namespace tensorflow {\n namespace profiler {\n \n+// Tool options for HloProtoToToolData conversion.\n+struct HloToolOptions {\n+  std::optional<std::string> module_name;\n+  std::optional<std::string> type;\n+  std::optional<std::string> node_name;\n+  std::optional<std::string> format;\n+  int graph_width;\n+  bool show_metadata;\n+  bool merge_fusion;\n+};\n+\n using ToolOptions =\n     absl::flat_hash_map<std::string, std::variant<int, std::string>>;\n \n@@ -53,6 +64,20 @@ T GetParamWithDefault(const ToolOptions& options, const std::string& key,\n   return default_param;\n }\n \n+inline HloToolOptions ToolOptionsToHloToolOptions(const ToolOptions& options) {\n+  HloToolOptions hlo_options;\n+  hlo_options.module_name = GetParam<std::string>(options, ""module_name"");\n+  hlo_options.type = GetParam<std::string>(options, ""type"");\n+  hlo_options.node_name = GetParam<std::string>(options, ""node_name"");\n+  hlo_options.format = GetParam<std::string>(options, ""format"");\n+  hlo_options.graph_width = GetParamWithDefault<int>(options, ""graph_width"", 3);\n+  hlo_options.show_metadata =\n+      GetParamWithDefault<int>(options, ""show_metadata"", 0);\n+  hlo_options.merge_fusion =\n+      GetParamWithDefault<int>(options, ""merge_fusion"", 0);\n+  return hlo_options;\n+}\n+\n }  // namespace profiler\n }  // namespace tensorflow\n \ndiff --git a/tensorflow/core/profiler/convert/xplane_to_tools_data.cc b/tensorflow/core/profiler/convert/xplane_to_tools_data.cc\nindex 787287d010734..f5e6f78928602 100644\n--- a/tensorflow/core/profiler/convert/xplane_to_tools_data.cc\n+++ b/tensorflow/core/profiler/convert/xplane_to_tools_data.cc\n@@ -252,7 +252,8 @@ StatusOr<std::string> ConvertMultiXSpacesToToolData(\n   } else if (tool_name == ""op_profile"") {\n     return ConvertMultiXSpacesToOpProfileViewer(session_snapshot);\n   } else if (tool_name == ""memory_viewer"" || tool_name == ""graph_viewer"") {\n-    return ConvertHloProtoToToolData(session_snapshot, tool_name, options);\n+    return ConvertHloProtoToToolData(session_snapshot, tool_name,\n+                                     ToolOptionsToHloToolOptions(options));\n   } else if (tool_name == ""tool_names"") {\n     return GetAvailableToolNames(session_snapshot);\n   } else if (tool_name == ""_xplane.pb"") {  // internal test only.\n'",['Pass HloToolOptions instead of ToolOptions to ConvertHloProtoToToolData\n\nPiperOrigin-RevId: 482033483'],[],2022-10-20 17:32:43
58187,Removed merge conflict marker,"Hi!

I was trying to compile r2.9 from source and the compiler found this merge conflict marker still in `execute.cc` which was causing compilation to fail. As far as I can see the other merge conflict markers had been removed but this one was still there.

Any questions or comments please let me know!
    
Jamie",JamieLine,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex 04c508ed52e79..73a45e18a084a 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -321,7 +321,6 @@ bool IsHostMemoryArg(const EagerOperation& op, const NodeDef* node_def,\n Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n                          const bool is_host_memory_arg,\n                          TensorHandle* tensor_handle, Device** result) {\n->>>>>>> f5381e0e10b (Fix OOB error when op input sizes do not match.)\n   Device* cpu_device = ctx.HostCPU();\n   string device_name;\n   if (tensor_handle->Type() != TensorHandle::LOCAL) {\n'",['Removed merge conflict marker'],[],2022-10-20 13:39:54
58185,Remove outdated docs re: Arduino Library Manager installation,"For some years, Arduino maintained a TensorFlow Lite Micro mirror packaged as a standalone Arduino library named ""**Arduino_TensorFlowLite**"". This allowed the library to be distributed via [the Arduino Library Manager system](https://docs.arduino.cc/software/ide-v2/tutorials/ide-v2-installing-a-library#installing-a-library).

The maintainers of [the official `tensorflow/tflite-micro-arduino-examples` repository](https://github.com/tensorflow/tflite-micro-arduino-examples) recently requested that library be removed from the Arduino Library Manager (https://github.com/arduino/library-registry/pull/1748). For this reason, it is no longer possible to install the library via Library Manager. The library should now be installed following the official instructions here:

https://github.com/tensorflow/tflite-micro-arduino-examples#how-to-install",per1234,[],[],['sirakiin'],['sirakiin'],['gbaned'],"b""diff --git a/tensorflow/lite/g3doc/microcontrollers/library.md b/tensorflow/lite/g3doc/microcontrollers/library.md\nindex 4b24a72a931e4..ed0047788a9e2 100644\n--- a/tensorflow/lite/g3doc/microcontrollers/library.md\n+++ b/tensorflow/lite/g3doc/microcontrollers/library.md\n@@ -60,7 +60,7 @@ instructions in this section.\n ### Use the Arduino library\n \n If you are using Arduino, the *Hello World* example is included in the\n-`Arduino_TensorFlowLite` Arduino library, which you can download from the\n+`Arduino_TensorFlowLite` Arduino library, which you can manually install in the\n Arduino IDE and in [Arduino Create](https://create.arduino.cc/).\n \n Once the library has been added, go to `File -> Examples`. You should see an\n@@ -169,9 +169,6 @@ encourage pull requests for new optimized implementations.\n \n ## Generate the Arduino library\n \n-A nightly build of the Arduino library is available via the Arduino IDE's\n-library manager.\n-\n If you need to generate a new build of the library, you can run the following\n script from the TensorFlow repository:\n \n""","['Remove outdated docs re: Arduino Library Manager installation\n\nFor some years, Arduino maintained a TensorFlow Lite Micro mirror packaged as a standalone Arduino library named\r\n""Arduino_TensorFlowLite"". This allowed the library to be distributed via the Arduino Library Manager system.\r\n\r\nThe maintainers of the official tensorflow/tflite-micro-arduino-examples repository recently requested that library be\r\nremoved from the Arduino Library Manager. For this reason, it is no longer possible to install the library via Library\r\nManager. The library should now be installed following the official instructions here:\r\n\r\nhttps://github.com/tensorflow/tflite-micro-arduino-examples#how-to-install']",[],2022-10-20 11:11:00
58182,Dev n1to1 a," Fix ReLUN1To1 fused activation for OpenCL and OpenGL

The ReLUN1To1 op was repurposed from the a ReLU1 op. However it was not fully reimplemented. As a result it clipped to a minimum of 0 instead of -1.

Add a left clip attribute, lclip, to the ReLU implementation. Set to -1 for ReLUN1To1 and 0 for all other ReLUs.",CaveMike,['sirakiin'],['@roserg Could you help review this change? Thanks!'],[],[],['gbaned'],"b'diff --git a/tensorflow/lite/delegates/gpu/cl/BUILD b/tensorflow/lite/delegates/gpu/cl/BUILD\nindex 9a42d9bb4553a..240d7cd91421c 100644\n--- a/tensorflow/lite/delegates/gpu/cl/BUILD\n+++ b/tensorflow/lite/delegates/gpu/cl/BUILD\n@@ -123,6 +123,7 @@ cc_test(\n     ],\n     deps = [\n         "":buffer"",\n+        "":cl_test"",\n         "":cl_arguments"",\n         "":gpu_object"",\n         ""//tensorflow/lite/delegates/gpu/common:gpu_info"",\ndiff --git a/tensorflow/lite/delegates/gpu/cl/cl_arguments_test.cc b/tensorflow/lite/delegates/gpu/cl/cl_arguments_test.cc\nindex 2a46c202286dd..dc652d01e1f2e 100644\n--- a/tensorflow/lite/delegates/gpu/cl/cl_arguments_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/cl_arguments_test.cc\n@@ -23,6 +23,7 @@ limitations under the License.\n #include ""tensorflow/lite/delegates/gpu/cl/buffer.h""\n #include ""tensorflow/lite/delegates/gpu/cl/gpu_object.h""\n #include ""tensorflow/lite/delegates/gpu/common/gpu_info.h""\n+#include ""tensorflow/lite/delegates/gpu/cl/cl_test.h""\n \n namespace tflite {\n namespace gpu {\n@@ -45,7 +46,7 @@ __kernel void main_function($0) {\n \n   CLArguments cl_args;\n   GpuInfo gpu_info;\n-  ASSERT_OK(cl_args.Init(gpu_info, {}, nullptr, &args, &sample_code));\n+  ASSERT_OK(cl_args.Init(gpu_info, nullptr, &args, &sample_code));\n   EXPECT_TRUE(absl::StrContains(sample_code, ""value = weights_buffer[id];""));\n   EXPECT_TRUE(\n       absl::StrContains(sample_code, ""__global float4* weights_buffer""));\n@@ -67,7 +68,7 @@ TEST(CLArgumentsTest, TestNoSelector) {\n )"";\n   CLArguments cl_args;\n   GpuInfo gpu_info;\n-  EXPECT_FALSE(cl_args.Init(gpu_info, {}, nullptr, &args, &sample_code).ok());\n+  EXPECT_FALSE(cl_args.Init(gpu_info, nullptr, &args, &sample_code).ok());\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/BUILD b/tensorflow/lite/delegates/gpu/cl/kernels/BUILD\nindex 983b0e90119bc..3ba6e4537537a 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/BUILD\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/BUILD\n@@ -40,8 +40,14 @@ cc_test(\n         ""//tensorflow/lite/delegates/gpu/common:operations"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n         ""//tensorflow/lite/delegates/gpu/common/tasks:cast_test_util"",\n-        ""@com_google_googletest//:gtest_main"",\n-    ],\n+    ] + select({\n+        ""//tensorflow:android"": [\n+            ""@com_google_googletest//:gtest_main"",\n+        ],\n+        ""//conditions:default"": [\n+            ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n+        ],\n+    })\n )\n \n cc_library(\n@@ -56,8 +62,14 @@ cc_library(\n         ""//tensorflow/lite/delegates/gpu/cl:tensor"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n         ""//tensorflow/lite/delegates/gpu/common/task:testing_util"",\n-        ""@com_google_googletest//:gtest"",\n-    ],\n+        ] + select({\n+            ""//tensorflow:android"": [\n+                ""@com_google_googletest//:gtest_main"",\n+            ],\n+            ""//conditions:default"": [\n+                ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n+            ],\n+        }),\n )\n \n cc_test(\n@@ -74,8 +86,14 @@ cc_test(\n         ""//tensorflow/lite/delegates/gpu/common:operations"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n         ""//tensorflow/lite/delegates/gpu/common/tasks:concat_test_util"",\n-        ""@com_google_googletest//:gtest_main"",\n-    ],\n+        ] + select({\n+            ""//tensorflow:android"": [\n+                ""@com_google_googletest//:gtest_main"",\n+            ],\n+            ""//conditions:default"": [\n+                ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n+            ],\n+        }),\n )\n \n cc_test(\n@@ -92,8 +110,14 @@ cc_test(\n         ""//tensorflow/lite/delegates/gpu/common:operations"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n         ""//tensorflow/lite/delegates/gpu/common/tasks:conv_constants_test_util"",\n-        ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n-    ],\n+    ] + select({\n+        ""//tensorflow:android"": [\n+            ""@com_google_googletest//:gtest_main"",\n+        ],\n+        ""//conditions:default"": [\n+            ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n+        ],\n+    })\n )\n \n cc_test(\n@@ -207,8 +231,14 @@ cc_test(\n         ""//tensorflow/lite/delegates/gpu/common:operations"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n         ""//tensorflow/lite/delegates/gpu/common/tasks:convolution_transposed_3x3_thin_test_util"",\n-        ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n-    ],\n+        ] + select({\n+            ""//tensorflow:android"": [\n+                ""@com_google_googletest//:gtest_main"",\n+            ],\n+            ""//conditions:default"": [\n+                ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n+            ],\n+        })\n )\n \n cc_test(\n@@ -243,8 +273,14 @@ cc_test(\n         ""//tensorflow/lite/delegates/gpu/common:operations"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n         ""//tensorflow/lite/delegates/gpu/common/tasks:convolution_transposed_thin_test_util"",\n-        ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n-    ],\n+        ] + select({\n+            ""//tensorflow:android"": [\n+                ""@com_google_googletest//:gtest_main"",\n+            ],\n+            ""//conditions:default"": [\n+                ""@com_google_googletest//:gtest_main_no_heapcheck"",  # constant buffers leak on nvidia\n+            ],\n+        })\n )\n \n cc_test(\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/add_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/add_test.cc\nindex f1532b2eeee66..2e867a6ce4b4b 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/add_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/add_test.cc\n@@ -29,17 +29,17 @@ namespace {\n \n TEST_F(OpenCLOperationTest, AddTwoEqualTensors) {\n   auto status = AddTwoEqualTensorsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, AddFirstTensorHasMoreChannelsThanSecond) {\n   auto status = AddFirstTensorHasMoreChannelsThanSecondTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, AddFirstTensorHasLessChannelsThanSecond) {\n   auto status = AddFirstTensorHasLessChannelsThanSecond(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/cast_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/cast_test.cc\nindex 60755c480fe35..3728cc855d51d 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/cast_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/cast_test.cc\n@@ -27,17 +27,17 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Cast) {\n   auto status = CastTests(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, CastToBool) {\n   auto status = CastToBoolTests(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, CastFromBool) {\n   auto status = CastFromBoolTests(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/cl_test.h b/tensorflow/lite/delegates/gpu/cl/kernels/cl_test.h\nindex 91413a0101a5d..2ee3641e887b3 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/cl_test.h\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/cl_test.h\n@@ -30,6 +30,10 @@ namespace tflite {\n namespace gpu {\n namespace cl {\n \n+#ifndef ASSERT_OK\n+#define ASSERT_OK(x) ASSERT_TRUE(x.ok());\n+#endif\n+\n class ClExecutionEnvironment : public TestExecutionEnvironment {\n  public:\n   ClExecutionEnvironment() = default;\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/concat_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/concat_test.cc\nindex 3ccf52d7ad29a..e2f0efe3c2bb2 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/concat_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/concat_test.cc\n@@ -29,22 +29,22 @@ namespace {\n \n TEST_F(OpenCLOperationTest, ConcatWidth) {\n   auto status = ConcatWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConcatHeight) {\n   auto status = ConcatHeightTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConcatChannels) {\n   auto status = ConcatChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConcatChannelsAlignedx4) {\n   auto status = ConcatChannelsAlignedx4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/conv_constants_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/conv_constants_test.cc\nindex bca987ae93f8e..78488e404cfa7 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/conv_constants_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/conv_constants_test.cc\n@@ -26,12 +26,12 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, ConvConstantsSimpleWeights) {\n   const auto status = ConvConstantsSimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConvConstants) {\n   const auto status = ConvConstantsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/conv_generic_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/conv_generic_test.cc\nindex 5a73ee864e56d..9c3b511c736eb 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/conv_generic_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/conv_generic_test.cc\n@@ -28,27 +28,27 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, ConvGeneric1x1SimpleWeights) {\n   const auto status = ConvGeneric1x1SimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConvGeneric1x1) {\n   const auto status = ConvGeneric1x1Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConvGenericSimpleWeights) {\n   const auto status = ConvGenericSimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConvGeneric) {\n   const auto status = ConvGenericTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConvGenericGrouped) {\n   const auto status = ConvGenericGroupedTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/conv_weights_converter_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/conv_weights_converter_test.cc\nindex cddac9aadcb6e..a2c88c3188119 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/conv_weights_converter_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/conv_weights_converter_test.cc\n@@ -28,32 +28,32 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, ConverterToConvWeights1x1OutX4) {\n   const auto status = ConverterToConvWeights1x1OutX4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConverterToConvWeights1x1OutX4Unaligned) {\n   const auto status = ConverterToConvWeights1x1OutX4UnalignedTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConverterToConvWeights1x1OutX2) {\n   const auto status = ConverterToConvWeights1x1OutX2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConverterToConvWeightsOutX2) {\n   const auto status = ConverterToConvWeightsOutX2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConverterToConvTransposedWeights4x4) {\n   const auto status = ConverterToConvTransposedWeights4x4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConverterToConvWeights4xTextures) {\n   const auto status = ConverterToConvWeights4xTexturesTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/convolution_transposed_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/convolution_transposed_test.cc\nindex 8affdbcc1f06f..4ea411b018f0a 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/convolution_transposed_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/convolution_transposed_test.cc\n@@ -29,12 +29,12 @@ namespace {\n \n TEST_F(OpenCLOperationTest, ConvolutionTransposedSimpleWeights) {\n   auto status = ConvolutionTransposedSimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ConvolutionTransposed) {\n   auto status = ConvolutionTransposedTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/cumsum_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/cumsum_test.cc\nindex f7b0f97ce0cf9..630d0eb8834c1 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/cumsum_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/cumsum_test.cc\n@@ -24,12 +24,12 @@ namespace {\n \n TEST_F(OpenCLOperationTest, CumsumHWCTest) {\n   absl::Status status = CumsumHWCTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, CumsumBHWCTest) {\n   absl::Status status = CumsumBHWCTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n }  // namespace\n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_3x3_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_3x3_test.cc\nindex 04c9ac4cdd52e..a3976aaa2d7e3 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_3x3_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_3x3_test.cc\n@@ -30,17 +30,17 @@ namespace {\n \n TEST_F(OpenCLOperationTest, DepthwiseConv3x3SimpleWeights) {\n   auto status = DepthwiseConv3x3SimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, DepthwiseConv3x3) {\n   auto status = DepthwiseConv3x3Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, DepthWiseConv3x3StrideH2SimpleWeights) {\n   auto status = DepthWiseConv3x3StrideH2SimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_test.cc\nindex cbcfeabdadc5b..1bb0f35ab16a7 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/depthwise_conv_test.cc\n@@ -29,17 +29,17 @@ namespace {\n \n TEST_F(OpenCLOperationTest, DepthwiseConvSimpleWeights) {\n   auto status = DepthwiseConvSimpleWeightsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, DepthwiseConvNoMultiplier) {\n   auto status = DepthwiseConvNoMultiplierTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, DepthwiseConvMultiplier2) {\n   auto status = DepthwiseConvMultiplier2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/elementwise_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/elementwise_test.cc\nindex 307ffb7364d1b..436f914c4087e 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/elementwise_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/elementwise_test.cc\n@@ -29,217 +29,217 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Abs) {\n   auto status = AbsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Cos) {\n   auto status = CosTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Copy) {\n   auto status = CopyTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Elu) {\n   auto status = EluTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Exp) {\n   auto status = ExpTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Floor) {\n   auto status = FloorTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, FloorDiv) {\n   auto status = FloorDivTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, FloorMod) {\n   auto status = FloorModTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, HardSwish) {\n   auto status = HardSwishTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Log) {\n   auto status = LogTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Neg) {\n   auto status = NegTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Rsqrt) {\n   auto status = RsqrtTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Sigmoid) {\n   auto status = SigmoidTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Sin) {\n   auto status = SinTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Sqrt) {\n   auto status = SqrtTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Square) {\n   auto status = SquareTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Tanh) {\n   auto status = TanhTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Sub) {\n   auto status = SubTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SquaredDiff) {\n   auto status = SquaredDiffTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Div) {\n   auto status = DivTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Pow) {\n   auto status = PowTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Add) {\n   auto status = AddTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Maximum) {\n   auto status = MaximumTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaximumWithScalar) {\n   auto status = MaximumWithScalarTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaximumWithConstantLinearTensor) {\n   auto status = MaximumWithConstantLinearTensorTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaximumWithConstantHWCTensor) {\n   auto status = MaximumWithConstantHWCTensorTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaximumWithConstantHWCTensorBroadcastChannels) {\n   auto status = MaximumWithConstantHWCTensorBroadcastChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Minimum) {\n   auto status = MinimumTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MinimumWithScalar) {\n   auto status = MinimumWithScalarTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Mul) {\n   auto status = MulTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MulBroadcastHW) {\n   auto status = MulBroadcastHWTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MulBroadcastChannels) {\n   auto status = MulBroadcastChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SubWithScalarAtFirstPosition) {\n   auto status = SubWithScalarAtFirstPositionTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Less) {\n   auto status = LessTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, LessEqual) {\n   auto status = LessEqualTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Greater) {\n   auto status = GreaterTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, GreaterEqual) {\n   auto status = GreaterEqualTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Equal) {\n   auto status = EqualTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, NotEqual) {\n   auto status = NotEqualTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, CosBroadcast) {\n   auto status = CosBroadcastTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaximumScalarBroadcastInput) {\n   auto status = MaximumScalarBroadcastInputTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MulLinearBroadcastInput) {\n   auto status = MulLinearBroadcastInputTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MulBroadcastBothInputs) {\n   auto status = MulBroadcastBothInputsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/fully_connected_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/fully_connected_test.cc\nindex 58a4ce64f6133..551cdc4e1b162 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/fully_connected_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/fully_connected_test.cc\n@@ -37,22 +37,22 @@ namespace {\n \n TEST_F(OpenCLOperationTest, FullyConnected) {\n   auto status = FullyConnectedTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, FullyConnectedLarge) {\n   auto status = FullyConnectedLargeTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, FullyConnectedExtraLarge) {\n   auto status = FullyConnectedExtraLargeTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, FullyConnectedInt8) {\n   auto status = FullyConnectedInt8Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, RearrageWeights) {\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/gather_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/gather_test.cc\nindex 04bcebd4f4757..297a2af70fce5 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/gather_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/gather_test.cc\n@@ -26,7 +26,7 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, GatherWidth) {\n   auto status = GatherWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/lstm_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/lstm_test.cc\nindex 264bf9cfcc723..3676694660166 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/lstm_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/lstm_test.cc\n@@ -30,7 +30,7 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, LSTM) {\n   auto status = LstmTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/max_unpooling_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/max_unpooling_test.cc\nindex e30372a153a1c..5515d7975ff06 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/max_unpooling_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/max_unpooling_test.cc\n@@ -29,7 +29,7 @@ namespace {\n \n TEST_F(OpenCLOperationTest, MaxUnpooling) {\n   auto status = MaxUnpoolingTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/mean_stddev_normalization_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/mean_stddev_normalization_test.cc\nindex e4ba67abe954e..452e89b3134bc 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/mean_stddev_normalization_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/mean_stddev_normalization_test.cc\n@@ -31,54 +31,54 @@ namespace {\n TEST_F(OpenCLOperationTest, MeanStddevNormSeparateBatches) {\n   // zero mean, zero variance\n   auto status = MeanStddevNormSeparateBatchesTest(0.0f, 0.0f, 0.0f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // zero mean, small variance\n   status = MeanStddevNormSeparateBatchesTest(0.0f, 0.01f, 2.63e-4f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // zero mean, large variance\n   status =\n       MeanStddevNormSeparateBatchesTest(0.0f, 100.0f, 2.63e-4f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // small mean, zero variance\n   status = MeanStddevNormSeparateBatchesTest(0.01f, 0.0f, 0.0f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // small mean, small variance\n   status =\n       MeanStddevNormSeparateBatchesTest(0.01f, 0.01f, 3.57e-4f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // small mean, large variance\n   status =\n       MeanStddevNormSeparateBatchesTest(1.0f, 100.0f, 2.63e-4f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // large mean, zero variance\n   status = MeanStddevNormSeparateBatchesTest(100.0f, 0.0f, 0.0f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // large mean, small variance\n   status =\n       MeanStddevNormSeparateBatchesTest(100.0f, 1.0f, 2.63e-4f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   // large mean, large variance\n   status =\n       MeanStddevNormSeparateBatchesTest(100.0f, 100.0f, 2.63e-4f, &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MeanStddevNormalizationAllBatches) {\n   auto status = MeanStddevNormalizationAllBatchesTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MeanStddevNormalizationLargeVector) {\n   auto status = MeanStddevNormalizationLargeVectorTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/one_hot_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/one_hot_test.cc\nindex 736ec74d412e5..abd33ba82449c 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/one_hot_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/one_hot_test.cc\n@@ -27,12 +27,12 @@ namespace {\n \n TEST_F(OpenCLOperationTest, OneHot) {\n   auto status = OneHotTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, OneHotBatch) {\n   auto status = OneHotBatchTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/padding_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/padding_test.cc\nindex f40513e014cd2..7b77316ba64c7 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/padding_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/padding_test.cc\n@@ -29,52 +29,52 @@ namespace {\n \n TEST_F(OpenCLOperationTest, PaddingAppendWidth) {\n   auto status = PaddingAppendWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingPrependWidth) {\n   auto status = PaddingPrependWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingAppendHeight) {\n   auto status = PaddingAppendHeightTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingPrependHeight) {\n   auto status = PaddingPrependHeightTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingAppendChannels) {\n   auto status = PaddingAppendChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingPrependChannels) {\n   auto status = PaddingPrependChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingPrependChannelsX4) {\n   auto status = PaddingPrependChannelsX4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingComplex) {\n   auto status = PaddingComplexTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingReflectWidth) {\n   auto status = PaddingReflectWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PaddingReflectChannels) {\n   auto status = PaddingReflectChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/pooling_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/pooling_test.cc\nindex 6a1f9b3d27b7f..669fee0d679a9 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/pooling_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/pooling_test.cc\n@@ -29,22 +29,22 @@ namespace {\n \n TEST_F(OpenCLOperationTest, AveragePooling) {\n   auto status = AveragePoolingTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, AveragePoolingNonEmptyPadding) {\n   auto status = AveragePoolingNonEmptyPaddingTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaxPooling) {\n   auto status = MaxPoolingTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, MaxPoolingIndices) {\n   auto status = MaxPoolingIndicesTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/prelu_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/prelu_test.cc\nindex e19f7992baf69..ea1aacf50a44c 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/prelu_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/prelu_test.cc\n@@ -29,12 +29,12 @@ namespace {\n \n TEST_F(OpenCLOperationTest, PReLUAlpha) {\n   auto status = PReLUAlphaTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, PReLUHWCAlpha) {\n   auto status = PReLUHWCAlphaTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/quantize_and_dequantize_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/quantize_and_dequantize_test.cc\nindex 8e66ffa44e5fa..6406dd5e2b331 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/quantize_and_dequantize_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/quantize_and_dequantize_test.cc\n@@ -29,22 +29,22 @@ namespace {\n \n TEST_F(OpenCLOperationTest, QuantAndDequant_Dim2Bits8) {\n   auto status = QuantAndDequant_Dim2Bits8Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, QuantAndDequant_Dim3Bits8_NegativeRange) {\n   auto status = QuantAndDequant_Dim3Bits8_NegativeRangeTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, QuantAndDequant_Dim3Bits16) {\n   auto status = QuantAndDequant_Dim3Bits16Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, QuantAndDequant_Dim2Bits16_NegativeRange) {\n   auto status = QuantAndDequant_Dim2Bits16_NegativeRangeTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/reduce_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/reduce_test.cc\nindex 148b9159f04b3..2fd03cc69f615 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/reduce_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/reduce_test.cc\n@@ -29,27 +29,27 @@ namespace {\n \n TEST_F(OpenCLOperationTest, MeanHW) {\n   auto status = MeanHWTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReduceSumChannels) {\n   auto status = ReduceSumChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReduceProductChannels) {\n   auto status = ReduceProductChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReduceMaxChannels) {\n   auto status = ReduceMaxChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReduceMinChannels) {\n   auto status = ReduceMinChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/relu_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/relu_test.cc\nindex b7a113666c60b..d1d88e468b2d9 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/relu_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/relu_test.cc\n@@ -28,22 +28,42 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, ReLUNoClipNoAlpha) {\n   auto status = ReLUNoClipNoAlphaTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReLUClip) {\n   auto status = ReLUClipTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReLUAlpha) {\n   auto status = ReLUAlphaTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ReLUAlphaClip) {\n   auto status = ReLUAlphaClipTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n+}\n+\n+TEST_F(OpenCLOperationTest, ReLULClipNoAlphaNoClip) {\n+  auto status = ReLULClipNoAlphaNoClipTest(&exec_env_);\n+  ASSERT_TRUE(status.ok()) << status;\n+}\n+\n+TEST_F(OpenCLOperationTest, ReLUAlphaLClipNoClip) {\n+  auto status = ReLUAlphaLClipNoClipTest(&exec_env_);\n+  ASSERT_TRUE(status.ok()) << status;\n+}\n+\n+TEST_F(OpenCLOperationTest, ReLULClipClipNoAlpha) {\n+  auto status = ReLULClipClipNoAlphaTest(&exec_env_);\n+  ASSERT_TRUE(status.ok()) << status;\n+}\n+\n+TEST_F(OpenCLOperationTest, ReLUAlphaLClipClip) {\n+  auto status = ReLUAlphaLClipClipTest(&exec_env_);\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/resampler_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/resampler_test.cc\nindex 9b88427cbace8..448f8c1642277 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/resampler_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/resampler_test.cc\n@@ -28,13 +28,13 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, ResamplerIdentity) {\n   auto status = ResamplerIdentityTest(BHWC(1, 2, 2, 1), &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   status = ResamplerIdentityTest(BHWC(1, 3, 5, 3), &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n \n   status = ResamplerIdentityTest(BHWC(1, 6, 1, 7), &exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/reshape_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/reshape_test.cc\nindex 4949a18c2a3eb..1c2c9e0afea6a 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/reshape_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/reshape_test.cc\n@@ -29,7 +29,7 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Reshape) {\n   auto status = ReshapeTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/reshapex4_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/reshapex4_test.cc\nindex bb1db97e660ec..91e4112cfb2b0 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/reshapex4_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/reshapex4_test.cc\n@@ -29,7 +29,7 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Reshapex4) {\n   auto status = Reshapex4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/resize_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/resize_test.cc\nindex 72004bea0a89d..336b4575fbbe3 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/resize_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/resize_test.cc\n@@ -29,37 +29,37 @@ namespace {\n \n TEST_F(OpenCLOperationTest, ResizeBilinearAligned) {\n   auto status = ResizeBilinearAlignedTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ResizeBilinearNonAligned) {\n   auto status = ResizeBilinearNonAlignedTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ResizeBilinearWithoutHalfPixel) {\n   auto status = ResizeBilinearWithoutHalfPixelTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ResizeBilinearWithHalfPixel) {\n   auto status = ResizeBilinearWithHalfPixelTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ResizeNearest) {\n   auto status = ResizeNearestTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ResizeNearestAlignCorners) {\n   auto status = ResizeNearestAlignCornersTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, ResizeNearestHalfPixelCenters) {\n   auto status = ResizeNearestHalfPixelCentersTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/select_v2_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/select_v2_test.cc\nindex 6c7d0d94ebaeb..499afa1b0494c 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/select_v2_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/select_v2_test.cc\n@@ -24,42 +24,42 @@ namespace {\n \n TEST_F(OpenCLOperationTest, SelectV2) {\n   auto status = SelectV2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2Batch) {\n   auto status = SelectV2BatchTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2Channels) {\n   auto status = SelectV2ChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2ChannelsBatch) {\n   auto status = SelectV2ChannelsBatchTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2BroadcastTrue) {\n   auto status = SelectV2BroadcastTrueTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2BroadcastFalse) {\n   auto status = SelectV2BroadcastFalseTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2BroadcastBoth) {\n   auto status = SelectV2BroadcastBothTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SelectV2ChannelsBroadcastFalse) {\n   auto status = SelectV2ChannelsBroadcastFalseTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/softmax1x1_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/softmax1x1_test.cc\nindex 9e9fe082e4e37..9bb795b8b1382 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/softmax1x1_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/softmax1x1_test.cc\n@@ -29,12 +29,12 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Softmax1x1) {\n   auto status = Softmax1x1Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Softmax1x1BigNumber) {\n   auto status = Softmax1x1BigNumberTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/softmax_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/softmax_test.cc\nindex b5466343c6c37..d45ec8ccd979a 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/softmax_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/softmax_test.cc\n@@ -29,12 +29,12 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Softmax) {\n   auto status = SoftmaxTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SoftmaxBigNumber) {\n   auto status = SoftmaxBigNumberTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth_test.cc\nindex e1b31bcb6608c..c675dc7a9c811 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth_test.cc\n@@ -29,22 +29,22 @@ namespace {\n // 5xxs.\n TEST_F(OpenCLOperationTest, SpaceToDepthTensorShape1x2x2x1BlockSize2) {\n   auto status = SpaceToDepthTensorShape1x2x2x1BlockSize2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SpaceToDepthTensorShape1x2x2x2BlockSize2) {\n   auto status = SpaceToDepthTensorShape1x2x2x2BlockSize2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SpaceToDepthTensorShape1x2x2x3BlockSize2) {\n   auto status = SpaceToDepthTensorShape1x2x2x3BlockSize2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SpaceToDepthTensorShape1x4x4x1BlockSize2) {\n   auto status = SpaceToDepthTensorShape1x4x4x1BlockSize2Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/split_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/split_test.cc\nindex 10ff2da812761..2f9536147ef13 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/split_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/split_test.cc\n@@ -28,32 +28,32 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, SplitChannels) {\n   auto status = SplitChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SplitChannelsX4) {\n   auto status = SplitChannelsX4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SplitWidth) {\n   auto status = SplitWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SplitHeight) {\n   auto status = SplitHeightTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SplitBatch) {\n   auto status = SplitBatchTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, SplitDepth) {\n   auto status = SplitDepthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/strided_slice_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/strided_slice_test.cc\nindex 6e42149af4ec5..51126296b481d 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/strided_slice_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/strided_slice_test.cc\n@@ -29,7 +29,7 @@ namespace {\n \n TEST_F(OpenCLOperationTest, StridedSlice) {\n   auto status = StridedSliceTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/tile_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/tile_test.cc\nindex be54aae094d08..12724c0d27cf7 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/tile_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/tile_test.cc\n@@ -26,27 +26,27 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, TileChannels) {\n   auto status = TileChannelsTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, TileChannelsX4) {\n   auto status = TileChannelsX4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, TileWidth) {\n   auto status = TileWidthTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, TileHeight) {\n   auto status = TileHeightTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, TileHWC) {\n   auto status = TileHWCTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/transpose_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/transpose_test.cc\nindex b32a764787fa5..9f55ec706bbd2 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/transpose_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/transpose_test.cc\n@@ -29,7 +29,7 @@ namespace {\n \n TEST_F(OpenCLOperationTest, Transpose) {\n   auto status = TransposeTest(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\ndiff --git a/tensorflow/lite/delegates/gpu/cl/kernels/winograd_test.cc b/tensorflow/lite/delegates/gpu/cl/kernels/winograd_test.cc\nindex 3aa1424fe295a..54849118d169f 100644\n--- a/tensorflow/lite/delegates/gpu/cl/kernels/winograd_test.cc\n+++ b/tensorflow/lite/delegates/gpu/cl/kernels/winograd_test.cc\n@@ -26,22 +26,22 @@ namespace cl {\n \n TEST_F(OpenCLOperationTest, Winograd4x4To36TileX6) {\n   auto status = Winograd4x4To36TileX6Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Winograd36To4x4Tile4x1) {\n   auto status = Winograd36To4x4Tile4x1Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Winograd4x4To36) {\n   auto status = Winograd4x4To36Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST_F(OpenCLOperationTest, Winograd36To4x4) {\n   auto status = Winograd36To4x4Test(&exec_env_);\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace cl\ndiff --git a/tensorflow/lite/delegates/gpu/common/BUILD b/tensorflow/lite/delegates/gpu/common/BUILD\nindex 048dfcf66c6a4..b430dd22c77fc 100644\n--- a/tensorflow/lite/delegates/gpu/common/BUILD\n+++ b/tensorflow/lite/delegates/gpu/common/BUILD\n@@ -7,6 +7,15 @@ package(\n     licenses = [""notice""],\n )\n \n+cc_library(\n+    name = ""gpu_common_wrapper"",\n+    linkopts = select({\n+        ""//tensorflow:android"": [\n+            ""-lm"",\n+        ],\n+    }),\n+)\n+\n cc_library(\n     name = ""convert"",\n     srcs = [""convert.cc""],\n@@ -119,6 +128,7 @@ cc_test(\n     name = ""data_type_test"",\n     srcs = [""data_type_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":data_type"",\n         ""@com_google_googletest//:gtest_main"",\n     ],\n@@ -185,6 +195,7 @@ cc_test(\n     name = ""model_test"",\n     srcs = [""model_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":model"",\n         ""@com_google_absl//absl/status"",\n         ""@com_google_googletest//:gtest_main"",\n@@ -397,6 +408,7 @@ cc_test(\n     name = ""shape_test"",\n     srcs = [""shape_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":shape"",\n         ""@com_google_googletest//:gtest_main"",\n     ],\n@@ -440,6 +452,7 @@ cc_test(\n     name = ""memory_management_test"",\n     srcs = [""memory_management_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":memory_management"",\n         "":shape"",\n         "":types"",\n@@ -452,6 +465,7 @@ cc_test(\n     name = ""memory_management_internal_test"",\n     srcs = [""memory_management/internal_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":memory_management"",\n         ""@com_google_googletest//:gtest_main"",\n     ],\n@@ -461,6 +475,7 @@ cc_test(\n     name = ""memory_management_types_test"",\n     srcs = [""memory_management/types_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":memory_management"",\n         ""@com_google_googletest//:gtest_main"",\n     ],\n@@ -498,6 +513,7 @@ cc_test(\n     name = ""util_test"",\n     srcs = [""util_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":util"",\n         ""@com_google_googletest//:gtest_main"",\n     ],\n@@ -508,6 +524,7 @@ cc_library(\n     srcs = [""winograd_util.cc""],\n     hdrs = [""winograd_util.h""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":data_type"",\n         "":operations"",\n         "":shape"",\n@@ -519,6 +536,7 @@ cc_test(\n     name = ""winograd_util_test"",\n     srcs = [""winograd_util_test.cc""],\n     deps = [\n+        "":gpu_common_wrapper"",\n         "":winograd_util"",\n         ""@com_google_googletest//:gtest_main"",\n     ],\ndiff --git a/tensorflow/lite/delegates/gpu/common/model_builder_helper.cc b/tensorflow/lite/delegates/gpu/common/model_builder_helper.cc\nindex c314ed144865c..4b9e21fd145c9 100644\n--- a/tensorflow/lite/delegates/gpu/common/model_builder_helper.cc\n+++ b/tensorflow/lite/delegates/gpu/common/model_builder_helper.cc\n@@ -400,6 +400,7 @@ absl::Status MaybeFuseActivation(TfLiteFusedActivation fused_activation,\n       attr.clip = fused_activation == kTfLiteActRelu\n                       ? 0.0f\n                       : (fused_activation == kTfLiteActReluN1To1 ? 1.0f : 6.0f);\n+      attr.lclip = fused_activation == kTfLiteActReluN1To1 ? -1.0f : 0.0f;\n       Node* activation_node;\n       RETURN_IF_ERROR(\n           NewPassthroughNode(graph, node, outputs[0], &activation_node));\ndiff --git a/tensorflow/lite/delegates/gpu/common/operations.h b/tensorflow/lite/delegates/gpu/common/operations.h\nindex 9214bbffadc1c..af7eb7fa06455 100644\n--- a/tensorflow/lite/delegates/gpu/common/operations.h\n+++ b/tensorflow/lite/delegates/gpu/common/operations.h\n@@ -388,18 +388,23 @@ Padding3D CalculateSamePadding(const BHWDC& input,\n                                const DepthwiseConvolution3DAttributes& attr);\n \n // f(x):= {\n-//   if x < 0  : x -> alpha * x\n-//   if x >= 0 : x -> min(clip, x)\n+//   if x < lclip  : x -> min(lclip, alpha * x)\n+//   if x >= lclip : x -> min(clip, x)\n // }\n //\n // Examples:\n-//   - ReLU: clip = 0, alpha = 0\n-//   - ReLU6: clip = 6, alpha = 0\n-//   - Leaky ReLU: clip = 0, alpha = a\n+//   - ReLU: clip = 0, alpha = 0, lclip = 0\n+//   - ReLU6: clip = 6, alpha = 0, lclip = 0\n+//   - Leaky ReLU: clip = 0, alpha = a, lclip = 0\n+//   - ReLUN1To1: clip = 1, alpha = 0, lclip = -1\n struct ReLUAttributes {\n   // clip <= 0 mean it is not set.\n   float clip = 0;\n \n+  // lclip must be < clip\n+  float lclip = 0;\n+\n+  // alpha must be <= 1\n   float alpha = 0;\n };\n \ndiff --git a/tensorflow/lite/delegates/gpu/common/tasks/fully_connected_test_util.cc b/tensorflow/lite/delegates/gpu/common/tasks/fully_connected_test_util.cc\nindex d1c02385671c7..abac094adb654 100644\n--- a/tensorflow/lite/delegates/gpu/common/tasks/fully_connected_test_util.cc\n+++ b/tensorflow/lite/delegates/gpu/common/tasks/fully_connected_test_util.cc\n@@ -52,8 +52,7 @@ absl::Status FullyConnectedTest(TestExecutionEnvironment* env) {\n       RETURN_IF_ERROR(env->ExecuteGPUOperation(\n           src_tensor, std::make_unique<FullyConnected>(std::move(operation)),\n           BHWC(1, 1, 1, 2), &dst_tensor));\n-      RETURN_IF_ERROR(PointWiseNear({14.5f, 37.5f}, dst_tensor.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+      RETURN_IF_ERROR(PointWiseNear({14.5f, 37.5f}, dst_tensor.data, eps));\n     }\n   }\n   return absl::OkStatus();\n@@ -101,8 +100,7 @@ absl::Status FullyConnectedLargeTest(TestExecutionEnvironment* env) {\n       RETURN_IF_ERROR(\n           PointWiseNear({139.4f, 363.5f, 587.6f, 811.7f, 1035.8f, 1259.9f,\n                          1484.1f, 1708.2f, 1932.3f, 2156.4f, 2380.5f, 2604.6f},\n-                        dst_tensor.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+                        dst_tensor.data, eps));\n     }\n   }\n   return absl::OkStatus();\n@@ -159,8 +157,7 @@ absl::Status FullyConnectedExtraLargeTest(TestExecutionEnvironment* env) {\n       RETURN_IF_ERROR(env->ExecuteGPUOperation(\n           src_tensor, std::make_unique<FullyConnected>(std::move(operation)),\n           BHWC(1, 1, 1, kOutputSize), &dst_tensor));\n-      RETURN_IF_ERROR(PointWiseNear(expected, dst_tensor.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+      RETURN_IF_ERROR(PointWiseNear(expected, dst_tensor.data, eps));\n     }\n   }\n   return absl::OkStatus();\n@@ -194,8 +191,7 @@ absl::Status FullyConnectedInt8Test(TestExecutionEnvironment* env) {\n       RETURN_IF_ERROR(env->ExecuteGPUOperation(\n           src_tensor, std::make_unique<FullyConnected>(std::move(operation)),\n           BHWC(1, 1, 1, 2), &dst_tensor));\n-      RETURN_IF_ERROR(PointWiseNear({20.5f, 15.5f}, dst_tensor.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+      RETURN_IF_ERROR(PointWiseNear({20.5f, 15.5f}, dst_tensor.data, eps));\n     }\n   }\n   return absl::OkStatus();\ndiff --git a/tensorflow/lite/delegates/gpu/common/tasks/lstm_test_util.cc b/tensorflow/lite/delegates/gpu/common/tasks/lstm_test_util.cc\nindex ad6ffb9ff4f55..4248ea91be411 100644\n--- a/tensorflow/lite/delegates/gpu/common/tasks/lstm_test_util.cc\n+++ b/tensorflow/lite/delegates/gpu/common/tasks/lstm_test_util.cc\n@@ -66,15 +66,13 @@ absl::Status LstmTest(TestExecutionEnvironment* env) {\n           {BHWC(1, 1, 1, 4), BHWC(1, 1, 1, 4)}, {&new_state, &new_activ}));\n       RETURN_IF_ERROR(\n           PointWiseNear({7.0 / 15.0, 10.0 / 15.0, 13.0 / 15.0, 16.0 / 15.0},\n-                        new_state.data, eps))\n-          << ToString(storage) << "", "" << ToString(precision);\n+                        new_state.data, eps));\n       RETURN_IF_ERROR(PointWiseNear(\n           {static_cast<float>((1.0 / 6.0) * std::tanh(7.0 / 15.0)),\n            static_cast<float>((1.0 / 6.0) * std::tanh(10.0 / 15.0)),\n            static_cast<float>((1.0 / 6.0) * std::tanh(13.0 / 15.0)),\n            static_cast<float>((1.0 / 6.0) * std::tanh(16.0 / 15.0))},\n-          new_activ.data, eps))\n-          << ToString(storage) << "", "" << ToString(precision);\n+          new_activ.data, eps));\n     }\n   }\n   return absl::OkStatus();\ndiff --git a/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization_test_util.cc b/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization_test_util.cc\nindex 2455a258afb03..62255c63be526 100644\n--- a/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization_test_util.cc\n+++ b/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization_test_util.cc\n@@ -126,8 +126,7 @@ absl::Status MeanStddevNormalizationAllBatchesTest(\n           -ksqrt16, -ksqrt04, ksqrt04, ksqrt16,  // large mean, small variance\n           -ksqrt16, -ksqrt04, ksqrt04, ksqrt16,  // large mean, large variance\n       };\n-      RETURN_IF_ERROR(PointWiseNear(expected_output, dst_tensor.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+      RETURN_IF_ERROR(PointWiseNear(expected_output, dst_tensor.data, eps));\n \n       TensorFloat32 dst_tensor_single_step;\n       auto operation_single_step = CreateMeanStdDevNormalization(\n@@ -139,8 +138,7 @@ absl::Status MeanStddevNormalizationAllBatchesTest(\n                                        std::move(operation_single_step)),\n                                    BHWC(9, 1, 1, 4), &dst_tensor_single_step));\n       RETURN_IF_ERROR(\n-          PointWiseNear(expected_output, dst_tensor_single_step.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+          PointWiseNear(expected_output, dst_tensor_single_step.data, eps));\n     }\n   }\n   return absl::OkStatus();\n@@ -198,8 +196,7 @@ absl::Status MeanStddevNormalizationLargeVectorTest(\n         expected_output[kVectorSize + i + 0] = +expected_elem;\n         expected_output[kVectorSize + i + 1] = -expected_elem;\n       }\n-      RETURN_IF_ERROR(PointWiseNear(expected_output, dst_tensor.data, eps))\n-          << ""Failed using precision "" << ToString(precision);\n+      RETURN_IF_ERROR(PointWiseNear(expected_output, dst_tensor.data, eps));\n \n       if (precision != CalculationsPrecision::F32) {\n         TensorFloat32 dst_tensor_single_step;\n@@ -212,8 +209,7 @@ absl::Status MeanStddevNormalizationLargeVectorTest(\n                 std::move(operation_single_step)),\n             BHWC(1, 1, 2, kVectorSize), &dst_tensor_single_step));\n         RETURN_IF_ERROR(\n-            PointWiseNear(expected_output, dst_tensor_single_step.data, eps))\n-            << ""Failed using precision "" << ToString(precision);\n+            PointWiseNear(expected_output, dst_tensor_single_step.data, eps));\n       }\n     }\n   }\ndiff --git a/tensorflow/lite/delegates/gpu/common/tasks/relu.cc b/tensorflow/lite/delegates/gpu/common/tasks/relu.cc\nindex 9afc2c7508eab..172d60179600a 100644\n--- a/tensorflow/lite/delegates/gpu/common/tasks/relu.cc\n+++ b/tensorflow/lite/delegates/gpu/common/tasks/relu.cc\n@@ -28,14 +28,21 @@ ElementwiseDescriptor CreateReLU(const ReLUAttributes& attr,\n   ElementwiseDescriptor result;\n   std::string min_func;\n   if (attr.alpha != 0.0f) {\n-    min_func = ""min(in_value * args.alpha, INIT_FLT(0.0f))"";\n+    min_func = ""min(in_value * args.alpha, INIT_FLT4(args.lclip))"";\n     if (precision == CalculationsPrecision::F32) {\n       result.args.AddFloat(""alpha"", attr.alpha);\n+      result.args.AddFloat(""lclip"", attr.lclip);\n     } else {\n       result.args.AddHalf(""alpha"", half(attr.alpha));\n+      result.args.AddHalf(""lclip"", half(attr.lclip));\n     }\n   } else {\n-    min_func = ""INIT_FLT4(0.0f)"";\n+    min_func = ""INIT_FLT4(args.lclip)"";\n+    if (precision == CalculationsPrecision::F32) {\n+      result.args.AddFloat(""lclip"", attr.lclip);\n+    } else {\n+      result.args.AddHalf(""lclip"", half(attr.lclip));\n+    }\n   }\n   if (attr.clip != 0.0f) {\n     if (precision == CalculationsPrecision::F32) {\ndiff --git a/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.cc b/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.cc\nindex 7c87bbb7823c0..cb3a80c86f2c6 100644\n--- a/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.cc\n+++ b/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.cc\n@@ -142,5 +142,130 @@ absl::Status ReLUAlphaClipTest(TestExecutionEnvironment* env) {\n   return absl::OkStatus();\n }\n \n+absl::Status ReLULClipNoAlphaNoClipTest(TestExecutionEnvironment* env) {\n+  TensorFloat32 src_tensor;\n+  src_tensor.shape = BHWC(1, 2, 1, 4);\n+  src_tensor.data = {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f};\n+\n+  ReLUAttributes attr;\n+  attr.alpha = 0.0f;\n+  attr.lclip = -1.0f;\n+  attr.clip = 0.0f;\n+\n+  for (auto precision : env->GetSupportedPrecisions()) {\n+    auto data_type = DeduceDataTypeFromPrecision(precision);\n+    for (auto storage : env->GetSupportedStorages(data_type)) {\n+      const float eps = precision == CalculationsPrecision::F32 ? 1e-6f : 1e-3f;\n+      OperationDef op_def;\n+      op_def.precision = precision;\n+      auto data_type = DeduceDataTypeFromPrecision(precision);\n+      op_def.src_tensors.push_back({data_type, storage, Layout::HWC});\n+      op_def.dst_tensors.push_back({data_type, storage, Layout::HWC});\n+      TensorFloat32 dst_tensor;\n+      GPUOperation operation = CreateReLU(op_def, attr);\n+      RETURN_IF_ERROR(env->ExecuteGPUOperation(\n+          src_tensor, absl::make_unique<GPUOperation>(std::move(operation)),\n+          BHWC(1, 2, 1, 4), &dst_tensor));\n+      RETURN_IF_ERROR(\n+          PointWiseNear({-1.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f},\n+              dst_tensor.data, eps));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status ReLUAlphaLClipNoClipTest(TestExecutionEnvironment* env) {\n+  TensorFloat32 src_tensor;\n+  src_tensor.shape = BHWC(1, 2, 1, 4);\n+  src_tensor.data = {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f};\n+\n+  ReLUAttributes attr;\n+  attr.alpha = 0.5f;\n+  attr.lclip = -1.0f;\n+  attr.clip = 0.0f;\n+\n+  for (auto precision : env->GetSupportedPrecisions()) {\n+    auto data_type = DeduceDataTypeFromPrecision(precision);\n+    for (auto storage : env->GetSupportedStorages(data_type)) {\n+      const float eps = precision == CalculationsPrecision::F32 ? 1e-6f : 1e-3f;\n+      OperationDef op_def;\n+      op_def.precision = precision;\n+      auto data_type = DeduceDataTypeFromPrecision(precision);\n+      op_def.src_tensors.push_back({data_type, storage, Layout::HWC});\n+      op_def.dst_tensors.push_back({data_type, storage, Layout::HWC});\n+      TensorFloat32 dst_tensor;\n+      GPUOperation operation = CreateReLU(op_def, attr);\n+      RETURN_IF_ERROR(env->ExecuteGPUOperation(\n+          src_tensor, absl::make_unique<GPUOperation>(std::move(operation)),\n+          BHWC(1, 2, 1, 4), &dst_tensor));\n+      RETURN_IF_ERROR(PointWiseNear({-6.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f},\n+          dst_tensor.data, eps));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status ReLULClipClipNoAlphaTest(TestExecutionEnvironment* env) {\n+  TensorFloat32 src_tensor;\n+  src_tensor.shape = BHWC(1, 2, 1, 4);\n+  src_tensor.data = {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f};\n+\n+  ReLUAttributes attr;\n+  attr.alpha = 0.0f;\n+  attr.lclip = -1.0f;\n+  attr.clip = 1.0f;\n+\n+  for (auto precision : env->GetSupportedPrecisions()) {\n+    auto data_type = DeduceDataTypeFromPrecision(precision);\n+    for (auto storage : env->GetSupportedStorages(data_type)) {\n+      const float eps = precision == CalculationsPrecision::F32 ? 1e-6f : 1e-3f;\n+      OperationDef op_def;\n+      op_def.precision = precision;\n+      auto data_type = DeduceDataTypeFromPrecision(precision);\n+      op_def.src_tensors.push_back({data_type, storage, Layout::HWC});\n+      op_def.dst_tensors.push_back({data_type, storage, Layout::HWC});\n+      TensorFloat32 dst_tensor;\n+      GPUOperation operation = CreateReLU(op_def, attr);\n+      RETURN_IF_ERROR(env->ExecuteGPUOperation(\n+          src_tensor, absl::make_unique<GPUOperation>(std::move(operation)),\n+          BHWC(1, 2, 1, 4), &dst_tensor));\n+      RETURN_IF_ERROR(PointWiseNear({-1.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 1.0f},\n+          dst_tensor.data, eps));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status ReLUAlphaLClipClipTest(TestExecutionEnvironment* env) {\n+  TensorFloat32 src_tensor;\n+  src_tensor.shape = BHWC(1, 2, 1, 4);\n+  src_tensor.data = {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f};\n+\n+  ReLUAttributes attr;\n+  attr.alpha = 0.5f;\n+  attr.lclip = -1.0f;\n+  attr.clip = 3.0f;\n+\n+  for (auto precision : env->GetSupportedPrecisions()) {\n+    auto data_type = DeduceDataTypeFromPrecision(precision);\n+    for (auto storage : env->GetSupportedStorages(data_type)) {\n+      const float eps = precision == CalculationsPrecision::F32 ? 1e-6f : 1e-3f;\n+      OperationDef op_def;\n+      op_def.precision = precision;\n+      auto data_type = DeduceDataTypeFromPrecision(precision);\n+      op_def.src_tensors.push_back({data_type, storage, Layout::HWC});\n+      op_def.dst_tensors.push_back({data_type, storage, Layout::HWC});\n+      TensorFloat32 dst_tensor;\n+      GPUOperation operation = CreateReLU(op_def, attr);\n+      RETURN_IF_ERROR(env->ExecuteGPUOperation(\n+          src_tensor, absl::make_unique<GPUOperation>(std::move(operation)),\n+          BHWC(1, 2, 1, 4), &dst_tensor));\n+      RETURN_IF_ERROR(PointWiseNear({-6.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.0f},\n+          dst_tensor.data, eps));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n }  // namespace gpu\n }  // namespace tflite\ndiff --git a/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.h b/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.h\nindex 92ed2eea5cbcd..cb8aa455d9c6e 100644\n--- a/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.h\n+++ b/tensorflow/lite/delegates/gpu/common/tasks/relu_test_util.h\n@@ -26,6 +26,10 @@ absl::Status ReLUNoClipNoAlphaTest(TestExecutionEnvironment* env);\n absl::Status ReLUClipTest(TestExecutionEnvironment* env);\n absl::Status ReLUAlphaTest(TestExecutionEnvironment* env);\n absl::Status ReLUAlphaClipTest(TestExecutionEnvironment* env);\n+absl::Status ReLULClipNoAlphaNoClipTest(TestExecutionEnvironment* env);\n+absl::Status ReLUAlphaLClipNoClipTest(TestExecutionEnvironment* env);\n+absl::Status ReLULClipClipNoAlphaTest(TestExecutionEnvironment* env);\n+absl::Status ReLUAlphaLClipClipTest(TestExecutionEnvironment* env);\n \n }  // namespace gpu\n }  // namespace tflite\ndiff --git a/tensorflow/lite/delegates/gpu/gl/BUILD b/tensorflow/lite/delegates/gpu/gl/BUILD\nindex 6e3e0aff57cd7..05340187cff26 100644\n--- a/tensorflow/lite/delegates/gpu/gl/BUILD\n+++ b/tensorflow/lite/delegates/gpu/gl/BUILD\n@@ -212,7 +212,12 @@ cc_test(\n     linkopts = [\n         ""-lEGL"",\n         ""-lGLESv2"",\n-    ],\n+    ] + select({\n+        ""//tensorflow:android"": [\n+            ""-ldl"",\n+            ""-lm"",\n+        ],\n+    }),\n     tags = tf_gpu_tests_tags() + [\n         ""local"",\n         ""nobuilder"",\n@@ -445,6 +450,11 @@ cc_library(\n cc_test(\n     name = ""serialization_test"",\n     srcs = [""serialization_test.cc""],\n+    linkopts = select({\n+        ""//tensorflow:android"": [\n+            ""-lm"",\n+        ],\n+    }),\n     tags = [\n         ""local"",\n         ""nobuilder"",\ndiff --git a/tensorflow/lite/delegates/gpu/gl/kernels/BUILD b/tensorflow/lite/delegates/gpu/gl/kernels/BUILD\nindex 7d62109d6a7dd..9aafd7ae7aa1a 100644\n--- a/tensorflow/lite/delegates/gpu/gl/kernels/BUILD\n+++ b/tensorflow/lite/delegates/gpu/gl/kernels/BUILD\n@@ -44,6 +44,7 @@ cc_test(\n     ],\n     deps = [\n         "":converter"",\n+        "":test_util"",\n         ""//tensorflow/lite/delegates/gpu/common:convert"",\n         ""//tensorflow/lite/delegates/gpu/common:shape"",\n         ""//tensorflow/lite/delegates/gpu/common:status"",\n@@ -719,7 +720,12 @@ cc_library(\n     linkopts = [\n         ""-lEGL"",\n         ""-lGLESv3"",\n-    ],\n+    ] + select({\n+        ""//tensorflow:android"": [\n+            ""-ldl"",\n+            ""-lm"",\n+        ],\n+    }),\n     deps = [\n         ""//tensorflow/lite/delegates/gpu/common:model"",\n         ""//tensorflow/lite/delegates/gpu/common:operations"",\ndiff --git a/tensorflow/lite/delegates/gpu/gl/kernels/relu.cc b/tensorflow/lite/delegates/gpu/gl/kernels/relu.cc\nindex 6d05ea894d4cf..944dca9759ef0 100644\n--- a/tensorflow/lite/delegates/gpu/gl/kernels/relu.cc\n+++ b/tensorflow/lite/delegates/gpu/gl/kernels/relu.cc\n@@ -43,10 +43,12 @@ class ReLU : public NodeShader {\n     std::vector<Variable> params;\n     std::string min;\n     if (attr.alpha == 0) {\n-      min = ""vec4(0.0)"";\n+      min = ""vec4($lclip$)"";\n+      params.push_back({""lclip"", attr.lclip});\n     } else {\n-      min = ""min($alpha$ * value_0, 0.0)"";\n+      min = ""min($alpha$ * value_0, $lclip$)"";\n       params.push_back({""alpha"", attr.alpha});\n+      params.push_back({""lclip"", attr.lclip});\n     }\n     std::string code;\n     if (attr.clip == 0) {\ndiff --git a/tensorflow/lite/delegates/gpu/gl/kernels/relu_test.cc b/tensorflow/lite/delegates/gpu/gl/kernels/relu_test.cc\nindex 0c2d2536fd654..76a56a78b923b 100644\n--- a/tensorflow/lite/delegates/gpu/gl/kernels/relu_test.cc\n+++ b/tensorflow/lite/delegates/gpu/gl/kernels/relu_test.cc\n@@ -94,6 +94,62 @@ TEST_F(ReluTest, ClipAndAlpha) {\n               Pointwise(FloatNear(1e-6), {-3.0, 0.0, 2.0, 6.0}));\n }\n \n+TEST_F(ReluTest, ReLULClipNoAlphaNoClip) {\n+  OperationType op_type = OperationType::RELU;\n+  ReLUAttributes attr;\n+  attr.lclip = -1;\n+  attr.clip = 0;\n+  attr.alpha = 0;\n+  SingleOpModel model({ToString(op_type), attr}, {GetTensorRef(0)},\n+                      {GetTensorRef(1)});\n+  ASSERT_TRUE(model.PopulateTensor(0, {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f}));\n+  ASSERT_OK(model.Invoke(*NewReLUNodeShader()));\n+  EXPECT_THAT(model.GetOutput(0),\n+              Pointwise(FloatNear(1e-6), {-1.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f}));\n+}\n+\n+TEST_F(ReluTest, ReLUAlphaLClipNoClip) {\n+  OperationType op_type = OperationType::RELU;\n+  ReLUAttributes attr;\n+  attr.lclip = -1;\n+  attr.clip = 0;\n+  attr.alpha = 0.5;\n+  SingleOpModel model({ToString(op_type), attr}, {GetTensorRef(0)},\n+                      {GetTensorRef(1)});\n+  ASSERT_TRUE(model.PopulateTensor(0, {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f}));\n+  ASSERT_OK(model.Invoke(*NewReLUNodeShader()));\n+  EXPECT_THAT(model.GetOutput(0),\n+              Pointwise(FloatNear(1e-6), {-6.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f}));\n+}\n+\n+TEST_F(ReluTest, ReLULClipClipNoAlpha) {\n+  OperationType op_type = OperationType::RELU;\n+  ReLUAttributes attr;\n+  attr.lclip = -1;\n+  attr.clip = 1;\n+  attr.alpha = 0;\n+  SingleOpModel model({ToString(op_type), attr}, {GetTensorRef(0)},\n+                      {GetTensorRef(1)});\n+  ASSERT_TRUE(model.PopulateTensor(0, {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f}));\n+  ASSERT_OK(model.Invoke(*NewReLUNodeShader()));\n+  EXPECT_THAT(model.GetOutput(0),\n+              Pointwise(FloatNear(1e-6), {-1.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 1.0f}));\n+}\n+\n+TEST_F(ReluTest, ReLUAlphaLClipClip) {\n+  OperationType op_type = OperationType::RELU;\n+  ReLUAttributes attr;\n+  attr.lclip = -1;\n+  attr.clip = 3;\n+  attr.alpha = 0.5;\n+  SingleOpModel model({ToString(op_type), attr}, {GetTensorRef(0)},\n+                      {GetTensorRef(1)});\n+  ASSERT_TRUE(model.PopulateTensor(0, {-12.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.2f}));\n+  ASSERT_OK(model.Invoke(*NewReLUNodeShader()));\n+  EXPECT_THAT(model.GetOutput(0),\n+              Pointwise(FloatNear(1e-6), {-6.0f, -1.0f, -0.5f, 0.0f, 0.8f, -0.6f, 1.0f, 3.0f}));\n+}\n+\n }  // namespace\n }  // namespace gl\n }  // namespace gpu\ndiff --git a/tensorflow/lite/delegates/gpu/gl/kernels/resampler_test.cc b/tensorflow/lite/delegates/gpu/gl/kernels/resampler_test.cc\nindex f218132816c6c..9894f747cfe5c 100644\n--- a/tensorflow/lite/delegates/gpu/gl/kernels/resampler_test.cc\n+++ b/tensorflow/lite/delegates/gpu/gl/kernels/resampler_test.cc\n@@ -74,17 +74,17 @@ absl::Status ResamplerIdentityTest(const BHWC& shape) {\n \n TEST(ResamplerTest, Identity_2_2_1) {\n   auto status = ResamplerIdentityTest(BHWC(1, 2, 2, 1));\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST(ResamplerTest, Identity_3_5_3) {\n   auto status = ResamplerIdentityTest(BHWC(1, 3, 5, 3));\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n TEST(ResamplerTest, Identity_6_1_7) {\n   auto status = ResamplerIdentityTest(BHWC(1, 6, 1, 7));\n-  ASSERT_TRUE(status.ok()) << status.error_message();\n+  ASSERT_TRUE(status.ok()) << status;\n }\n \n }  // namespace\n'","['Fix GPU builds for Android\n\nFix GPU builds on Android (OpenCL and OpenGL).\nTested with Android NDK r18b.\n\nSigned-off-by: Mike Corrigan <corrigan@gmail.com>', 'Fix status log messages\n\nThe status type was changed from an internal TensorFlow status\nto the abseil status. This status does not have an\nerror_message() method. Remove usage of this method from\ntest programs.\n\nSigned-off-by: Mike Corrigan <corrigan@gmail.com>', 'Fix ReLUN1To1 fused activation for OpenCL and OpenGL\n\nThe ReLUN1To1 op was repurposed from the a ReLU1 op.\nHowever it was not fully reimplemented. As a result\nit clipped to a minimum of 0 instead of -1.\n\nAdd a left clip attribute, lclip, to the ReLU\nimplementation. Set to -1 for ReLUN1To1 and 0 for\nall other ReLUs.\n\nSigned-off-by: Mike Corrigan <corrigan@gmail.com>']",[],2022-10-20 04:31:58
58174,Fix duplicated dylibs in Mac pip wheel,"Fixes #58164

On Mac, copying the runfiles with `-L` duplicates the symlinked dylibs. On Linux, the duplicate copies are removed during the wheel build, so this PR does the same for Mac.

Before
```
-rwxr-xr-x   1 tester  wheel   473M Oct 19  2022 libtensorflow_cc.2.12.0.dylib
-rwxr-xr-x   1 tester  wheel   473M Oct 19  2022 libtensorflow_cc.2.dylib
-rwxr-xr-x   1 tester  wheel    32M Oct 19  2022 libtensorflow_framework.2.12.0.dylib
-rwxr-xr-x   1 tester  wheel    32M Oct 19  2022 libtensorflow_framework.2.dylib
-rwxr-xr-x   1 tester  wheel    32M Oct 19  2022 libtensorflow_framework.dylib
```

After
```
-rwxr-xr-x   1 tester  wheel   473M Oct 19  2022 libtensorflow_cc.2.dylib
-rwxr-xr-x   1 tester  wheel    32M Oct 19  2022 libtensorflow_framework.2.dylib
```

cc @learning-to-play ",trevor-m,[],[],['mihaimaruseac'],['mihaimaruseac'],['gbaned'],"b'diff --git a/tensorflow/tools/pip_package/build_pip_package.sh b/tensorflow/tools/pip_package/build_pip_package.sh\nindex f97ff50bc56d1..dc6270d70bfa6 100755\n--- a/tensorflow/tools/pip_package/build_pip_package.sh\n+++ b/tensorflow/tools/pip_package/build_pip_package.sh\n@@ -217,6 +217,12 @@ function prepare_src() {\n   rm -f ${TMPDIR}/tensorflow/libtensorflow_framework.so\n   rm -f ${TMPDIR}/tensorflow/libtensorflow_framework.so.[0-9].*\n \n+  # Copying symlinks with -L duplicates these libraries.\n+  rm -f ${TMPDIR}/tensorflow/libtensorflow_framework.dylib\n+  rm -f ${TMPDIR}/tensorflow/libtensorflow_framework.[0-9].*.dylib\n+  rm -f ${TMPDIR}/tensorflow/libtensorflow_cc.dylib\n+  rm -f ${TMPDIR}/tensorflow/libtensorflow_cc.[0-9].*.dylib\n+\n   # TODO(annarev): copy over API files from tensorflow/api/_vN to tensorflow/\n   #   except tensorflow/api/_vN/lite/.\n \n'",['Fix duplicated dylibs in Mac pip wheel'],[],2022-10-19 22:29:57
58173,Update rules_pkg,Update rules_pkg from 0.7.0 to 0.7.1,Vertexwahn,[],[],['mihaimaruseac'],['mihaimaruseac'],['gbaned'],"b'diff --git a/tensorflow/workspace3.bzl b/tensorflow/workspace3.bzl\nindex a6c2c5c5835d7..94a7fb9fd404e 100644\n--- a/tensorflow/workspace3.bzl\n+++ b/tensorflow/workspace3.bzl\n@@ -30,10 +30,10 @@ def workspace():\n     http_archive(\n         name = ""rules_pkg"",\n         urls = [\n-            ""https://mirror.bazel.build/github.com/bazelbuild/rules_pkg/releases/download/0.7.0/rules_pkg-0.7.0.tar.gz"",\n-            ""https://github.com/bazelbuild/rules_pkg/releases/download/0.7.0/rules_pkg-0.7.0.tar.gz"",\n+            ""https://mirror.bazel.build/github.com/bazelbuild/rules_pkg/releases/download/0.7.1/rules_pkg-0.7.1.tar.gz"",\n+            ""https://github.com/bazelbuild/rules_pkg/releases/download/0.7.1/rules_pkg-0.7.1.tar.gz"",\n         ],\n-        sha256 = ""8a298e832762eda1830597d64fe7db58178aa84cd5926d76d5b744d6558941c2"",\n+        sha256 = ""451e08a4d78988c06fa3f9306ec813b836b1d076d0f055595444ba4ff22b867f"",\n     )\n \n     # Load the raw llvm-project.  llvm does not have build rules set up by default,\n'",['Update rules_pkg'],[],2022-10-19 21:45:46
58172,Add missing link library for MhloDialect,"Code in MhloDialect uses MLIRSparseTensorDialect, so it needs to be linked against for shared library build to work. This was causing builds to fail for onnx-mlir when updating versions.",MikeHolman,[],[],['burmako'],['burmako'],['gbaned'],"b'diff --git a/tensorflow/compiler/xla/mlir_hlo/lib/Dialect/mhlo/IR/CMakeLists.txt b/tensorflow/compiler/xla/mlir_hlo/lib/Dialect/mhlo/IR/CMakeLists.txt\nindex 924ec41e67c92..e7a1a0b03c28c 100644\n--- a/tensorflow/compiler/xla/mlir_hlo/lib/Dialect/mhlo/IR/CMakeLists.txt\n+++ b/tensorflow/compiler/xla/mlir_hlo/lib/Dialect/mhlo/IR/CMakeLists.txt\n@@ -46,6 +46,7 @@ target_link_libraries(MhloDialect\n   MLIRIR\n   MLIRMhloUtils\n   MLIRQuantDialect\n+  MLIRSparseTensorDialect\n   HloOpsCommon\n   StablehloBase\n )\n'","['Add missing link library for MhloDialect\n\nCode in MhloDialect uses MLIRSparseTensorDialect, so it needs to be linked against for shared library build to work. This was causing builds to fail for onnx-mlir when updating versions.']",[],2022-10-19 20:48:17
58171,[ROCm] Fix for JAX build breakage on ROCm.,"The following upstream commit caused JAX on ROCm to fail to build:

https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/commit/f03950067329636899e81173b3650c78ce78c432

It caused the following link time error:

/usr/bin/ld.gold: error: bazel-out/k8-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Ucuda_Scuda_Slib/libcudart.so: file is empty",rsanthanam-amd,['rsanthanam-amd'],"['/cc @cheshire @hawkinsp ', 'Closing this because it does not work on CUDA.  I will open another PR with a better fix.']",['hawkinsp'],['hawkinsp'],['gbaned'],"b'diff --git a/tensorflow/core/platform/BUILD b/tensorflow/core/platform/BUILD\nindex bc95fb60354b9..80b4672ae56c7 100644\n--- a/tensorflow/core/platform/BUILD\n+++ b/tensorflow/core/platform/BUILD\n@@ -38,6 +38,10 @@ load(\n     ""tf_copts"",  # @unused\n     ""tf_cuda_library"",\n )\n+load(\n+    ""//tensorflow/tsl/platform/default:cuda_build_defs.bzl"",\n+    ""if_cuda_is_configured"",\n+)\n load(\n     ""@local_config_rocm//rocm:build_defs.bzl"",\n     ""if_rocm_is_configured"",\n@@ -1046,9 +1050,9 @@ cc_binary(\n cc_library(\n     name = ""private_static_dep"",\n     visibility = [""//visibility:private""],\n-    deps = if_static(\n+    deps = if_cuda_is_configured(if_static(\n         [""//tensorflow/compiler/xla/stream_executor/cuda:all_runtime""],\n-    ),\n+    )),\n )\n \n tf_cuda_library(\n'",['Fix for JAX build breakage on ROCm.\n\nThe following upstream commit caused JAX on ROCm to fail to build:\n\nhttps://github.com/ROCmSoftwarePlatform/tensorflow-upstream/commit/f03950067329636899e81173b3650c78ce78c432\n\nIt caused the following link time error:\n\n/usr/bin/ld.gold: error: bazel-out/k8-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Ucuda_Scuda_Slib/libcudart.so: file is empty'],[],2022-10-19 18:29:40
58170,Fix-rel-notes,Fixes one typo and removes lines breaks which cause relnotes in the GitHub release page to show up in the wrong place.,mihaimaruseac,[],[],['rishikasinha-tf'],['rishikasinha-tf'],['gbaned'],"b'diff --git a/RELEASE.md b/RELEASE.md\nindex 4596151f2b174..ae9df4f18d64e 100644\n--- a/RELEASE.md\n+++ b/RELEASE.md\n@@ -1,34 +1,21 @@\n # Release 2.11.0\n \n ## Breaking Changes\n-*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.\n+*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.  \n     If you find your workflow failing due to this change, you may be facing one of the following issues:\n-    *   **Checkpoint loading failure.** The new optimizer handles optimizer state differently from the old optimizer, which simplies the logic of\n-        checkpoint saving/loading, but at the cost of breaking checkpoint backward compatibility in some cases. If you want to keep using an old\n-        checkpoint, please change your optimizer to `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n-    *   **TF1 compatibility.** The new optimizer, `tf.keras.optimizers.Optimizer`, does not support TF1 any more, so please use the legacy optimizer\n-        `tf.keras.optimizer.legacy.XXX`.\n+    *   **Checkpoint loading failure.** The new optimizer handles optimizer state differently from the old optimizer, which simplifies the logic of checkpoint saving/loading, but at the cost of breaking checkpoint backward compatibility in some cases. If you want to keep using an old checkpoint, please change your optimizer to `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n+    *   **TF1 compatibility.** The new optimizer, `tf.keras.optimizers.Optimizer`, does not support TF1 any more, so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.  \n         We highly recommend to migrate your workflow to TF2 for stable support and new features.\n-    *   **Old optimizer API not found.** The new optimizer, `tf.keras.optimizers.Optimizer`, has a different set of public APIs from the old optimizer.\n-        These API changes are mostly related to getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives\n-        to the missing API. If you must call the deprecated API, please change your optimizer to the legacy optimizer.\n-    *   **Learning rate schedule access.** When using a `LearningRateSchedule`, The new optimizer\'s `learning_rate` property returns the\n-        current learning rate value instead of a `LearningRateSchedule` object as before. If you need to access the `LearningRateSchedule` object,\n-        please use `optimizer._learning_rate`.\n-    *   **If you implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass\n-        `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new optimizer and find it does not support your optimizer, please file\n-        an issue in the Keras GitHub repo.\n-    *   **Errors, such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first\n-        `apply_gradients()` or `minimize()` call. If your workflow calls optimizer to update different parts of model in multiple stages,\n-        please call `optimizer.build(model.trainable_variables)` before the training loop.\n-    *   **Timeout or performance loss.** We don\'t anticipate this to happen, but if you see such issues, please use the legacy optimizer, and file\n-        an issue in the Keras GitHub repo.\n-\n-    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (for example,\n-    `tf.keras.optimizers.Adafactor`) will only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n-\n-*   `tensorflow/python/keras` code is a legacy copy of Keras since 2.7 release, and will be deleted in 2.12 release. Please remove any import of \n-    `tensorflow.python.keras` and use public API with `from tensorflow import keras` or `import tensorflow as tf; tf.keras`.\n+    *   **Old optimizer API not found.** The new optimizer, `tf.keras.optimizers.Optimizer`, has a different set of public APIs from the old optimizer.  \n+        These API changes are mostly related to getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives to the missing API. If you must call the deprecated API, please change your optimizer to the legacy optimizer.\n+    *   **Learning rate schedule access.** When using a `LearningRateSchedule`, The new optimizer\'s `learning_rate` property returns the current learning rate value instead of a `LearningRateSchedule` object as before. If you need to access the `LearningRateSchedule` object, please use `optimizer._learning_rate`.\n+    *   **If you implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new optimizer and find it does not support your optimizer, please file an issue in the Keras GitHub repo.\n+    *   **Errors, such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first `apply_gradients()` or `minimize()` call. If your workflow calls optimizer to update different parts of model in multiple stages, please call `optimizer.build(model.trainable_variables)` before the training loop.\n+    *   **Timeout or performance loss.** We don\'t anticipate this to happen, but if you see such issues, please use the legacy optimizer, and file an issue in the Keras GitHub repo.\n+\n+    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (for example, `tf.keras.optimizers.Adafactor`) will only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n+\n+*   `tensorflow/python/keras` code is a legacy copy of Keras since 2.7 release, and will be deleted in 2.12 release. Please remove any import of `tensorflow.python.keras` and use public API with `from tensorflow import keras` or `import tensorflow as tf; tf.keras`.\n \n ## Major Features and Improvements\n \n@@ -40,8 +27,7 @@\n \n *   `tf.experimental.StructuredTensor`\n \n-    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and TensorFlow-native way to encode structured data such as protocol\n-        buffers or pandas dataframes.\n+    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and TensorFlow-native way to encode structured data such as protocol buffers or pandas dataframes.\n \n *   `tf.keras`:\n \n@@ -51,33 +37,25 @@\n     *   Added weight decay support for all Keras optimizers.\n     *   Added Adafactor optimizer `tf.keras.optimizers.Adafactor`.\n     *   Added `warmstart_embedding_matrix` to `tf.keras.utils`.\n-        *   This utility can be used to warmstart an embeddings matrix, so you reuse previously-learned word embeddings when working with a new set of\n-        words which may include previously unseen words (the embedding vectors for unseen words will be randomly initialized).\n+        *   This utility can be used to warmstart an embeddings matrix, so you reuse previously-learned word embeddings when working with a new set of words which may include previously unseen words (the embedding vectors for unseen words will be randomly initialized).\n \n *   `tf.Variable`:\n \n     *   Added `CompositeTensor` as a baseclass to `ResourceVariable`.\n         *   This allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n     *   Added a new constructor argument `experimental_enable_variable_lifting` to `tf.Variable`, defaulting to True.\n-        *   When it\'s `False`, the variable won\'t be lifted out of `tf.function`, thus it can be used as a `tf.function`-local variable: during each\n-        execution of the `tf.function`, the variable will be created and then disposed, similar to a local (that is, stack-allocated) variable in C/C++. \n-        Currently, `experimental_enable_variable_lifting=False` only works on non-XLA devices (for example, under `@tf.function(jit_compile=False)`).\n+        *   When it\'s `False`, the variable won\'t be lifted out of `tf.function`, thus it can be used as a `tf.function`-local variable: during each execution of the `tf.function`, the variable will be created and then disposed, similar to a local (that is, stack-allocated) variable in C/C++. Currently, `experimental_enable_variable_lifting=False` only works on non-XLA devices (for example, under `@tf.function(jit_compile=False)`).\n \n *   TF SavedModel:\n-    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb` file is a protobuf containing the ""fingerprint"" of the SavedModel. See\n-        the [RFC](https://github.com/tensorflow/community/pull/415) for more details regarding its design and properties.\n+    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb` file is a protobuf containing the ""fingerprint"" of the SavedModel. See the [RFC](https://github.com/tensorflow/community/pull/415) for more details regarding its design and properties.\n         \n *   TF pip:\n-    *   Windows CPU-builds for x86/x64 processors are now built, maintained, tested and released by a third party: Intel. Installing the windows-native\n-        pip packages for `tensorflow` or `tensorflow-cpu` would install Intel\'s tensorflow-intel package. These packages are provided as-is. Tensorflow\n-        will use reasonable efforts to maintain the availability and integrity of this pip package. There may be delays if the third party fails to\n-        release the pip package. For using TensorFlow GPU on Windows, you will need to install TensorFlow in WSL2.\n+    *   Windows CPU-builds for x86/x64 processors are now built, maintained, tested and released by a third party: Intel. Installing the windows-native pip packages for `tensorflow` or `tensorflow-cpu` would install Intel\'s tensorflow-intel package. These packages are provided as-is. Tensorflow will use reasonable efforts to maintain the availability and integrity of this pip package. There may be delays if the third party fails to release the pip package. For using TensorFlow GPU on Windows, you will need to install TensorFlow in WSL2.\n \n ## Bug Fixes and Other Changes\n \n *   `tf.image`\n-    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which causes the returned value to be the local SSIM map instead of the global\n-        mean.\n+    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which causes the returned value to be the local SSIM map instead of the global mean.\n \n *   TF Core:\n \n'",['Fix the relnotes\n\nFixes one typo and removes lines breaks which cause relnotes in the GitHub release page to show up in the wrong place.'],[],2022-10-19 17:20:32
58169,Notice of deletion of legacy keras code.,,qlzh727,[],[],['mihaimaruseac'],['mihaimaruseac'],[],"b'diff --git a/RELEASE.md b/RELEASE.md\nindex 150e980ebd8d0..4596151f2b174 100644\n--- a/RELEASE.md\n+++ b/RELEASE.md\n@@ -27,6 +27,9 @@\n     The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (for example,\n     `tf.keras.optimizers.Adafactor`) will only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n \n+*   `tensorflow/python/keras` code is a legacy copy of Keras since 2.7 release, and will be deleted in 2.12 release. Please remove any import of \n+    `tensorflow.python.keras` and use public API with `from tensorflow import keras` or `import tensorflow as tf; tf.keras`.\n+\n ## Major Features and Improvements\n \n *   `tf.lite`:\n'",['Notice of deletion of legacy keras code.'],[],2022-10-19 17:11:54
58167,Fix valgrind error,"Valgrind indentified an error due to use of unintialised memory and identified this char array as being the source, so clear it to zero on allocation.",elfringham,[],[],['mihaimaruseac'],['mihaimaruseac'],['gbaned'],"b'diff --git a/tensorflow/core/common_runtime/pending_counts.h b/tensorflow/core/common_runtime/pending_counts.h\nindex 5951cd379e157..cff837ec48592 100644\n--- a/tensorflow/core/common_runtime/pending_counts.h\n+++ b/tensorflow/core/common_runtime/pending_counts.h\n@@ -81,7 +81,7 @@ class PendingCounts {\n   // Create a new PendingCounts object that can hold the state of\n   // all the Handles allocated from ""final_allocator"".\n   explicit PendingCounts(Layout layout)\n-      : num_bytes_(layout.next_offset_), bytes_(new char[num_bytes_]) {\n+      : num_bytes_(layout.next_offset_), bytes_(new char[num_bytes_]()) {\n     if (num_bytes_ >= sizeof(LargeCounts)) {\n       CHECK_EQ(uintptr_t(bytes_) % alignof(LargeCounts), 0);\n     }\n'","['Fix valgrind error\n\nValgrind indentified an error due to use of unintialised memory\nand identified this char array as being the source, so clear it\nto zero on allocation.']",[],2022-10-19 15:41:48
58158,Update version numbers for TensorFlow 2.11.0-rc1,"Before merging this PR, please double check that it has correctly updated
`core/public/version.h`, `tools/pip_package/setup.py`, and
`tensorflow/tensorflow.bzl`. Also review the execution notes below:

```
Major: 2 -> 2
Minor: 11 -> 11
Patch: 0 -> 0

No lingering old version strings ""2.11.0-rc0"" found in source directory 
""tensorflow/"". Good.
WARNING: Below are potentially instances of lingering old version string 
""2.11.0rc0"" in source directory ""tensorflow/"" that are not updated by this 
script. Please check them manually!
tensorflow/tools/pip_package/setup.py:123:2.11.0rc0
```",tensorflow-jenkins,[],[],"['vinila21', 'learning-to-play']","['vinila21', 'learning-to-play']",[],"b'diff --git a/tensorflow/core/public/version.h b/tensorflow/core/public/version.h\nindex 3b79a3de04cb6..43935b17fb80d 100644\n--- a/tensorflow/core/public/version.h\n+++ b/tensorflow/core/public/version.h\n@@ -26,7 +26,7 @@ limitations under the License.\n \n // TF_VERSION_SUFFIX is non-empty for pre-releases (e.g. ""-alpha"", ""-alpha.1"",\n // ""-beta"", ""-rc"", ""-rc.1"")\n-#define TF_VERSION_SUFFIX ""-rc0""\n+#define TF_VERSION_SUFFIX ""-rc1""\n \n #define TF_STR_HELPER(x) #x\n #define TF_STR(x) TF_STR_HELPER(x)\ndiff --git a/tensorflow/tools/pip_package/setup.py b/tensorflow/tools/pip_package/setup.py\nindex 2a4d29538bdfd..62a1bdb7e7b1d 100644\n--- a/tensorflow/tools/pip_package/setup.py\n+++ b/tensorflow/tools/pip_package/setup.py\n@@ -46,7 +46,7 @@\n # result for pip.\n # Also update tensorflow/tensorflow.bzl and\n # tensorflow/core/public/version.h\n-_VERSION = \'2.11.0-rc0\'\n+_VERSION = \'2.11.0-rc1\'\n \n \n # We use the same setup.py for all tensorflow_* packages and for the nightly\n'",['Update version numbers to 2.11.0-rc1'],[],2022-10-19 00:02:10
58157,Update the keras packages version in master.,"Both keras nightly and keras next release are done, so we can do this update.

Similar PRs need to happen to Estimator (either a single one tomorrow updating both final and nightly or one today after rc0 estimator is released to main package and tomorrow for nightly)",mihaimaruseac,[],[],['qlzh727'],['qlzh727'],['gbaned'],"b""diff --git a/tensorflow/tools/pip_package/setup.py b/tensorflow/tools/pip_package/setup.py\nindex 5a2008cf46e4c..b44c030900dd5 100644\n--- a/tensorflow/tools/pip_package/setup.py\n+++ b/tensorflow/tools/pip_package/setup.py\n@@ -122,8 +122,8 @@ def standard_or_nightly(standard, nightly):\n                         'tb-nightly ~= 2.11.0.a'),\n     standard_or_nightly('tensorflow_estimator >= 2.10.0rc0, < 2.11',\n                         'tf-estimator-nightly ~= 2.11.0.dev'),\n-    standard_or_nightly('keras >= 2.10.0rc0, < 2.11',\n-                        'keras-nightly ~= 2.11.0.dev'),\n+    standard_or_nightly('keras >= 2.11.0rc1, < 2.12',\n+                        'keras-nightly ~= 2.12.0.dev'),\n ]\n REQUIRED_PACKAGES = [p for p in REQUIRED_PACKAGES if p is not None]\n \n""","['Update the keras packages version in master.\n\nBoth keras nightly and keras next release are done, so we can do this update.\n\nSimilar PRs need to happen to Estimator (either a single one tomorrow updating both final and nightly or one today after rc0 estimator is released to main package and tomorrow for nightly)']",[],2022-10-18 21:38:25
58154,Remove empty glob,"This glob is not globbing anything.
This prevents flipping the flag incompatible_disallow_empty_glob
https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/1301#0183e377-b3bf-4648-8470-e7a0d37f4a04/582",limdor,[],[],['mihaimaruseac'],['mihaimaruseac'],['gbaned'],"b'diff --git a/tensorflow/core/BUILD b/tensorflow/core/BUILD\nindex 2fe24e9ea87ee..32aee1d3c671c 100644\n--- a/tensorflow/core/BUILD\n+++ b/tensorflow/core/BUILD\n@@ -824,17 +824,7 @@ filegroup(\n         ""//tensorflow/tsl/framework:mobile_srcs_no_runtime"",\n         ""//tensorflow/tsl/framework/fixedpoint:mobile_srcs_no_runtime"",\n         ""//tensorflow/tsl/platform:mobile_srcs_no_runtime"",\n-    ] + glob(\n-        [\n-            ""client/**/*.cc"",\n-        ],\n-        exclude = [\n-            ""**/*test.*"",\n-            ""**/*testutil*"",\n-            ""**/*testlib*"",\n-            ""**/*main.cc"",\n-        ],\n-    ),\n+    ],\n     visibility = [""//visibility:public""],\n )\n \n'",['Remove empty glob\n\nThis glob is not globbing anything.\r\nThis prevents flipping the flag incompatible_disallow_empty_glob'],[],2022-10-18 21:06:51
58152,Update Keras and Estimator dependency versions in setup.py,,learning-to-play,['mihaimaruseac'],"[""This doesn't exist yet"", 'Need to either split the PR and only update Keras or wait until Estimator is released', ""```suggestion\r\n                        'tf-estimator-nightly ~= 2.12.0.dev'),\r\n```""]","['mihaimaruseac', 'mihaimaruseac', 'mihaimaruseac']","['mihaimaruseac', 'mihaimaruseac']",[],"b""diff --git a/tensorflow/tools/pip_package/setup.py b/tensorflow/tools/pip_package/setup.py\nindex 095ef5970f8aa..2a4d29538bdfd 100644\n--- a/tensorflow/tools/pip_package/setup.py\n+++ b/tensorflow/tools/pip_package/setup.py\n@@ -120,10 +120,10 @@ def standard_or_nightly(standard, nightly):\n     # These are all updated during the TF release process.\n     standard_or_nightly('tensorboard >= 2.10, < 2.11',\n                         'tb-nightly ~= 2.11.0.a'),\n-    standard_or_nightly('tensorflow_estimator >= 2.10.0rc0, < 2.11',\n-                        'tf-estimator-nightly ~= 2.11.0.dev'),\n-    standard_or_nightly('keras >= 2.10.0rc0, < 2.11',\n-                        'keras-nightly ~= 2.11.0.dev'),\n+    standard_or_nightly('tensorflow_estimator >= 2.11.0rc0, < 2.12',\n+                        'tf-estimator-nightly ~= 2.12.0.dev'),\n+    standard_or_nightly('keras >= 2.11.0rc1, < 2.12',\n+                        'keras-nightly ~= 2.12.0.dev'),\n ]\n REQUIRED_PACKAGES = [p for p in REQUIRED_PACKAGES if p is not None]\n \n""","['Update setup.py', 'Update tensorflow/tools/pip_package/setup.py']",[],2022-10-18 20:01:35
58149,[OneDNN] Bug fix: Fixing a primitive cache key,"This PR addresses a potential problem that can appear in primitive caching for some rare cases where model has some FusedConv2D/3D nodes with same exact dimensions and parameters with the only difference being the fused activation function. To cover that case, we are updating the primitive cache key string to include the kind of activation function so it does the right cache lookup.",mahmoud-abuzaina,['penpornk'],"[""Also cc'ing @nSircombe and @milpuz01:\r\nFYI, since this affects the aarch64 build as well.""]",['penpornk'],['penpornk'],"['penpornk', 'gbaned']","b'diff --git a/tensorflow/core/kernels/mkl/mkl_conv_ops.cc b/tensorflow/core/kernels/mkl/mkl_conv_ops.cc\nindex fc1ad71a69b0e..82f91744db9da 100644\n--- a/tensorflow/core/kernels/mkl/mkl_conv_ops.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_conv_ops.cc\n@@ -511,6 +511,7 @@ class MklConvFwdPrimitiveFactory : public MklPrimitiveFactory<float> {\n     for (auto const& post_op_param : convFwdDims.post_op_params) {\n       key_creator.AddAsKey(post_op_param.name);\n       if (post_op_param.name == ""activation"") {\n+        key_creator.AddAsKey(post_op_param.alg);\n         DCHECK_EQ(post_op_param.param.size(), 3);\n         for (auto& param : post_op_param.param) {\n           key_creator.AddAsKey(param);\n'",['Fixing a bug in primitive cache key'],[],2022-10-18 16:47:32
58148,[TF-TRT] Adding additional TraceMe ranges,This PR adds a few additional TraceMe annotations to improve profiling for TF-TRT.,DEKHTIARJonathan,['DEKHTIARJonathan'],['@bixia1 for review'],['bixia1'],['bixia1'],['gbaned'],"b'diff --git a/tensorflow/compiler/tf2tensorrt/BUILD b/tensorflow/compiler/tf2tensorrt/BUILD\nindex 6bfd55ae0fdec..c2f7f380df6f3 100644\n--- a/tensorflow/compiler/tf2tensorrt/BUILD\n+++ b/tensorflow/compiler/tf2tensorrt/BUILD\n@@ -206,7 +206,7 @@ cc_library(\n     deps = [\n         ""//tensorflow/core:framework"",\n         ""//tensorflow/core/platform:logging"",\n-        ""//tensorflow/core/profiler/lib:annotated_traceme"",\n+        ""//tensorflow/core/profiler/lib:traceme"",\n     ] + if_tensorrt(["":tensorrt_lib""]),\n )\n \n@@ -276,6 +276,7 @@ cc_library(\n         ""//tensorflow/core:stream_executor_headers_lib"",\n         ""//tensorflow/core/common_runtime:core_cpu_lib_no_ops"",\n         ""//tensorflow/core/grappler/costs:graph_properties"",\n+        ""//tensorflow/core/profiler/lib:traceme"",\n     ] + if_tensorrt([\n         "":tensorrt_lib"",\n         ""@local_config_cuda//cuda:cuda_headers"",\n@@ -301,6 +302,7 @@ cc_library(\n         ""//tensorflow/core:lib"",\n         ""//tensorflow/core:lib_internal"",\n         ""//tensorflow/core:lib_proto_parsing"",\n+        ""//tensorflow/core/profiler/lib:traceme"",\n     ] + if_tensorrt(["":tensorrt_lib""]) + tf_custom_op_library_additional_deps(),\n     alwayslink = 1,\n )\n@@ -418,7 +420,7 @@ tf_cuda_library(\n         ""//tensorflow/core:framework_headers_lib"",\n         ""//tensorflow/core:lib"",\n         ""//tensorflow/core/platform:status"",\n-        ""//tensorflow/core/profiler/lib:annotated_traceme"",\n+        ""//tensorflow/core/profiler/lib:traceme"",\n         ""//tensorflow/core:stream_executor_headers_lib"",\n     ] + if_tensorrt(["":tensorrt_lib""]),\n )\n@@ -739,6 +741,7 @@ tf_cuda_library(\n         ""//tensorflow/core/grappler/clusters:virtual_cluster"",\n         ""//tensorflow/core/grappler/costs:graph_properties"",\n         ""//tensorflow/core/grappler/optimizers:meta_optimizer"",\n+        ""//tensorflow/core/profiler/lib:traceme"",\n         ""//tensorflow/core/profiler/lib:annotated_traceme"",\n         ""//tensorflow/compiler/xla/stream_executor/lib"",\n         ""//tensorflow/tools/graph_transforms:transform_utils"",\n@@ -911,6 +914,7 @@ cc_library(\n         ""//tensorflow/core:protos_all_cc"",\n         ""//tensorflow/core/common_runtime:core_cpu"",\n         ""//tensorflow/core/grappler/costs:graph_properties"",\n+        ""//tensorflow/core/profiler/lib:traceme"",\n         ""@com_google_absl//absl/container:flat_hash_set"",\n         ""@com_google_absl//absl/strings"",\n         ""@com_google_absl//absl/strings:str_format"",\ndiff --git a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\nindex c8fb932581511..b8877f8c44445 100644\n--- a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\n+++ b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\n@@ -70,6 +70,7 @@ limitations under the License.\n #include ""tensorflow/core/platform/tensor_float_32_utils.h""\n #include ""tensorflow/core/platform/types.h""\n #include ""tensorflow/core/profiler/lib/annotated_traceme.h""\n+#include ""tensorflow/core/profiler/lib/traceme.h""\n #include ""tensorflow/core/public/version.h""\n #include ""tensorflow/core/util/env_var.h""\n #include ""tensorflow/core/util/strided_slice_op.h""\n@@ -5908,12 +5909,20 @@ Status ConvertSegmentToGraphDef(\n     const Graph* graph, const grappler::GraphProperties& graph_properties,\n     const std::vector<const Node*>& subgraph_nodes,  // In topological order\n     EngineInfo* engine_info) {\n+  tensorflow::profiler::TraceMe activity(\n+      ""ConvertSegmentToGraphDef"", tensorflow::profiler::TraceMeLevel::kInfo);\n   std::vector<EngineConnection>* connections = &engine_info->connections;\n   GraphDef* segment_def = &engine_info->segment_graph_def;\n   std::set<string> marker_nodes;\n   // Update connection shapes/data types and add corresponding input/output\n   // nodes in the segment graphdef.\n   for (size_t i = 0; i < connections->size(); ++i) {\n+    tensorflow::profiler::TraceMe activity(\n+        [&] {\n+          return StrCat(""Constructing TRTEngine IO: "", i + 1, ""/"",\n+            connections->size());\n+        },\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n     auto& connection = connections->at(i);\n     if (connection.is_control_edge()) continue;\n     auto outside_node = graph->FindNodeId(connection.outside_id);\n@@ -5988,7 +5997,14 @@ Status ConvertSegmentToGraphDef(\n   std::unordered_map<int, int> old_to_new_id_map;\n   // Copy internal nodes to new graphdef\n   string local_scope = subgraph_nodes.front()->name();\n+  int i = 0;\n   for (const Node* node : subgraph_nodes) {\n+    tensorflow::profiler::TraceMe activity(\n+        [&] {\n+          return StrCat(""Copy Node to Subgraph: "", ++i, ""/"",\n+              subgraph_nodes.size());\n+        },\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n     local_scope = GetCommonNameScope(local_scope, node->name());\n     old_to_new_id_map[node->id()] = segment_def->node_size();\n     auto snode = segment_def->add_node();\n@@ -5997,6 +6013,13 @@ Status ConvertSegmentToGraphDef(\n   }\n   // Update the inputs of the new input nodes to point to placeholder nodes.\n   for (int i = 0; i < connections->size(); ++i) {\n+    tensorflow::profiler::TraceMe activity(\n+        [&] {\n+          return StrCat(""Updating Subgraph Input: "", i + 1, ""/"",\n+              connections->size());\n+        },\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n+\n     auto& connection = connections->at(i);\n     if (connection.is_control_edge() || !connection.is_input_edge) continue;\n     auto snode =\n@@ -6008,13 +6031,26 @@ Status ConvertSegmentToGraphDef(\n             << arg_name;\n     snode->set_input(connection.inside_port, arg_name);\n   }\n+\n   std::set<string> subgraph_node_names;\n-  for (const Node* node : subgraph_nodes) {\n-    subgraph_node_names.insert(node->name());\n+  {\n+    tensorflow::profiler::TraceMe activity(\n+        ""Constructing subgraph_node_names set: "",\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n+\n+    for (const Node* node : subgraph_nodes) {\n+      subgraph_node_names.insert(node->name());\n+    }\n   }\n \n   // Remove control inputs that are not inside the segment.\n   for (int i = 0; i < segment_def->node_size(); ++i) {\n+    tensorflow::profiler::TraceMe activity(\n+        [&] {\n+          return StrCat(""Removing outside to subgraph control inputs: "", i + 1,\n+              ""/"", segment_def->node_size());\n+        },\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n     auto snode = segment_def->mutable_node(i);\n     const int input_size = snode->input_size();\n     int input_idx = 0;\ndiff --git a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc b/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc\nindex 2b912bda26339..740beb3fbb1e0 100644\n--- a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc\n+++ b/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc\n@@ -344,6 +344,9 @@ static Status FunctionDefToGraphDef(FunctionLibraryRuntime::Handle handle,\n StatusOr<FunctionLibraryRuntime::Handle> TRTEngineOp::ConstructFunctionHandle(\n     FunctionLibraryRuntime* lib, const string& device_name,\n     bool allow_soft_placement, size_t num_inputs, size_t num_outputs) {\n+  tensorflow::profiler::TraceMe activity(\n+      ""TRTEngineOp::ConstructFunctionHandle"",\n+      tensorflow::profiler::TraceMeLevel::kInfo);\n   VLOG(1) << ""Constructing function handle"";\n   if (lib == nullptr) {\n     return errors::Internal(""Context function library is null"");\n@@ -388,6 +391,9 @@ StatusOr<FunctionLibraryRuntime::Handle> TRTEngineOp::ConstructFunctionHandle(\n \n Status TRTEngineOp::ImportSegmentGraphDef(FunctionLibraryRuntime* lib,\n                                           const string& device_name) {\n+  tensorflow::profiler::TraceMe activity(\n+      ""TRTEngineOp::ImportSegmentGraphDef"",\n+      tensorflow::profiler::TraceMeLevel::kInfo);\n   TF_ASSIGN_OR_RETURN(FunctionLibraryRuntime::Handle func_handle,\n                       ConstructFunctionHandle(lib, device_name));\n   return FunctionDefToGraphDef(func_handle, lib, &segment_graph_def_);\n@@ -395,6 +401,9 @@ Status TRTEngineOp::ImportSegmentGraphDef(FunctionLibraryRuntime* lib,\n \n TRTEngineOp::TRTEngineOp(OpKernelConstruction* context)\n     : AsyncOpKernel(context) {\n+  tensorflow::profiler::TraceMe activity(\n+    ""TRTEngineOp::TRTEngineOp"",\n+    tensorflow::profiler::TraceMeLevel::kInfo);\n   // read serialized_engine\n   OP_REQUIRES_OK(context,\n                  context->GetAttr(""serialized_segment"", &serialized_segment_));\n@@ -706,6 +715,9 @@ void TRTEngineOp::ExecuteCalibration(OpKernelContext* ctx,\n \n Status TRTEngineOp::VerifyInputShapes(\n     const std::vector<TensorShape>& input_concrete_shapes) {\n+  tensorflow::profiler::TraceMe activity(\n+    ""TRTEngineOp::VerifyInputShapes"",\n+    tensorflow::profiler::TraceMeLevel::kInfo);\n   if (input_concrete_shapes.empty()) {\n     return errors::InvalidArgument(""Input shapes are empty, for "", name());\n   }\n@@ -1047,6 +1059,9 @@ StatusOr<TrtUniquePtrType<nvinfer1::ICudaEngine>> TRTEngineOp::BuildEngine(\n     const std::vector<TensorShape>& input_concrete_shapes, int batch_size,\n     bool use_calibration, TRTInt8Calibrator* calibrator,\n     TRTEngineCacheResource* cache_resource, OpKernelContext* ctx) {\n+  tensorflow::profiler::TraceMe activity(\n+    ""TRTEngineOp::BuildEngine"",\n+    tensorflow::profiler::TraceMeLevel::kInfo);\n   TRT_ENSURE(cache_resource);\n   TRT_ENSURE(ctx);\n   // Use concrete shapes for implicit batch mode and partial shapes for\n@@ -1092,9 +1107,9 @@ StatusOr<TrtUniquePtrType<nvinfer1::ICudaEngine>> TRTEngineOp::BuildEngine(\n StatusOr<std::pair<EngineContext*, int>> TRTEngineOp::GetEngine(\n     const std::vector<TensorShape>& input_concrete_shapes, OpKernelContext* ctx,\n     TRTEngineCacheResource* cache_res) {\n-  static EngineContext empty_context;\n   tensorflow::profiler::TraceMe activity(\n       ""TRTEngineOp::GetEngine"", tensorflow::profiler::TraceMeLevel::kInfo);\n+  static EngineContext empty_context;\n   mutex_lock lock(engine_mutex_);\n   // Using first input to get batch size is reliable - VerifyInputShapes()\n   // guarantees that the first input is not a scalar. As such we can always use\n@@ -1275,6 +1290,9 @@ StatusOr<std::pair<EngineContext*, int>> TRTEngineOp::GetEngine(\n // possible.\n Status TRTEngineOp::AllocateCalibrationResources(\n     OpKernelContext* ctx, TRTEngineCacheResource* cache_res) {\n+  tensorflow::profiler::TraceMe activity(\n+      ""TRTEngineOp::AllocateCalibrationResources"",\n+      tensorflow::profiler::TraceMeLevel::kInfo);\n   cache_res->calib_ctx_ = std::make_unique<CalibrationContext>();\n   auto* cres = cache_res->calib_ctx_.get();\n \ndiff --git a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_resource_ops.cc b/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_resource_ops.cc\nindex 83f8dbca03465..a18de773008f5 100644\n--- a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_resource_ops.cc\n+++ b/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_resource_ops.cc\n@@ -32,6 +32,7 @@ limitations under the License.\n #include ""tensorflow/core/platform/logging.h""\n #include ""tensorflow/core/platform/mutex.h""\n #include ""tensorflow/core/platform/thread_annotations.h""\n+#include ""tensorflow/core/profiler/lib/traceme.h""\n \n #if GOOGLE_CUDA && GOOGLE_TENSORRT\n #include ""third_party/tensorrt/NvInfer.h""\n@@ -47,6 +48,9 @@ class CreateTRTResourceHandle : public OpKernel {\n   }\n \n   void Compute(OpKernelContext* ctx) override {\n+    tensorflow::profiler::TraceMe activity(\n+        ""CreateTRTResourceHandle::Compute"",\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n     {\n       mutex_lock l(mutex_);\n       if (!initialized_) {\n@@ -88,6 +92,9 @@ class InitializeTRTResource : public OpKernel {\n   }\n \n   void Compute(OpKernelContext* ctx) override {\n+    tensorflow::profiler::TraceMe activity(\n+        ""InitializeTRTResource::Compute"",\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n     ResourceHandle handle = HandleFromInput(ctx, 0);\n     core::RefCountPtr<TRTEngineCacheResource> resource;\n     OP_REQUIRES_OK(\n@@ -186,6 +193,9 @@ class SerializeTRTResource : public OpKernel {\n   }\n \n   void Compute(OpKernelContext* ctx) override {\n+    tensorflow::profiler::TraceMe activity(\n+        ""SerializeTRTResource::Compute"",\n+        tensorflow::profiler::TraceMeLevel::kInfo);\n     const string& resource_name = ctx->input(0).scalar<tstring>()();\n     const string& filename = ctx->input(1).scalar<tstring>()();\n     OP_REQUIRES(ctx, !filename.empty(),\ndiff --git a/tensorflow/compiler/tf2tensorrt/segment/segment.cc b/tensorflow/compiler/tf2tensorrt/segment/segment.cc\nindex d22aecc0c61aa..356d35f02a4ae 100644\n--- a/tensorflow/compiler/tf2tensorrt/segment/segment.cc\n+++ b/tensorflow/compiler/tf2tensorrt/segment/segment.cc\n@@ -37,6 +37,7 @@ limitations under the License.\n #include ""tensorflow/core/lib/strings/str_util.h""\n #include ""tensorflow/core/lib/strings/strcat.h""\n #include ""tensorflow/core/platform/types.h""\n+#include ""tensorflow/core/profiler/lib/traceme.h""\n #include ""tensorflow/core/util/env_var.h""\n \n #if GOOGLE_CUDA && GOOGLE_TENSORRT\n@@ -674,6 +675,8 @@ void AddSegmentForNode(const grappler::GraphProperties* graph_properties,\n                        SimpleNode* node,\n                        const DeviceNameUtils::ParsedName& device_name,\n                        bool use_implicit_batch) {\n+ tensorflow::profiler::TraceMe activity(\n+     ""AddSegmentForNode"", tensorflow::profiler::TraceMeLevel::kInfo);\n   ClusterProperty property(\n       GetClusterBatchSizeForNode(graph_properties,\n                                  node == nullptr ? nullptr : node->tf_node(),\n@@ -688,6 +691,9 @@ Status ExportNonConversionReportToCSV(\n     string filename,\n     std::map<string, std::map<string, int>>& nonconverted_ops_map,\n     string sep = ""|"") {\n+  tensorflow::profiler::TraceMe activity(\n+    ""ExportNonConversionReportToCSV"",\n+    tensorflow::profiler::TraceMeLevel::kInfo);\n   std::fstream csv_file(filename, std::fstream::out | std::fstream::trunc);\n \n   if (!csv_file || !csv_file.good()) {\n@@ -732,6 +738,8 @@ string GenerateNonConversionReport(\n   //                        Usage: TF_TRT_SHOW_DETAILED_REPORT=/path/to/file.csv\n   // - Else:                Print normal (undetailed) non-conversion report on\n   //                        stdout.\n+  tensorflow::profiler::TraceMe activity(\n+    ""GenerateNonConversionReport"", tensorflow::profiler::TraceMeLevel::kInfo);\n \n   string detailed_report_var;\n   TF_CHECK_OK(ReadStringFromEnvVar(""TF_TRT_SHOW_DETAILED_REPORT"",\n@@ -843,6 +851,8 @@ Status SegmentGraph(const Graph* tf_graph,\n                     const std::function<bool(const Edge*)>& input_candidate_fn,\n                     const std::function<bool(const Edge*)>& output_candidate_fn,\n                     const SegmentOptions& options, SegmentVector* segments) {\n+  tensorflow::profiler::TraceMe activity(\n+    ""SegmentGraph"", tensorflow::profiler::TraceMeLevel::kInfo);\n   if (!options.use_implicit_batch && !options.allow_dynamic_non_batch_dim) {\n     return errors::Internal(\n         ""Explicit batch mode should allow dynamic non-batch dimensions"");\n'",['[TF-TRT] Adding additional TraceMe ranges'],[],2022-10-18 16:22:49
58132,Refactor/update TensorFlow 2.11 RELEASE.md,,8bitmp3,[],[],['vinila21'],['vinila21'],[],"b'diff --git a/RELEASE.md b/RELEASE.md\nindex b329c07f65b8f..b960d862418e7 100644\n--- a/RELEASE.md\n+++ b/RELEASE.md\n@@ -6,25 +6,26 @@\n     *   **Checkpoint loading failure.** The new optimizer handles optimizer state differently from the old optimizer, which simplies the logic of\n         checkpoint saving/loading, but at the cost of breaking checkpoint backward compatibility in some cases. If you want to keep using an old\n         checkpoint, please change your optimizer to `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n-    *   **TF1 compatibility.** The new optimizer does not support TF1 any more, so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.\n+    *   **TF1 compatibility.** The new optimizer, `tf.keras.optimizers.Optimizer`, does not support TF1 any more, so please use the legacy optimizer\n+        `tf.keras.optimizer.legacy.XXX`.\n         We highly recommend to migrate your workflow to TF2 for stable support and new features.\n-    *   **API not found.** The new optimizer has a different set of public APIs from the old optimizer. These API changes are mostly related to\n-        getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives to the missing API. If you must\n-        call the deprecated API, please change your optimizer to the legacy optimizer.\n+    *   **Old optimizer API not found.** The new optimizer, `tf.keras.optimizers.Optimizer`, has a different set of public APIs from the old optimizer.\n+        These API changes are mostly related to getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives\n+        to the missing API. If you must call the deprecated API, please change your optimizer to the legacy optimizer.\n     *   **Learning rate schedule access.** When using a `LearningRateSchedule`, The new optimizer\'s `learning_rate` property returns the\n         current learning rate value instead of a `LearningRateSchedule` object as before. If you need to access the `LearningRateSchedule` object,\n         please use `optimizer._learning_rate`.\n-    *   **You implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass\n+    *   **If you implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass\n         `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new optimizer and find it does not support your optimizer, please file\n         an issue in the Keras GitHub repo.\n-    *   **Error such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first\n+    *   **Errors, such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first\n         `apply_gradients()` or `minimize()` call. If your workflow calls optimizer to update different parts of model in multiple stages,\n         please call `optimizer.build(model.trainable_variables)` before the training loop.\n     *   **Timeout or performance loss.** We don\'t anticipate this to happen, but if you see such issues, please use the legacy optimizer, and file\n         an issue in the Keras GitHub repo.\n \n-    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (e.g., `Adafactor`) will\n-    only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n+    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (for example,\n+    `tf.keras.optimizers.Adafactor`) will only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n \n ## Major Features and Improvements\n \n@@ -39,27 +40,28 @@\n \n *   `tf.experimental.StructuredTensor`\n \n-    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and Tensorflow-native way to encode structured data such as protocol\n+    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and TensorFlow-native way to encode structured data such as protocol\n         buffers or pandas dataframes.\n \n *   `tf.keras`:\n \n-    *   Added method `get_metrics_result()` to `tf.keras.models.Model`.\n+    *   Added a new `get_metrics_result()` method to `tf.keras.models.Model`.\n         *   Returns the current metrics values of the model as a dict.\n-    *   Added group normalization layer `tf.keras.layers.GroupNormalization`.\n+    *   Added a new group normalization layer - `tf.keras.layers.GroupNormalization`.\n     *   Added weight decay support for all Keras optimizers.\n     *   Added Adafactor optimizer `tf.keras.optimizers.Adafactor`.\n-    *   Added `warmstart_embedding_matrix` to `tf.keras.utils`. This utility can be used to warmstart an embeddings matrix so you\n-        reuse previously-learned word embeddings when working with a new set of words which may include previously unseen words (the embedding\n-        vectors for unseen words will be randomly initialized).\n+    *   Added `warmstart_embedding_matrix` to `tf.keras.utils`.\n+        *   This utility can be used to warmstart an embeddings matrix, so you reuse previously-learned word embeddings when working with a new set of\n+        words which may include previously unseen words (the embedding vectors for unseen words will be randomly initialized).\n \n *   `tf.Variable`:\n \n-    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`. This allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n-    *   Added a new constructor argument `experimental_enable_variable_lifting` to `tf.Variable`, defaulting to True. When it\'s `False`, the variable\n-        won\'t be lifted out of `tf.function`, thus it can be used as a `tf.function`-local variable: during each execution of the\n-        `tf.function`, the variable will be created and then disposed, similar to a local (i.e. stack-allocated) variable in C/C++. Currently\n-        `experimental_enable_variable_lifting=False` only works on non-XLA devices (e.g. under `@tf.function(jit_compile=False)`).\n+    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`.\n+        *   This allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n+    *   Added a new constructor argument `experimental_enable_variable_lifting` to `tf.Variable`, defaulting to True.\n+        *   When it\'s `False`, the variable won\'t be lifted out of `tf.function`, thus it can be used as a `tf.function`-local variable: during each\n+        execution of the `tf.function`, the variable will be created and then disposed, similar to a local (that is, stack-allocated) variable in C/C++. \n+        Currently, `experimental_enable_variable_lifting=False` only works on non-XLA devices (for example, under `@tf.function(jit_compile=False)`).\n \n *   TF SavedModel:\n     *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb` file is a protobuf containing the ""fingerprint"" of the SavedModel. See\n'",['Refactor/update TensorFlow 2.11 RELEASE.md'],[],2022-10-17 23:08:10
58130,Fix minor typos in release notes,,mihaimaruseac,[],[],['bhack'],['bhack'],"['learning-to-play', 'vinila21']","b'diff --git a/RELEASE.md b/RELEASE.md\nindex b329c07f65b8f..e63e3845deff5 100644\n--- a/RELEASE.md\n+++ b/RELEASE.md\n@@ -30,12 +30,9 @@\n \n *   `tf.lite`:\n \n-    *   New operations supported:\n-          * tf.unsortedsegmentmin op is supported.\n-          * tf.atan2 op is supported.\n-          * tf.sign op is supported.\n+    *   New operations supported: `tf.unsortedsegmentmin`, `tf.atan2` and `tf.sign`.\n     *   Updates to existing operations:\n-          * tfl.mul now supports complex32 inputs.\n+          * `tfl.mul` now supports complex32 inputs.\n \n *   `tf.experimental.StructuredTensor`\n \n@@ -75,7 +72,7 @@\n \n     *   `tf.custom_gradient` can now be applied to functions that accept ""composite"" tensors, such as `tf.RaggedTensor`, as inputs.\n     *   Fix device placement issues related to datasets with ragged tensors of strings (i.e. variant encoded data with types not supported on GPU).\n-    *   \'experimental_follow_type_hints\' for tf.function has been deprecated. Please use input_signature or reduce_retracing to minimize retracing.\n+    *   `experimental_follow_type_hints` for tf.function has been deprecated. Please `use input_signature` or `reduce_retracing` to minimize retracing.\n \n *   `tf.SparseTensor`:\n     *   Introduced `set_shape`, which sets the static dense shape of the sparse tensor and has the same semantics as `tf.Tensor.set_shape`.\n'",['Fix minor typos in release notes'],[],2022-10-17 22:22:07
58129,Update version numbers for TensorFlow 2.11.0-rc0,"Before merging this PR, please double check that it has correctly updated
`core/public/version.h`, `tools/pip_package/setup.py`, and
`tensorflow/tensorflow.bzl`. Also review the execution notes below:

```
Major: 2 -> 2
Minor: 11 -> 11
Patch: 0 -> 0

WARNING: Below are potentially instances of lingering old version string 
""2.11.0"" in source directory ""tensorflow/"" that are not updated by this script. 
Please check them manually!
tensorflow/lite/tools/versioning/runtime_version.cc:157:2.11.0
tensorflow/lite/tools/versioning/runtime_version.cc:386:2.11.0
tensorflow/lite/tools/versioning/runtime_version.cc:389:2.11.0
tensorflow/tensorflow.bzl:65:2.11.0
tensorflow/tools/ci_build/release/requirements_common.txt:26:2.11.0
tensorflow/tools/pip_package/setup.py:49:2.11.0
tensorflow/tools/pip_package/setup.py:122:2.11.0
tensorflow/tools/pip_package/setup.py:124:2.11.0
tensorflow/tools/pip_package/setup.py:126:2.11.0
tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt:32:2.11.0
tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt:34:2.11.0
Binary file 
tensorflow/cc/saved_model/testdata/OptimizerSlotVariableModule/saved_model.pb 
matches

WARNING: Below are potentially instances of lingering old version string 
""2.11.0"" in source directory ""tensorflow/"" that are not updated by this script. 
Please check them manually!
tensorflow/lite/tools/versioning/runtime_version.cc:157:2.11.0
tensorflow/lite/tools/versioning/runtime_version.cc:386:2.11.0
tensorflow/lite/tools/versioning/runtime_version.cc:389:2.11.0
tensorflow/tensorflow.bzl:65:2.11.0
tensorflow/tools/ci_build/release/requirements_common.txt:26:2.11.0
tensorflow/tools/pip_package/setup.py:49:2.11.0
tensorflow/tools/pip_package/setup.py:122:2.11.0
tensorflow/tools/pip_package/setup.py:124:2.11.0
tensorflow/tools/pip_package/setup.py:126:2.11.0
tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt:32:2.11.0
tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt:34:2.11.0
Binary file 
tensorflow/cc/saved_model/testdata/OptimizerSlotVariableModule/saved_model.pb 
matches
```",tensorflow-jenkins,[],[],"['vinila21', 'learning-to-play', 'learning-to-play']","['vinila21', 'learning-to-play', 'learning-to-play']",[],"b'diff --git a/tensorflow/core/public/version.h b/tensorflow/core/public/version.h\nindex 2a94515d20d14..3b79a3de04cb6 100644\n--- a/tensorflow/core/public/version.h\n+++ b/tensorflow/core/public/version.h\n@@ -26,7 +26,7 @@ limitations under the License.\n \n // TF_VERSION_SUFFIX is non-empty for pre-releases (e.g. ""-alpha"", ""-alpha.1"",\n // ""-beta"", ""-rc"", ""-rc.1"")\n-#define TF_VERSION_SUFFIX """"\n+#define TF_VERSION_SUFFIX ""-rc0""\n \n #define TF_STR_HELPER(x) #x\n #define TF_STR(x) TF_STR_HELPER(x)\ndiff --git a/tensorflow/tools/pip_package/setup.py b/tensorflow/tools/pip_package/setup.py\nindex cc23caac4cb8b..095ef5970f8aa 100644\n--- a/tensorflow/tools/pip_package/setup.py\n+++ b/tensorflow/tools/pip_package/setup.py\n@@ -46,7 +46,7 @@\n # result for pip.\n # Also update tensorflow/tensorflow.bzl and\n # tensorflow/core/public/version.h\n-_VERSION = \'2.11.0\'\n+_VERSION = \'2.11.0-rc0\'\n \n \n # We use the same setup.py for all tensorflow_* packages and for the nightly\n'",['Update version numbers to 2.11.0-rc0'],[],2022-10-17 21:08:57
58128,Update release notes for TensorFlow 2.11.0,"This PR is intentionally incomplete. One of the Release Owners for 2.11.0
needs to fill in the internal release notes for this version before the PR gets
submitted. Click on the :pencil2: icon in the header for `RELEASE.md` under
""Files Changed"" above.",tensorflow-jenkins,[],[],"['rishikasinha-tf', 'learning-to-play']","['rishikasinha-tf', 'learning-to-play']",[],"b'diff --git a/RELEASE.md b/RELEASE.md\nindex 0fa310871fb1c..b329c07f65b8f 100644\n--- a/RELEASE.md\n+++ b/RELEASE.md\n@@ -1,63 +1,30 @@\n # Release 2.11.0\n \n-<INSERT SMALL BLURB ABOUT RELEASE FOCUS AREA AND POTENTIAL TOOLCHAIN CHANGES>\n-\n-* `tensorflow::StatusOr::ConsumeValueOrDie`, deprecated in TF 2.10 has been\n-  removed.\n-\n ## Breaking Changes\n-*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and\n-    old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.\n-    If you find your workflow failing due to this change,\n-    you may be facing one of the following issues:\n-\n-    *   **Checkpoint loading failure.** The new optimizer handles optimizer\n-        state differently from the old optimizer, which simplies the logic of\n-        checkpoint saving/loading, but at the cost of breaking checkpoint\n-        backward compatibility in some cases. If you want to keep using an old\n-        checkpoint, please change your optimizer to\n-        `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n-    *   **TF1 compatibility.** The new optimizer does not support TF1 any more,\n-        so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.\n-        We highly recommend to migrate your workflow to TF2 for stable\n-        support and new features.\n-    *   **API not found.** The new optimizer has a different set of public APIs\n-        from the old optimizer. These API changes are mostly related to\n-        getting rid of slot variables and TF1 support. Please check the API\n-        documentation to find alternatives to the missing API. If you must\n-        call the deprecated API, please change your optimizer to the legacy\n-        optimizer.\n-    *   **Learning rate schedule access.** When using a `LearningRateSchedule`,\n-        The new optimizer\'s `learning_rate` property returns the\n-        current learning rate value instead of a `LearningRateSchedule` object\n-        as before. If you need to access the `LearningRateSchedule` object,\n+*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.\n+    If you find your workflow failing due to this change, you may be facing one of the following issues:\n+    *   **Checkpoint loading failure.** The new optimizer handles optimizer state differently from the old optimizer, which simplies the logic of\n+        checkpoint saving/loading, but at the cost of breaking checkpoint backward compatibility in some cases. If you want to keep using an old\n+        checkpoint, please change your optimizer to `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\n+    *   **TF1 compatibility.** The new optimizer does not support TF1 any more, so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.\n+        We highly recommend to migrate your workflow to TF2 for stable support and new features.\n+    *   **API not found.** The new optimizer has a different set of public APIs from the old optimizer. These API changes are mostly related to\n+        getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives to the missing API. If you must\n+        call the deprecated API, please change your optimizer to the legacy optimizer.\n+    *   **Learning rate schedule access.** When using a `LearningRateSchedule`, The new optimizer\'s `learning_rate` property returns the\n+        current learning rate value instead of a `LearningRateSchedule` object as before. If you need to access the `LearningRateSchedule` object,\n         please use `optimizer._learning_rate`.\n-    *   **You implemented a custom optimizer based on the old optimizer.**\n-        Please set your optimizer to subclass\n-        `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new\n-        optimizer and find it does not support your optimizer, please file\n+    *   **You implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass\n+        `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new optimizer and find it does not support your optimizer, please file\n         an issue in the Keras GitHub repo.\n-    *   **Error such as `Cannot recognize variable...`.** The new optimizer\n-        requires all optimizer variables to be created at the first\n-        `apply_gradients()` or `minimize()` call. If your workflow calls\n-        optimizer to update different parts of model in multiple stages,\n-        please call `optimizer.build(model.trainable_variables)` before the\n-        training loop.\n-    *   **Timeout or performance loss.** We don\'t anticipate this to happen, but\n-        if you see such issues, please use the legacy optimizer, and file\n+    *   **Error such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first\n+        `apply_gradients()` or `minimize()` call. If your workflow calls optimizer to update different parts of model in multiple stages,\n+        please call `optimizer.build(model.trainable_variables)` before the training loop.\n+    *   **Timeout or performance loss.** We don\'t anticipate this to happen, but if you see such issues, please use the legacy optimizer, and file\n         an issue in the Keras GitHub repo.\n \n-    The old Keras optimizer will never be deleted, but will not see any\n-    new feature additions.\n-    New optimizers (e.g., `Adafactor`) will\n-    only be implemented based on `tf.keras.optimizers.Optimizer`, the new\n-    base class.\n-\n-## Known Caveats\n-\n-* <CAVEATS REGARDING THE RELEASE (BUT NOT BREAKING CHANGES).>\n-* <ADDING/BUMPING DEPENDENCIES SHOULD GO HERE>\n-* <KNOWN LACK OF SUPPORT ON SOME PLATFORM, SHOULD GO HERE>\n+    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (e.g., `Adafactor`) will\n+    only be implemented based on `tf.keras.optimizers.Optimizer`, the new base class.\n \n ## Major Features and Improvements\n \n@@ -72,8 +39,7 @@\n \n *   `tf.experimental.StructuredTensor`\n \n-    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible\n-        and Tensorflow-native way to encode structured data such as protocol\n+    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and Tensorflow-native way to encode structured data such as protocol\n         buffers or pandas dataframes.\n \n *   `tf.keras`:\n@@ -83,46 +49,33 @@\n     *   Added group normalization layer `tf.keras.layers.GroupNormalization`.\n     *   Added weight decay support for all Keras optimizers.\n     *   Added Adafactor optimizer `tf.keras.optimizers.Adafactor`.\n-    *   Added `warmstart_embedding_matrix` to `tf.keras.utils`.\n-        This utility can be used to warmstart an embeddings matrix so you\n-        reuse previously-learned word embeddings when working with a new set\n-        of words which may include previously unseen words (the embedding\n+    *   Added `warmstart_embedding_matrix` to `tf.keras.utils`. This utility can be used to warmstart an embeddings matrix so you\n+        reuse previously-learned word embeddings when working with a new set of words which may include previously unseen words (the embedding\n         vectors for unseen words will be randomly initialized).\n \n *   `tf.Variable`:\n \n-    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`. This\n-        allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n-    *   Added a new constructor argument `experimental_enable_variable_lifting`\n-        to `tf.Variable`, defaulting to True. When it\'s `False`, the variable\n-        won\'t be lifted out of `tf.function`, thus it can be used as a\n-        `tf.function`-local variable: during each execution of the\n-        `tf.function`, the variable will be created and then disposed, similar\n-        to a local (i.e. stack-allocated) variable in C/C++. Currently\n-        `experimental_enable_variable_lifting=False` only works on non-XLA\n-        devices (e.g. under `@tf.function(jit_compile=False)`).\n+    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`. This allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n+    *   Added a new constructor argument `experimental_enable_variable_lifting` to `tf.Variable`, defaulting to True. When it\'s `False`, the variable\n+        won\'t be lifted out of `tf.function`, thus it can be used as a `tf.function`-local variable: during each execution of the\n+        `tf.function`, the variable will be created and then disposed, similar to a local (i.e. stack-allocated) variable in C/C++. Currently\n+        `experimental_enable_variable_lifting=False` only works on non-XLA devices (e.g. under `@tf.function(jit_compile=False)`).\n \n *   TF SavedModel:\n-    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb`\n-        file is a protobuf containing the ""fingerprint"" of the SavedModel. See\n-        the [RFC](https://github.com/tensorflow/community/pull/415) for more\n-        details regarding its design and properties.\n+    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb` file is a protobuf containing the ""fingerprint"" of the SavedModel. See\n+        the [RFC](https://github.com/tensorflow/community/pull/415) for more details regarding its design and properties.\n \n ## Bug Fixes and Other Changes\n \n *   `tf.image`\n-    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which\n-        causes the returned value to be the local SSIM map instead of the global\n+    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which causes the returned value to be the local SSIM map instead of the global\n         mean.\n \n *   TF Core:\n \n-    *   `tf.custom_gradient` can now be applied to functions that accept\n-        ""composite"" tensors, such as `tf.RaggedTensor`, as inputs.\n-    *   Fix device placement issues related to datasets with ragged tensors of\n-        strings (i.e. variant encoded data with types not supported on GPU).\n-    *   \'experimental_follow_type_hints\' for tf.function has been deprecated.\n-        Please use input_signature or reduce_retracing to minimize retracing.\n+    *   `tf.custom_gradient` can now be applied to functions that accept ""composite"" tensors, such as `tf.RaggedTensor`, as inputs.\n+    *   Fix device placement issues related to datasets with ragged tensors of strings (i.e. variant encoded data with types not supported on GPU).\n+    *   \'experimental_follow_type_hints\' for tf.function has been deprecated. Please use input_signature or reduce_retracing to minimize retracing.\n \n *   `tf.SparseTensor`:\n     *   Introduced `set_shape`, which sets the static dense shape of the sparse tensor and has the same semantics as `tf.Tensor.set_shape`.\n@@ -131,7 +84,8 @@\n \n This release contains contributions from many people at Google, as well as:\n \n-<INSERT>, <NAME>, <HERE>, <USING>, <GITHUB>, <HANDLE>\n+103yiran, 8bitmp3, Aakar Dwivedi, Alexander Grund, alif_elham, Aman Agarwal, amoitra, Andrei Ivanov, andreii, Andrew Goodbody, angerson, Ashay Rane, Azeem Shaikh, Ben Barsdell, bhack, Bhavani Subramanian, Cedric Nugteren, Chandra Kumar Ramasamy, Christopher Bate, CohenAriel, Cotarou, cramasam, Enrico Minack, Francisco Unda, Frederic Bastien, gadagashwini, Gauri1 Deshpande, george, Jake, Jeff, Jerry Ge, Jingxuan He, Jojimon Varghese, Jonathan Dekhtiar, Kaixi Hou, Kanvi Khanna, kcoul, Keith Smiley, Kevin Hu, Kun Lu, kushanam, Lianmin Zheng, liuyuanqiang, Louis Sugy, Mahmoud Abuzaina, Marius Brehler, mdfaijul, Meenakshi Venkataraman, Milos Puzovic, mohantym, Namrata-Ibm, Nathan John Sircombe, Nathan Luehr, Olaf Lipinski, Om Thakkar, Osman F Bayram, Patrice Vignola, Pavani Majety, Philipp Hack, Prianka Liz Kariat, Rahul Batra, RajeshT, Renato Golin, riestere, Roger Iyengar, Rohit Santhanam, Rsanthanam-Amd, Sadeed Pv, Samuel Marks, Shimokawa, Naoaki, Siddhesh Kothadi, Simengliu-Nv, Sindre Seppola, snadampal, Srinivasan Narayanamoorthy, sushreebarsa, syedshahbaaz, Tamas Bela Feher, Tatwai Chong, Thibaut Goetghebuer-Planchon, tilakrayal, Tom Anderson, Tomohiro Endo, Trevor Morris, vibhutisawant, Victor Zhang, Vremold, Xavier Bonaventura, Yanming Wang, Yasir Modak, Yimei Sun, Yong Tang, Yulv-Git, zhuoran.liu, zotanika\n+\n \n # Release 2.10.0\n \n'","['Insert release notes place-fill', 'Update release notes for TensorFlow 2.11.0\n\nUpdate release notes for TensorFlow 2.11.0']",[],2022-10-17 19:31:08
58121,[ROCm] Absorb fix for the LLVM AMDGPU backend addition of fp16 support of ne…,"…arbyint.

The following LLVM commit adds fp16 support for the nearbyint intrinsic on the AMDGPU backend:

https://github.com/llvm/llvm-project/commit/6370bc2435a8406898eee7338ae7d795a252ad04",rsanthanam-amd,['rsanthanam-amd'],['/cc @cheshire '],['cheshire'],['cheshire'],['gbaned'],"b'diff --git a/tensorflow/compiler/xla/service/elemental_ir_emitter.cc b/tensorflow/compiler/xla/service/elemental_ir_emitter.cc\nindex 296696d33acd8..feddf2ece0e0a 100644\n--- a/tensorflow/compiler/xla/service/elemental_ir_emitter.cc\n+++ b/tensorflow/compiler/xla/service/elemental_ir_emitter.cc\n@@ -524,11 +524,7 @@ StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n     // instead once GPU emitter supports lowering LLVM.\n     case HloOpcode::kRoundNearestEven:\n       return llvm_ir::EmitCallToIntrinsic(\n-#if TENSORFLOW_USE_ROCM\n-          llvm::Intrinsic::rint,\n-#else\n           llvm::Intrinsic::nearbyint,\n-#endif\n           {operand_value}, {operand_value->getType()}, b_);\n     case HloOpcode::kSign: {\n       auto type = operand_value->getType();\n'",['Absorb fix for the LLVM AMDGPU backend addition of fp16 support of nearbyint.\n\nThe following LLVM commit adds fp16 support for the nearbyint intrinsic on the AMDGPU backend:\n\nhttps://github.com/llvm/llvm-project/commit/6370bc2435a8406898eee7338ae7d795a252ad04'],[],2022-10-17 13:57:33
58116,Updated Dockerfile.rocm,"The rocm build was failing due to requirement of python3-pip. The current python-pip is obsolete.

Following is the error that it shows on jenkins:
```terminal
Fetched 29.0 kB in 1s (24.2 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
Package python-pip is not available, but is referred to by another package.
This may mean that the package is missing, has been obsoleted, or
is only available from another source
However the following packages replace it:
  python3-pip

E: Package 'python-pip' has no installation candidate
The command '/bin/sh -c apt-get update --allow-insecure-repositories && DEBIAN_FRONTEND=noninteractive apt-get install -y   build-essential   bsdmainutils   clang-6.0   clang-format-6.0   clang-tidy-6.0   cmake   cmake-qt-gui   ssh   curl   apt-utils   pkg-config   g++-multilib   git   kmod   libunwind-dev   libfftw3-dev   libelf-dev   libncurses5-dev   libpthread-stubs0-dev   vim   gfortran   libboost-program-options-dev   libssl-dev   libboost-dev   libboost-system-dev   libboost-filesystem-dev   rpm   libnuma-dev   pciutils   virtualenv   python-pip   libxml2   libxml2-dev   wget &&   apt-get clean &&   rm -rf /var/lib/apt/lists/*' returned a non-zero code: 100
ERROR: docker build failed. Dockerfile is at /home/jenkins/workspace/ROCm-Community-CI-Build_PR-58103/tensorflow/tools/ci_build/Dockerfile.rocm
```",Abinashbunty,['mihaimaruseac'],['Please write better commit messages and PR titles. See https://cbea.ms/git-commit/'],['mihaimaruseac'],['mihaimaruseac'],['gbaned'],"b'diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md\nindex 943fdc3f28e20..c16619387641d 100644\n--- a/CONTRIBUTING.md\n+++ b/CONTRIBUTING.md\n@@ -15,47 +15,64 @@ Before sending your pull requests, make sure you do the following:\n \n ## How to become a contributor and submit your own code\n \n-![Screen Shot 2022-08-30 at 7 27 04 PM](https://user-images.githubusercontent.com/42785357/187579207-9924eb32-da31-47bb-99f9-d8bf1aa238ad.png)\n-\n-### Typical Pull Request Workflow -\n-\n-**1. New PR** - As a contributor, you submit a New PR on GitHub. - We inspect\n-every incoming PR and add certain labels to the PR such as `size:`, `comp:` etc.\n-At this stage we check if the PR is valid and meets certain quality\n-requirements. - For example - We check if the CLA is signed, PR has sufficient\n-description, if applicable unit tests are added, if it is a reasonable\n-contribution meaning it is not a single liner cosmetic PR.\n-\n-**2. Valid?** - If the PR passes all the quality checks then we go ahead and\n-assign a reviewer. - If the PR didn\'t meet the validation criteria, we request\n-for additional changes to be made to PR to pass quality checks and send it back\n-or on a rare occassion we may reject it.\n-\n-**3. Review** - For Valid PR, reviewer (person familiar with the\n-code/functionality) checks if the PR looks good or needs additional changes. -\n-If all looks good, reviewer would approve the PR. - If a change is needed, the\n-contributor is requested to make suggested change. - You make the change and\n-submit for the review again. - This cycle repeats itself till the PR gets\n-approved. - Note: As a friendly reminder we may reach out to you if the PR is\n-awaiting your response for more than 2 weeks.\n-\n-**4. Approved** - Once the PR is approved, it gets `kokoro:force-run` label\n-applied and it initiates CI/CD tests. - We can\'t move forward if theses tests\n-fail. - In such situations, we may request you to make further changes to your\n-PR for the tests to pass. - Once the tests pass, we now bring all the code in\n-the internal code base, using a job called ""copybara"".\n-\n-**5. Copy to G3** - Once the PR is in Google codebase, we make sure it\n-integrates well with its dependencies and the rest of the system. - Rarely, but\n-If the tests fail at this stage, we cannot merge the code. - If needed, we may\n-come to you to make some changes. - At times, it may not be you, it may be us\n-who may have hit a snag. - Please be patient while we work to fix this. - Once\n-the internal tests pass, we go ahead and merge the code internally as well as\n-externally on GitHub.\n-\n-### Contributor License Agreements\n-\n-We\'d love to accept your patches! Before we can take them, we have to jump a couple of legal hurdles.\n+```mermaid\n+flowchart LR\n+A(New PR) ---> B{Valid}\n+B --> |Yes| C(Review)\n+B --> |No| D(Send back/Reject)\n+C --> E{Need change}\n+E --> |No| F(Approved)\n+E --> |Yes| G(Change requested)\n+G --> C\n+F --> H{Kokoro tests}\n+H --> |Fail| G\n+H --> |Pass| I(Copy to G3)\n+I --> J{Run tests}\n+J --> |Fail| G\n+J -----> |Pass| K(Merged)\n+\n+click A ""https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#1-new-pr"" _blank\n+click B ""https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#2-valid"" _blank\n+click C ""https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#3-review"" _blank\n+click F ""https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#4-approved"" _blank\n+click I ""https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#5-copy-to-g3"" _blank\n+```\n+\n+## Typical Pull Request Workflow\n+\n+### 1. New PR\n+- As a contributor, you submit a New PR on GitHub. \n+- We inspect every incoming PR and add certain labels to the PR such as `size:`, `comp:` etc. At this stage we check if the PR is valid and meets certain quality requirements. \n+- For example: We check if the CLA is signed, PR has sufficient description, if applicable unit tests are added and if it is a reasonable contribution, i.e., it is not a single liner cosmetic PR.\n+\n+### 2. Valid?\n+- If the PR passes all the quality checks then we go ahead and assign a reviewer.\n+- If the PR does not meet the validation criteria, we request for additional changes to be made to the PR to pass quality checks and send it back or on a rare occassion, we may reject it.\n+\n+### 3. Review\n+- For a valid PR, the reviewer (person familiar with the code/functionality) checks if the PR looks good or needs additional changes. \n+- If all looks good, the reviewer will approve the PR.\n+- If a change is needed, you (the contributor) are requested to make the suggested change.\n+- You make the change and submit for the review again. This cycle repeats itself till the PR gets approved.\n+\n+> Note: As a friendly reminder we may reach out to you if the PR is awaiting your response for more than 2 weeks.\n+\n+### 4. Approved\n+- Once the PR is approved, it gets the `kokoro:force-run` label applied and it initiates CI/CD tests.\n+- We can\'t move forward if these tests fail.\n+- If the tests fail, we may request you to make further changes to your PR for the tests to pass.\n+- Once the tests pass, we now bring all the code in the internal code base, using a job called ""copybara"".\n+\n+### 5. Copy to G3\n+- Once the PR is in Google codebase, we make sure it integrates well with its dependencies and the rest of the system.\n+- Rarely, the tests might fail at this stage. If they do fail, we cannot merge the code.\n+- If needed, we may ask you to make some changes.\n+- At times, it may not be you, it may be us who may have hit a snag. Please be patient while we work to fix this.\n+- Once the internal tests pass, we go ahead and merge the code internally as well as externally on GitHub.\n+\n+## Contributor License Agreements\n+\n+We love to accept your patches! But before we can take them, we have to jump a couple of legal hurdles.\n \n Please fill out either the individual or corporate Contributor License Agreement (CLA).\n \n@@ -64,34 +81,15 @@ Please fill out either the individual or corporate Contributor License Agreement\n \n Follow either of the two links above to access the appropriate CLA and instructions for how to sign and return it. Once we receive it, we\'ll be able to accept your pull requests.\n \n-***NOTE***: Only original source code from you and other people that have signed the CLA can be accepted into the main repository.\n+> NOTE: Only original source code from you and other people that have signed the CLA can be accepted into the main repository.\n \n ### Contributing code\n \n-If you have improvements to TensorFlow, send us your pull requests! For those\n-just getting started, Github has a\n-[how to](https://help.github.com/articles/using-pull-requests/).\n-\n-TensorFlow team members will be assigned to review your pull requests. Once the\n-pull requests are approved and pass continuous integration checks, a TensorFlow\n-team member will apply `ready to pull` label to your change. This means we are\n-working on getting your pull request submitted to our internal repository. After\n-the change has been submitted internally, your pull request will be merged\n-automatically on GitHub.\n-\n-If you want to contribute, start working through the TensorFlow codebase,\n-navigate to the\n-[Github ""issues"" tab](https://github.com/tensorflow/tensorflow/issues) and start\n-looking through interesting issues. If you are not sure of where to start, then\n-start by trying one of the smaller/easier issues here i.e.\n-[issues with the ""good first issue"" label](https://github.com/tensorflow/tensorflow/labels/good%20first%20issue)\n-and then take a look at the\n-[issues with the ""contributions welcome"" label](https://github.com/tensorflow/tensorflow/labels/stat%3Acontributions%20welcome).\n-These are issues that we believe are particularly well suited for outside\n-contributions, often because we probably won\'t get to them right now. If you\n-decide to start on an issue, leave a comment so that other people know that\n-you\'re working on it. If you want to help out, but not alone, use the issue\n-comment thread to coordinate.\n+If you have improvements to TensorFlow, send us your pull requests! For those just getting started, Github has a [how to](https://help.github.com/articles/using-pull-requests/).\n+\n+TensorFlow team members will be assigned to review your pull requests. Once the pull requests are approved and pass continuous integration checks, a TensorFlow team member will apply `ready to pull` label to your change. This means we are working on getting your pull request submitted to our internal repository. After the change has been submitted internally, your pull request will be merged automatically on GitHub.\n+\n+If you want to contribute, start working through the TensorFlow codebase, navigate to the Github [""issues""](https://github.com/tensorflow/tensorflow/issues) tab and start looking through interesting issues. If you are not sure of where to start, then start by trying one of the smaller/easier issues here i.e. issues with the [""good first issue""](https://github.com/tensorflow/tensorflow/labels/good%20first%20issue) label and then take a look at the issues with the [""contributions welcome""](https://github.com/tensorflow/tensorflow/labels/stat%3Acontributions%20welcome) label. These are issues that we believe are particularly well suited for outside contributions, often because we probably won\'t get to them right now. If you decide to start working on an issue, leave a comment so that other people know that you\'re working on it. If you want to help out, but not alone, use the issue comment thread to coordinate.\n \n ### Contribution guidelines and standards\n \n@@ -126,12 +124,12 @@ TensorFlow coding style.\n     airtime before a decision is made regarding whether they are to be migrated\n     to the core.\n *   As every PR requires several CPU/GPU hours of CI testing, we discourage\n-    submitting PRs to fix one typo, one warning,etc. We recommend fixing the\n+    submitting PRs to fix one typo, one warning, etc. We recommend fixing the\n     same issue at the file level at least (e.g.: fix all typos in a file, fix\n-    all compiler warning in a file, etc.)\n-*   Tests should follow the\n-    [testing best practices](https://www.tensorflow.org/community/contribute/tests)\n+    all compiler warnings in a file, etc.)\n+*   Tests should follow the [TensorFlow testing best practices](https://www.tensorflow.org/community/contribute/tests)\n     guide.\n+    \n \n #### License\n \n@@ -141,8 +139,7 @@ Include a license at the top of new files.\n * [Python license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn.py#L1)\n * [Java license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/Graph.java#L1)\n * [Go license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/operation.go#L1)\n-* [Bash license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_sanity.sh#L2)\n-* [HTML license example](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/components/tf_backend/tf-backend.html#L2)\n+* [Bash license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/code_link_check.sh#L2)\n * [JavaScript/TypeScript license example](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/components/tf_backend/backend.ts#L1)\n \n Bazel BUILD files also need to include a license section, e.g.,\n@@ -180,14 +177,13 @@ pip install pylint\n pylint --rcfile=tensorflow/tools/ci_build/pylintrc myfile.py\n ```\n \n-Note `pylint --rcfile=tensorflow/tools/ci_build/pylintrc` should run from the\n-top level tensorflow directory.\n+> Note `pylint --rcfile=tensorflow/tools/ci_build/pylintrc` should run from the top level tensorflow directory.\n \n #### Coding style for other languages\n \n * [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html)\n * [Google JavaScript Style Guide](https://google.github.io/styleguide/jsguide.html)\n-* [Google Shell Style Guide](https://google.github.io/styleguide/shell.xml)\n+* [Google Shell Style Guide](https://google.github.io/styleguide/shellguide.html)\n * [Google Objective-C Style Guide](https://google.github.io/styleguide/objcguide.html)\n \n #### Running sanity check\n@@ -316,9 +312,7 @@ There are two ways to test the code in the docstring locally:\n \n #### Debug builds\n \n-When [building Tensorflow](https://www.tensorflow.org/install/source), passing\n-`--config=dbg` to Bazel will build with debugging information and without\n-optimizations, allowing you to use GDB or other debuggers to debug C++ code. For\n+When [building Tensorflow](https://www.tensorflow.org/install/source) from source, if `--config=dbg` is passed to Bazel, it will build *with* debugging information and *without* optimizations, allowing you to use GDB or other debuggers to debug C++ code. For\n example, you can build the pip package with debugging information by running:\n \n ```bash\n@@ -337,4 +331,4 @@ op, which are in files starting with `identity_op`, you can run\n bazel build --config=dbg --per_file_copt=+tensorflow/core/kernels/identity_op.*@-g //tensorflow/tools/pip_package:build_pip_package\n ```\n \n-Note that the `--config=dbg` option is not officially supported.\n+> Note: the `--config=dbg` option is not officially supported.\ndiff --git a/tensorflow/tools/ci_build/Dockerfile.rocm b/tensorflow/tools/ci_build/Dockerfile.rocm\nindex 47997e7e9daa6..16645e879f4f1 100644\n--- a/tensorflow/tools/ci_build/Dockerfile.rocm\n+++ b/tensorflow/tools/ci_build/Dockerfile.rocm\n@@ -54,7 +54,7 @@ RUN apt-get update --allow-insecure-repositories && DEBIAN_FRONTEND=noninteracti\n   libnuma-dev \\\n   pciutils \\\n   virtualenv \\\n-  python-pip \\\n+  python3-pip \\\n   libxml2 \\\n   libxml2-dev \\\n   wget && \\\n'","['Update CONTRIBUTING.md\n\n1. Included a mermaid flowchart for PR Workflow.\r\n2. Fixed typos and broken links.\r\n3. Organised the file with new layout for better readability.', ""Merge branch 'tensorflow:master' into master"", 'Update Dockerfile.rocm']",[],2022-10-17 09:38:32
58113,Update tf_env_collect.sh,Removed Unnecessary Blank Lines.,TarunUM,['mihaimaruseac'],"[""Let's keep the code as it is, there is no actual benefit of taking this PR.""]",[],[],['gbaned'],"b'diff --git a/tools/tf_env_collect.sh b/tools/tf_env_collect.sh\nindex 11e60a512a775..431b0f3d92b0f 100755\n--- a/tools/tf_env_collect.sh\n+++ b/tools/tf_env_collect.sh\n@@ -103,8 +103,7 @@ ${python_bin_path} /tmp/check_os.py 2>&1  >> ${OUTPUT_FILE}\n   \n   echo\n   echo \'== check pips ===================================================\'\n-  pip list 2>&1 | grep ""proto\\|numpy\\|tensorflow""\n-  \n+  pip list 2>&1 | grep ""proto\\|numpy\\|tensorflow""  \n   \n   echo\n   echo \'== check for virtualenv =========================================\'\n@@ -141,7 +140,6 @@ LD_DEBUG=libs ${python_bin_path} -c ""import tensorflow""  2>>${OUTPUT_FILE} > /tm\n     echo DYLD_LIBRARY_PATH ${DYLD_LIBRARY_PATH} ;\n   fi\n   \n-  \n   echo\n   echo \'== nvidia-smi ===================================================\'\n   nvidia-smi 2>&1\n@@ -177,4 +175,3 @@ echo ""and use it to populate the fields in the github issue template.""\n echo\n echo ""cat ${OUTPUT_FILE}""\n echo\n-\n'",['Update tf_env_collect.sh'],[],2022-10-17 03:06:31
58110,Errorsolve,There was a grammatical mistake in a one of comment in pywrap_sanitizers.py,AroojSyed,"['mihaimaruseac', 'gbaned']","['@AroojSyed Can you please sign CLA. Thank you!', ""\r\nLet's keep the code as it is, there is no actual benefit of taking this PR.\r\n\r\n""]",[],[],['gbaned'],"b'diff --git a/tensorflow/python/pywrap_sanitizers.py b/tensorflow/python/pywrap_sanitizers.py\nindex 2840fd2db61fa..fafb6974f3872 100644\n--- a/tensorflow/python/pywrap_sanitizers.py\n+++ b/tensorflow/python/pywrap_sanitizers.py\n@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-""""""Python module for sanitizer detection functions exported by pybind11.""""""\n+""""""pybind11: a Python module for sanitizer detection functions exported by python.""""""\n \n # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\n from tensorflow.python import pywrap_tensorflow\ndiff --git a/tensorflow/python/pywrap_tfe.py b/tensorflow/python/pywrap_tfe.py\nindex d2da304a3ff67..15619709842b4 100644\n--- a/tensorflow/python/pywrap_tfe.py\n+++ b/tensorflow/python/pywrap_tfe.py\n@@ -12,12 +12,13 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-""""""Python module for TFE ops and functions exported by pybind11.\n+""""""The Python module for TFE ops and functions exported by pybind11\n \n-This module is created because we are splitting out eager bindings from\n-pywrap_tensorflow. This is causing some issues where Graphs are not properly\n-initialized when running eager code. Once the graph architecture has been\n-removed from pywrap_tensorflow as well, we can remove this file.\n+\n+This module was created because we are splitting out eager bindings from\n+pywrap_tensorflow. This is causing some issues where graphs are not properly\n+initialised when running eager code. Once the graph architecture has been\n+This file can be removed from pywrap_tensorflow as well.\n """"""\n \n # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\ndiff --git a/tensorflow/python/tf2.py b/tensorflow/python/tf2.py\nindex bce72186790db..9719e9317650a 100644\n--- a/tensorflow/python/tf2.py\n+++ b/tensorflow/python/tf2.py\n@@ -14,10 +14,11 @@\n # ==============================================================================\n """"""Tools to help with the TensorFlow 2.0 transition.\n \n-This module is meant for TensorFlow internal implementation, not for users of\n-the TensorFlow library. For that see tf.compat instead.\n+This module is meant for TensorFlow internal implementation, not for users of the TensorFlow library. For that, see tf.compat instead.\n """"""\n \n+""""""conda install -c anaconda tensorflow-gpu==1.15.0 , pip install tensorflow\n+""""""\n from tensorflow.python.platform import _pywrap_tf2\n from tensorflow.python.util.tf_export import tf_export\n \n'","['Fixed tensorflow installation and grammatical mistake', 'This is a new commit', '<message here>']",[],2022-10-16 13:36:20
58103,Fix typos and broken links in CONTRIBUTING.md,"- Included a mermaid flowchart for PR Workflow.
- Fixed typos and broken links.
- Organised the file with a new layout for better readability.",Abinashbunty,"['Abinashbunty', 'mihaimaruseac']","['Please revert this type of changes.', 'Removing line breaks here makes it harder to review what changed. Please revert.', 'Please revert unnecessary line wrap change', 'What happened with the HTML link?', 'Please revert', 'Please revert line wrap change', 'Please revert', 'The HTML link pointed to a broken link. For the bash one, I found a reference. But there was no file in the project to which I can refer for the HTML license.', 'Alright. In some cases, line breaks were needed because of the use of \\- in the previous version. But I will make the changes as you suggested.', 'We have automation for formatting and the changes would be reverted by that.', 'So I will keep the line breaks like before. 👍🏻  Any suggestion about the mermaid diagram? ', 'Done', 'Done', '@mihaimaruseac I made the changes that you suggested. 😄 ', 'Awesome. Unfortunately, the diagram has lines crossing compared to previous one and loses the flow of a waterfall model. Do you know if this can be updated? \r\n![image](https://user-images.githubusercontent.com/323199/196265897-5b3cadb4-7ee0-41f9-a7d7-17a8c34f0f0a.png)\r\n', '@mihaimaruseac Thanks! The mermaid flowchart cannot be updated due to an open issue in mermaid at the moment. So I reverted back to what the flowchart was. Later when mermaid will be updated, I will include it. 😄 \r\n\r\nFor now, I think the PR is all set.']","['mihaimaruseac', 'mihaimaruseac', 'Abinashbunty', 'Abinashbunty', 'mihaimaruseac', 'Abinashbunty', 'Abinashbunty', 'Abinashbunty', 'mihaimaruseac']","['mihaimaruseac', 'mihaimaruseac', 'Abinashbunty', 'Abinashbunty', 'mihaimaruseac', 'Abinashbunty', 'Abinashbunty', 'Abinashbunty', 'mihaimaruseac']",['gbaned'],"b'diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md\nindex 943fdc3f28e20..8cf8f67e4f387 100644\n--- a/CONTRIBUTING.md\n+++ b/CONTRIBUTING.md\n@@ -40,7 +40,7 @@ approved. - Note: As a friendly reminder we may reach out to you if the PR is\n awaiting your response for more than 2 weeks.\n \n **4. Approved** - Once the PR is approved, it gets `kokoro:force-run` label\n-applied and it initiates CI/CD tests. - We can\'t move forward if theses tests\n+applied and it initiates CI/CD tests. - We can\'t move forward if these tests\n fail. - In such situations, we may request you to make further changes to your\n PR for the tests to pass. - Once the tests pass, we now bring all the code in\n the internal code base, using a job called ""copybara"".\n@@ -141,8 +141,7 @@ Include a license at the top of new files.\n * [Python license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn.py#L1)\n * [Java license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/Graph.java#L1)\n * [Go license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/operation.go#L1)\n-* [Bash license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_sanity.sh#L2)\n-* [HTML license example](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/components/tf_backend/tf-backend.html#L2)\n+* [Bash license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_build.sh#L2)\n * [JavaScript/TypeScript license example](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/components/tf_backend/backend.ts#L1)\n \n Bazel BUILD files also need to include a license section, e.g.,\n@@ -187,7 +186,7 @@ top level tensorflow directory.\n \n * [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html)\n * [Google JavaScript Style Guide](https://google.github.io/styleguide/jsguide.html)\n-* [Google Shell Style Guide](https://google.github.io/styleguide/shell.xml)\n+* [Google Shell Style Guide](https://google.github.io/styleguide/shellguide.html)\n * [Google Objective-C Style Guide](https://google.github.io/styleguide/objcguide.html)\n \n #### Running sanity check\n@@ -232,7 +231,6 @@ There are two ways to run TensorFlow unit tests.\n \n     ```bash\n     export LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH""\n-\n     export flags=""--config=opt --config=cuda -k""\n     ```\n \n'","['Update CONTRIBUTING.md\n\n1. Included a mermaid flowchart for PR Workflow.\r\n2. Fixed typos and broken links.\r\n3. Organised the file with new layout for better readability.', ""Merge branch 'tensorflow:master' into master"", ""Merge branch 'tensorflow:master' into master"", ""Merge branch 'tensorflow:master' into master"", 'Update CONTRIBUTING.md\n\n- Fixed typos\r\n- Fixed broken links', ""Merge branch 'tensorflow:master' into master"", 'Update CONTRIBUTING.md\n\nReverted mermaid flowchart']",[],2022-10-15 19:23:35
58099,Disable failing linalg tests on ARM_CI,,elfringham,[],[],"['penpornk', 'learning-to-play']","['penpornk', 'learning-to-play']",['gbaned'],"b'diff --git a/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh b/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh\nindex ae26ae0ad9c8f..4977870515231 100644\n--- a/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh\n+++ b/tensorflow/tools/ci_build/build_scripts/ARM_SKIP_TESTS.sh\n@@ -24,4 +24,14 @@ ARM_SKIP_TESTS=""-//tensorflow/lite/... \\\n -//tensorflow/python/kernel_tests/nn_ops:conv_ops_test \\\n -//tensorflow/python/kernel_tests/nn_ops:conv2d_backprop_filter_grad_test \\\n -//tensorflow/python/kernel_tests/nn_ops:atrous_conv2d_test \\\n--//tensorflow/python/training:server_lib_test""\n+-//tensorflow/python/training:server_lib_test \\\n+-//tensorflow/python/kernel_tests/linalg:linalg_grad_test_gpu \\\n+-//tensorflow/python/kernel_tests/linalg:linalg_grad_test_cpu \\\n+-//tensorflow/python/kernel_tests/linalg:linear_operator_block_diag_test_gpu \\\n+-//tensorflow/python/kernel_tests/linalg:linear_operator_block_diag_test_cpu \\\n+-//tensorflow/python/kernel_tests/linalg:linear_operator_block_lower_triangular_test_gpu \\\n+-//tensorflow/python/kernel_tests/linalg:linear_operator_block_lower_triangular_test_cpu \\\n+-//tensorflow/python/kernel_tests/linalg:linalg_ops_test_gpu \\\n+-//tensorflow/python/kernel_tests/linalg:linalg_ops_test_cpu \\\n+-//tensorflow/python/kernel_tests/linalg:linear_operator_composition_test_gpu \\\n+-//tensorflow/python/kernel_tests/linalg:linear_operator_composition_test_cpu""\n'",['Disable failing linalg tests on ARM_CI'],[],2022-10-15 09:39:00
58095,Fixing the incorrect link in input_layer.py,Added the correct link for `RaggedTensor`,tilakrayal,['gbaned'],"['Hi @tilakrayal It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727']",[],[],['gbaned'],"b""diff --git a/tensorflow/python/keras/engine/input_layer.py b/tensorflow/python/keras/engine/input_layer.py\nindex ff7fff0630023..96661796146a9 100644\n--- a/tensorflow/python/keras/engine/input_layer.py\n+++ b/tensorflow/python/keras/engine/input_layer.py\n@@ -87,7 +87,7 @@ class InputLayer(base_layer.Layer):\n       ragged: Boolean, whether the placeholder created is meant to be ragged.\n           In this case, values of 'None' in the 'shape' argument represent\n           ragged dimensions. For more information about RaggedTensors, see\n-          [this guide](https://www.tensorflow.org/guide/ragged_tensors).\n+          [this guide](https://www.tensorflow.org/guide/ragged_tensor).\n           Default to False.\n       type_spec: A `tf.TypeSpec` object to create Input from. This `tf.TypeSpec`\n           represents the entire batch. When provided, all other args except\n""",['Fixing the incorrect link in input_layer.py'],[],2022-10-14 12:44:43
58092,Unify functions to check whether oneDNN is enabled,"Unify functions to check whether oneDNN is enabled: [Python test_util checker](https://github.com/tensorflow/tensorflow/blob/76b9fa22857148a562f3d9b5af6843402a93c15b/tensorflow/python/framework/test_util.py#L360-L362), [Pywrapped checker](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/port.cc#L62-L67) and [C++ checker](https://github.com/tensorflow/tensorflow/blob/76b9fa22857148a562f3d9b5af6843402a93c15b/tensorflow/core/util/util.cc#L130-L183).

Move the main function to port.cc to avoid cyclic dependency. Keeping the fix minimal to cherry-pick into TF 2.11.

Inconsistencies could cause bugs because Python layer may assume oneDNN is disabled when it's not. For example, `//tensorflow/python/framework:config_test` will fail when run on Cascade Lake or newer CPUs because:
* The test is [supposed to be skipped](https://github.com/tensorflow/tensorflow/blob/76b9fa22857148a562f3d9b5af6843402a93c15b/tensorflow/python/framework/config_test.py#L682-L684) when oneDNN is turned on.
* Python `test_util` `IsMklEnabled` only checks for [static defines](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/port.cc#L62-L67) and [`TF_ENABLE_ONEDNN_OPTS` environment variable](https://github.com/tensorflow/tensorflow/blob/76b9fa22857148a562f3d9b5af6843402a93c15b/tensorflow/python/framework/test_util.py#L362). When the var is unset, the Python checker will just think oneDNN is disabled. But oneDNN is turned on by default on Cascade Lake and newer Intel CPUs (even when the env var is unset).
* The test was not skipped when it should have been skipped.",penpornk,"['elfringham', 'penpornk']","[""@gbaned I opened this PR just to run external CIs and get reviews from partners. There's no need to assign a TF reviewer. (I will submit the changes internally and close this PR afterwards.) Sorry I forgot to mention this earlier!"", 'cc: @nSircombe @milpuz01 @elfringham FYI.', '[ARM CI](https://github.com/tensorflow/tensorflow/actions/runs/3248491140) has 1346 tests passed and 10 failed:\r\n```\r\n//tensorflow/python/kernel_tests/linalg:linalg_grad_test_cpu\r\n//tensorflow/python/kernel_tests/linalg:linalg_grad_test_gpu\r\n//tensorflow/python/kernel_tests/linalg:linear_operator_block_diag_test_cpu\r\n//tensorflow/python/kernel_tests/linalg:linear_operator_block_diag_test_gpu\r\n//tensorflow/python/kernel_tests/linalg:linear_operator_block_lower_triangular_test_cpu\r\n//tensorflow/python/kernel_tests/linalg:linear_operator_block_lower_triangular_test_gpu\r\n//tensorflow/python/kernel_tests/linalg:linear_operator_composition_test_cpu\r\n//tensorflow/python/kernel_tests/linalg:linear_operator_composition_test_gpu\r\n//tensorflow/python/kernel_tests/linalg:linalg_ops_test_cpu\r\n//tensorflow/python/kernel_tests/linalg:linalg_ops_test_gpu\r\n```\r\nThe failures look unrelated to this PR. The exact 10 tests have been failing in the past few days, e.g., this [trivial commit](https://github.com/tensorflow/tensorflow/commit/182d520728de6e4de7158218d0574e730ad4ef15) from 3 days ago also have the [same failures](https://github.com/tensorflow/tensorflow/actions/runs/3230028384). So I think this PR is fine for aarch64.', 'Those 10 failures were introduced by this commit https://github.com/tensorflow/tensorflow/commit/720df16242fb5cace4fae147a45688750b660ee4', '@elfringham @gzmkl Thank you both for the quick feedback!', ""I've submitted changes internally in https://github.com/tensorflow/tensorflow/commit/5ec3d2e626589540bcfbeb7dac40255034e587df. Closing this PR now.""]","['gzmkl', 'gzmkl']","['gzmkl', 'gzmkl']","['penpornk', 'gbaned']","b'diff --git a/tensorflow/core/util/BUILD b/tensorflow/core/util/BUILD\nindex 70cee37ab301e..b05f631df48cb 100644\n--- a/tensorflow/core/util/BUILD\n+++ b/tensorflow/core/util/BUILD\n@@ -489,6 +489,11 @@ cc_library(\n         ""//tensorflow/python:__pkg__"",\n         ""//tensorflow/python/util:__pkg__"",\n     ],\n+    deps = [\n+        ""//tensorflow/core/platform:platform_port"",\n+        ""//tensorflow/core/util:env_var"",\n+        ""@com_google_absl//absl/base"",\n+    ],\n     alwayslink = 1,\n )\n \ndiff --git a/tensorflow/core/util/port.cc b/tensorflow/core/util/port.cc\nindex 358b39bfb0064..5498624420ccf 100644\n--- a/tensorflow/core/util/port.cc\n+++ b/tensorflow/core/util/port.cc\n@@ -15,6 +15,9 @@ limitations under the License.\n \n #include ""tensorflow/core/util/port.h""\n \n+#include ""absl/base/call_once.h""\n+#include ""tensorflow/core/platform/cpu_info.h""\n+#include ""tensorflow/core/util/env_var.h""\n \n namespace tensorflow {\n \n@@ -60,10 +63,57 @@ bool GpuSupportsHalfMatMulAndConv() {\n }\n \n bool IsMklEnabled() {\n-#if defined(INTEL_MKL) && defined(ENABLE_MKL)\n-  return true;\n-#else\n+#ifndef INTEL_MKL\n   return false;\n-#endif  // INTEL_MKL && ENABLE_MKL\n+#endif  // !INTEL_MKL\n+  static absl::once_flag once;\n+#ifdef ENABLE_MKL\n+  // Keeping TF_DISABLE_MKL env variable for legacy reasons.\n+  static bool oneDNN_disabled = false;\n+  absl::call_once(once, [&] {\n+    TF_CHECK_OK(ReadBoolFromEnvVar(""TF_DISABLE_MKL"", false, &oneDNN_disabled));\n+    if (oneDNN_disabled) VLOG(2) << ""TF-MKL: Disabling oneDNN"";\n+  });\n+  return (!oneDNN_disabled);\n+#else\n+  // Linux: Turn oneDNN on by default for CPUs with neural network features.\n+  // Windows: oneDNN is off by default.\n+  // No need to guard for other platforms here because INTEL_MKL is only defined\n+  // for non-mobile Linux or Windows.\n+  static bool oneDNN_enabled =\n+#ifdef __linux__\n+      port::TestCPUFeature(port::CPUFeature::AVX512_VNNI) ||\n+      port::TestCPUFeature(port::CPUFeature::AVX512_BF16) ||\n+      port::TestCPUFeature(port::CPUFeature::AVX_VNNI) ||\n+      port::TestCPUFeature(port::CPUFeature::AMX_TILE) ||\n+      port::TestCPUFeature(port::CPUFeature::AMX_INT8) ||\n+      port::TestCPUFeature(port::CPUFeature::AMX_BF16);\n+#else\n+      false;\n+#endif  // __linux__\n+  absl::call_once(once, [&] {\n+    auto status = ReadBoolFromEnvVar(""TF_ENABLE_ONEDNN_OPTS"", oneDNN_enabled,\n+                                     &oneDNN_enabled);\n+    if (!status.ok()) {\n+      LOG(WARNING) << ""TF_ENABLE_ONEDNN_OPTS is not set to either \'0\', \'false\',""\n+                   << "" \'1\', or \'true\'. Using the default setting: ""\n+                   << oneDNN_enabled;\n+    }\n+    if (oneDNN_enabled) {\n+#ifndef DNNL_AARCH64_USE_ACL\n+      LOG(INFO) << ""oneDNN custom operations are on. ""\n+                << ""You may see slightly different numerical results due to ""\n+                << ""floating-point round-off errors from different computation ""\n+                << ""orders. To turn them off, set the environment variable ""\n+                << ""`TF_ENABLE_ONEDNN_OPTS=0`."";\n+#else\n+      LOG(INFO) << ""Experimental oneDNN custom operations are on. ""\n+                << ""If you experience issues, please turn them off by setting ""\n+                << ""the environment variable `TF_ENABLE_ONEDNN_OPTS=0`."";\n+#endif  // !DNNL_AARCH64_USE_ACL\n+    }\n+  });\n+  return oneDNN_enabled;\n+#endif  // ENABLE_MKL\n }\n }  // end namespace tensorflow\ndiff --git a/tensorflow/core/util/util.cc b/tensorflow/core/util/util.cc\nindex eef2618de91a8..a92ca20179aa0 100644\n--- a/tensorflow/core/util/util.cc\n+++ b/tensorflow/core/util/util.cc\n@@ -15,16 +15,10 @@ limitations under the License.\n \n #include ""tensorflow/core/util/util.h""\n \n-#include <string>\n-#include <vector>\n-\n-#include ""absl/base/call_once.h""\n-#include ""tensorflow/core/framework/device_factory.h""\n #include ""tensorflow/core/lib/gtl/inlined_vector.h""\n #include ""tensorflow/core/lib/strings/strcat.h""\n-#include ""tensorflow/core/platform/cpu_info.h""\n #include ""tensorflow/core/platform/logging.h""\n-#include ""tensorflow/core/util/env_var.h""\n+#include ""tensorflow/core/util/port.h""\n \n namespace tensorflow {\n \n@@ -127,59 +121,9 @@ string SliceDebugString(const TensorShape& shape, const int64_t flat) {\n   return result;\n }\n \n+// TODO(penporn): Remove this function from util.cc\n bool IsMKLEnabled() {\n-#ifndef INTEL_MKL\n-  return false;\n-#endif  // !INTEL_MKL\n-  static absl::once_flag once;\n-#ifdef ENABLE_MKL\n-  // Keeping TF_DISABLE_MKL env variable for legacy reasons.\n-  static bool oneDNN_disabled = false;\n-  absl::call_once(once, [&] {\n-    TF_CHECK_OK(ReadBoolFromEnvVar(""TF_DISABLE_MKL"", false, &oneDNN_disabled));\n-    if (oneDNN_disabled) VLOG(2) << ""TF-MKL: Disabling oneDNN"";\n-  });\n-  return (!oneDNN_disabled);\n-#else\n-  // Linux: Turn oneDNN on by default for CPUs with neural network features.\n-  // Windows: oneDNN is off by default.\n-  // No need to guard for other platforms here because INTEL_MKL is only defined\n-  // for non-mobile Linux or Windows.\n-  static bool oneDNN_enabled =\n-#ifdef __linux__\n-      port::TestCPUFeature(port::CPUFeature::AVX512_VNNI) ||\n-      port::TestCPUFeature(port::CPUFeature::AVX512_BF16) ||\n-      port::TestCPUFeature(port::CPUFeature::AVX_VNNI) ||\n-      port::TestCPUFeature(port::CPUFeature::AMX_TILE) ||\n-      port::TestCPUFeature(port::CPUFeature::AMX_INT8) ||\n-      port::TestCPUFeature(port::CPUFeature::AMX_BF16);\n-#else\n-      false;\n-#endif  // __linux__\n-  absl::call_once(once, [&] {\n-    auto status = ReadBoolFromEnvVar(""TF_ENABLE_ONEDNN_OPTS"", oneDNN_enabled,\n-                                     &oneDNN_enabled);\n-    if (!status.ok()) {\n-      LOG(WARNING) << ""TF_ENABLE_ONEDNN_OPTS is not set to either \'0\', \'false\',""\n-                   << "" \'1\', or \'true\'. Using the default setting: ""\n-                   << oneDNN_enabled;\n-    }\n-    if (oneDNN_enabled) {\n-#ifndef DNNL_AARCH64_USE_ACL\n-      LOG(INFO) << ""oneDNN custom operations are on. ""\n-                << ""You may see slightly different numerical results due to ""\n-                << ""floating-point round-off errors from different computation ""\n-                << ""orders. To turn them off, set the environment variable ""\n-                << ""`TF_ENABLE_ONEDNN_OPTS=0`."";\n-#else\n-      LOG(INFO) << ""Experimental oneDNN custom operations are on. ""\n-                << ""If you experience issues, please turn them off by setting ""\n-                << ""the environment variable `TF_ENABLE_ONEDNN_OPTS=0`."";\n-#endif  // !DNNL_AARCH64_USE_ACL\n-    }\n-  });\n-  return oneDNN_enabled;\n-#endif  // ENABLE_MKL\n+  return IsMklEnabled();\n }\n \n }  // namespace tensorflow\ndiff --git a/tensorflow/python/framework/test_util.py b/tensorflow/python/framework/test_util.py\nindex cfe333a921756..49bbfb24cdf8e 100644\n--- a/tensorflow/python/framework/test_util.py\n+++ b/tensorflow/python/framework/test_util.py\n@@ -358,8 +358,7 @@ def GpuSupportsHalfMatMulAndConv():\n \n \n def IsMklEnabled():\n-  return (_pywrap_util_port.IsMklEnabled() or\n-          os.getenv(""TF_ENABLE_ONEDNN_OPTS"", ""False"").lower() in [""true"", ""1""])\n+  return _pywrap_util_port.IsMklEnabled()\n \n \n def InstallStackTraceHandler():\n'","['Unify functions to check whether oneDNN is enabled: Pywrapped checker (port.cc) and C++ checker (util.cc).\n\nMove the main function to port.cc to avoid cyclic dependency. Keeping the fix minimal to cherry-pick into TF 2.11.', ""Clean up IsMklEnabled() in test_util.\n\nThe pywrapped IsMklEnabled() already checks for the environment\nvariable, so we don't need to explicitly read them in the Python layer\nanymore. This also avoids inconsistencies when the env var changes after\ntensorflow is imported in Python, since the C++ version only reads the\nenv var once during import time.""]",[],2022-10-14 07:52:30
58089,Fix conjugate transpose for 0/1D complex tensor,"This PR fixes issue-[58007](https://github.com/tensorflow/tensorflow/issues/58007).
For 0D or 1D complex input, the unfixed version tends to treat `tf.transpose(in, conjugate=True)` as no-op which may fail `tensorflow/python/kernel_tests/math_ops/transpose_op_test.py`.
",wenscarl,[],[],['cantonios'],['cantonios'],['gbaned'],"b'diff --git a/tensorflow/core/kernels/transpose_functor_gpu.cu.cc b/tensorflow/core/kernels/transpose_functor_gpu.cu.cc\nindex 0747685853ee0..35101d8ce3bb3 100644\n--- a/tensorflow/core/kernels/transpose_functor_gpu.cu.cc\n+++ b/tensorflow/core/kernels/transpose_functor_gpu.cu.cc\n@@ -31,6 +31,14 @@ typedef Eigen::GpuDevice GPUDevice;\n namespace tensorflow {\n namespace internal {\n \n+template <typename T>\n+__global__ void ConjugateKernel(int nthreads, const T* __restrict__ src,\n+                                T* __restrict__ dst) {\n+  GPU_1D_KERNEL_LOOP(idx, nthreads) {\n+    dst[idx] = Eigen::numext::conj(ldg(src + idx));\n+  }\n+}\n+\n template <typename T, bool conjugate>\n __global__ void TransposeKernel(int nthreads, const T* __restrict__ src,\n                                 const int32* __restrict__ buf,\n@@ -62,6 +70,15 @@ void TransposeSimple(const GPUDevice& d, const Tensor& in,\n   CHECK_LT(nelem, kint32max) << ""Tensor too large to transpose on GPU"";\n   // Pack strides and permutation into one buffer.\n   const int32 ndims = in.dims();\n+  GpuLaunchConfig cfg = GetGpuLaunchConfig(nelem, d);\n+  const T* p = reinterpret_cast<const T*>(in.tensor_data().data());\n+  T* q = reinterpret_cast<T*>(const_cast<char*>((out->tensor_data().data())));\n+  if (conjugate && ndims < 2) {\n+    TF_CHECK_OK(GpuLaunchKernel(ConjugateKernel<T>, cfg.block_count,\n+                                cfg.thread_per_block, 0, d.stream(),\n+                                cfg.virtual_thread_count, p, q));\n+    return;\n+  }\n   gtl::InlinedVector<int32, 24> host_buf(ndims * 3);\n   gtl::InlinedVector<int32, 8> in_strides = ComputeStride<int32>(in.shape());\n   gtl::InlinedVector<int32, 8> out_strides = ComputeStride<int32>(out->shape());\n@@ -78,9 +95,6 @@ void TransposeSimple(const GPUDevice& d, const Tensor& in,\n   // therefore we are doing a sync copy effectively.\n   d.memcpyHostToDevice(dev_buf, host_buf.data(), num_bytes);\n   // Launch kernel to q[...] = p[...].\n-  const T* p = reinterpret_cast<const T*>(in.tensor_data().data());\n-  T* q = reinterpret_cast<T*>(const_cast<char*>((out->tensor_data().data())));\n-  GpuLaunchConfig cfg = GetGpuLaunchConfig(nelem, d);\n   TF_CHECK_OK(GpuLaunchKernel(\n       TransposeKernel<T, conjugate>, cfg.block_count, cfg.thread_per_block, 0,\n       d.stream(), cfg.virtual_thread_count, p,\n@@ -179,8 +193,7 @@ template <typename T, bool conjugate>\n struct Transpose<GPUDevice, T, conjugate> {\n   static void run(const GPUDevice& d, const Tensor& in,\n                   const gtl::ArraySlice<int32> perm, Tensor* out) {\n-    if (in.dims() < 2) return;\n-    if (internal::TransposeUsingTile<T, conjugate>::run(d, in, perm, out)) {\n+    if (in.dims() > 1 && internal::TransposeUsingTile<T, conjugate>::run(d, in, perm, out)) {\n       return;\n     }\n \n'",['Fix conjugate transpose for 0/1D complex tensor'],[],2022-10-13 15:15:14
58083,"r2.10 cherry-pick: 717ca98d8c3 ""Adding missing requirement on inputs for MirrorPadGrad op and updating arithmetic to account for int32 padding values.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/717ca98d8c3bba348ff62281fdf38dcb5ea1ec92,tensorflow-jenkins,[],[],['learning-to-play'],['learning-to-play'],[],"b'diff --git a/tensorflow/core/kernels/image/mirror_pad_op.cc b/tensorflow/core/kernels/image/mirror_pad_op.cc\nindex 9b9ba45251711..b4bf3b3997513 100644\n--- a/tensorflow/core/kernels/image/mirror_pad_op.cc\n+++ b/tensorflow/core/kernels/image/mirror_pad_op.cc\n@@ -297,13 +297,21 @@ class MirrorPadGradOp : public OpKernel {\n     TensorShape output_shape;\n     typename TTypes<Tpaddings>::ConstMatrix paddings = in1.matrix<Tpaddings>();\n     for (int d = 0; d < dims; ++d) {\n-      const Tpaddings before = paddings(d, 0);  // Pad before existing elements.\n-      const Tpaddings after = paddings(d, 1);   // Pad after existing elements.\n+      const int64_t before = paddings(d, 0);  // Pad before existing elements.\n+      const int64_t after = paddings(d, 1);   // Pad after existing elements.\n       OP_REQUIRES(context, before >= 0 && after >= 0,\n                   errors::InvalidArgument(\n                       ""Paddings must be non-negative: "", before, "", "", after));\n \n-      const int64_t out_size = in0.dim_size(d) - (before + after);\n+      const int64_t in_size = in0.dim_size(d);\n+      const int64_t total_padding = before + after;\n+      OP_REQUIRES(\n+          context, total_padding < in_size && total_padding >= 0,\n+          errors::InvalidArgument(\n+              ""Total paddings must be less than the input dimension size: "",\n+              total_padding, "" was not less than "", in_size));\n+\n+      const int64_t out_size = in_size - total_padding;\n       if (offset_ == 0) {  // SYMMETRIC mode.\n         OP_REQUIRES(context, before <= out_size && after <= out_size,\n                     errors::InvalidArgument(""paddings must be no greater ""\ndiff --git a/tensorflow/python/kernel_tests/array_ops/array_ops_test.py b/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\nindex a9f4180ed4c70..c14703cde3934 100644\n--- a/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\n@@ -1617,6 +1617,21 @@ def testEager(self):\n                           [[0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 0, 0],\n                            [0, 0, 4, 5, 6, 0, 0], [0, 0, 0, 0, 0, 0, 0]])\n \n+  # b/246325518: Bad shape size. Explicitly testing different execution paths.\n+  def testInvalidMirrorPadGradEagerMode(self):\n+    with context.eager_mode():\n+      with self.assertRaises(Exception):\n+        gen_array_ops.MirrorPadGrad(\n+            input=[1], paddings=[[0x77f00000, 0xa000000]], mode=""REFLECT"")\n+\n+  # b/246325518: Bad shape size. Explicitly testing different execution paths.\n+  def testInvalidMirrorPadGradGraphMode(self):\n+    with context.graph_mode():\n+      with self.assertRaises(Exception):\n+        result = gen_array_ops.MirrorPadGrad(\n+            input=[1], paddings=[[0x77f00000, 0xa000000]], mode=""REFLECT"")\n+        self.evaluate(result)\n+\n   def testSymmetricMirrorPadGrad(self):\n     t = np.broadcast_to(np.arange(0, 7), (3, 2, 1, 7))\n     paddings = constant_op.constant([\n'",['Adding missing requirement on inputs for MirrorPadGrad op and updating arithmetic to account for int32 padding values.\n\nPiperOrigin-RevId: 480691952'],[],2022-10-13 01:42:40
58082,"r2.9 cherry-pick: 717ca98d8c3 ""Adding missing requirement on inputs for MirrorPadGrad op and updating arithmetic to account for int32 padding values.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/717ca98d8c3bba348ff62281fdf38dcb5ea1ec92,tensorflow-jenkins,[],[],['learning-to-play'],['learning-to-play'],[],"b'diff --git a/tensorflow/core/kernels/image/mirror_pad_op.cc b/tensorflow/core/kernels/image/mirror_pad_op.cc\nindex 9b9ba45251711..b4bf3b3997513 100644\n--- a/tensorflow/core/kernels/image/mirror_pad_op.cc\n+++ b/tensorflow/core/kernels/image/mirror_pad_op.cc\n@@ -297,13 +297,21 @@ class MirrorPadGradOp : public OpKernel {\n     TensorShape output_shape;\n     typename TTypes<Tpaddings>::ConstMatrix paddings = in1.matrix<Tpaddings>();\n     for (int d = 0; d < dims; ++d) {\n-      const Tpaddings before = paddings(d, 0);  // Pad before existing elements.\n-      const Tpaddings after = paddings(d, 1);   // Pad after existing elements.\n+      const int64_t before = paddings(d, 0);  // Pad before existing elements.\n+      const int64_t after = paddings(d, 1);   // Pad after existing elements.\n       OP_REQUIRES(context, before >= 0 && after >= 0,\n                   errors::InvalidArgument(\n                       ""Paddings must be non-negative: "", before, "", "", after));\n \n-      const int64_t out_size = in0.dim_size(d) - (before + after);\n+      const int64_t in_size = in0.dim_size(d);\n+      const int64_t total_padding = before + after;\n+      OP_REQUIRES(\n+          context, total_padding < in_size && total_padding >= 0,\n+          errors::InvalidArgument(\n+              ""Total paddings must be less than the input dimension size: "",\n+              total_padding, "" was not less than "", in_size));\n+\n+      const int64_t out_size = in_size - total_padding;\n       if (offset_ == 0) {  // SYMMETRIC mode.\n         OP_REQUIRES(context, before <= out_size && after <= out_size,\n                     errors::InvalidArgument(""paddings must be no greater ""\ndiff --git a/tensorflow/python/kernel_tests/array_ops/array_ops_test.py b/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\nindex 1cf45c1ff48a8..1a55c64b46934 100644\n--- a/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\n@@ -1553,6 +1553,21 @@ def testEager(self):\n                           [[0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 0, 0],\n                            [0, 0, 4, 5, 6, 0, 0], [0, 0, 0, 0, 0, 0, 0]])\n \n+  # b/246325518: Bad shape size. Explicitly testing different execution paths.\n+  def testInvalidMirrorPadGradEagerMode(self):\n+    with context.eager_mode():\n+      with self.assertRaises(Exception):\n+        gen_array_ops.MirrorPadGrad(\n+            input=[1], paddings=[[0x77f00000, 0xa000000]], mode=""REFLECT"")\n+\n+  # b/246325518: Bad shape size. Explicitly testing different execution paths.\n+  def testInvalidMirrorPadGradGraphMode(self):\n+    with context.graph_mode():\n+      with self.assertRaises(Exception):\n+        result = gen_array_ops.MirrorPadGrad(\n+            input=[1], paddings=[[0x77f00000, 0xa000000]], mode=""REFLECT"")\n+        self.evaluate(result)\n+\n   def testSymmetricMirrorPadGrad(self):\n     t = np.broadcast_to(np.arange(0, 7), (3, 2, 1, 7))\n     paddings = constant_op.constant([\n'",['Adding missing requirement on inputs for MirrorPadGrad op and updating arithmetic to account for int32 padding values.\n\nPiperOrigin-RevId: 480691952'],[],2022-10-13 01:42:23
58081,"r2.8 cherry-pick: 717ca98d8c3 ""Adding missing requirement on inputs for MirrorPadGrad op and updating arithmetic to account for int32 padding values.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/717ca98d8c3bba348ff62281fdf38dcb5ea1ec92,tensorflow-jenkins,[],[],['learning-to-play'],['learning-to-play'],[],"b'diff --git a/tensorflow/core/kernels/image/mirror_pad_op.cc b/tensorflow/core/kernels/image/mirror_pad_op.cc\nindex 9b9ba45251711..b4bf3b3997513 100644\n--- a/tensorflow/core/kernels/image/mirror_pad_op.cc\n+++ b/tensorflow/core/kernels/image/mirror_pad_op.cc\n@@ -297,13 +297,21 @@ class MirrorPadGradOp : public OpKernel {\n     TensorShape output_shape;\n     typename TTypes<Tpaddings>::ConstMatrix paddings = in1.matrix<Tpaddings>();\n     for (int d = 0; d < dims; ++d) {\n-      const Tpaddings before = paddings(d, 0);  // Pad before existing elements.\n-      const Tpaddings after = paddings(d, 1);   // Pad after existing elements.\n+      const int64_t before = paddings(d, 0);  // Pad before existing elements.\n+      const int64_t after = paddings(d, 1);   // Pad after existing elements.\n       OP_REQUIRES(context, before >= 0 && after >= 0,\n                   errors::InvalidArgument(\n                       ""Paddings must be non-negative: "", before, "", "", after));\n \n-      const int64_t out_size = in0.dim_size(d) - (before + after);\n+      const int64_t in_size = in0.dim_size(d);\n+      const int64_t total_padding = before + after;\n+      OP_REQUIRES(\n+          context, total_padding < in_size && total_padding >= 0,\n+          errors::InvalidArgument(\n+              ""Total paddings must be less than the input dimension size: "",\n+              total_padding, "" was not less than "", in_size));\n+\n+      const int64_t out_size = in_size - total_padding;\n       if (offset_ == 0) {  // SYMMETRIC mode.\n         OP_REQUIRES(context, before <= out_size && after <= out_size,\n                     errors::InvalidArgument(""paddings must be no greater ""\ndiff --git a/tensorflow/python/kernel_tests/array_ops/array_ops_test.py b/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\nindex 4512f1777e55a..150a8574cab91 100644\n--- a/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/array_ops_test.py\n@@ -1522,6 +1522,21 @@ def testEager(self):\n                           [[0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 0, 0],\n                            [0, 0, 4, 5, 6, 0, 0], [0, 0, 0, 0, 0, 0, 0]])\n \n+  # b/246325518: Bad shape size. Explicitly testing different execution paths.\n+  def testInvalidMirrorPadGradEagerMode(self):\n+    with context.eager_mode():\n+      with self.assertRaises(Exception):\n+        gen_array_ops.MirrorPadGrad(\n+            input=[1], paddings=[[0x77f00000, 0xa000000]], mode=""REFLECT"")\n+\n+  # b/246325518: Bad shape size. Explicitly testing different execution paths.\n+  def testInvalidMirrorPadGradGraphMode(self):\n+    with context.graph_mode():\n+      with self.assertRaises(Exception):\n+        result = gen_array_ops.MirrorPadGrad(\n+            input=[1], paddings=[[0x77f00000, 0xa000000]], mode=""REFLECT"")\n+        self.evaluate(result)\n+\n   def testSymmetricMirrorPadGrad(self):\n     t = np.broadcast_to(np.arange(0, 7), (3, 2, 1, 7))\n     paddings = constant_op.constant([\n'",['Adding missing requirement on inputs for MirrorPadGrad op and updating arithmetic to account for int32 padding values.\n\nPiperOrigin-RevId: 480691952'],[],2022-10-13 01:25:13
58079,Replace reviewer for automatic cherrypicks,Since I no longer work in TF due to reasons :),mihaimaruseac,[],[],[],[],"['gbaned', 'learning-to-play']","b'diff --git a/.github/workflows/release-branch-cherrypick.yml b/.github/workflows/release-branch-cherrypick.yml\nindex 456aa93bd0b4b..a57852a964489 100644\n--- a/.github/workflows/release-branch-cherrypick.yml\n+++ b/.github/workflows/release-branch-cherrypick.yml\n@@ -62,7 +62,7 @@ jobs:\n         token: ${{ secrets.JENKINS_TOKEN }}\n         base: ${{ github.event.inputs.release_branch }}\n         branch: ${{ github.event.inputs.release_branch }}-${{ steps.cherrypick.outputs.SHORTSHA }}\n-        reviewers: mihaimaruseac\n+        reviewers: learning-to-play\n         body: |\n           Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/${{ github.event.inputs.git_commit }}\n \n'",['Replace reviewer for automatic cherrypicks\n\nSince I no longer work in TF due to reasons :)'],[],2022-10-12 20:34:42
